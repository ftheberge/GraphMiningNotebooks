{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Graph Embeddings\n",
    "\n",
    "In this notebook, we illustrate several graph embedding algorithms, we show how we can compare embeddings using an unsupervised framework, and we look at various applications such as clustering, link prediction and anomaly detection.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- install node2vec code (see https://snap.stanford.edu/node2vec)\n",
    "- compile GED code (graph embedding divergence), \n",
    "  the base implementation of the framework in C (the code is included, and can also be found at      https://github.com/ftheberge/Comparing_Graph_Embeddings) \n",
    "- new package to install: 'pip install --no-dependencies graphrole'\n",
    "\n",
    "Also set the path(s) in the cell below. For Windows, you may need to use \"\\\\\" or \"\\\\\\\\\" as delimiters, for example 'C:\\\\\\\\node2vec\\\\\\\\node2vec.exe'\n",
    "\n",
    "Also for windows, \"cp\" should be changed to \"copy\" when keeping track of best and worst embeddings.\n",
    "\n",
    "### Non-deterministic results\n",
    "\n",
    "Some of the results in this notebook may vary from run to run in particular for node2vec (which uses random walks) and for 2-d renditions of high-dimensional embeddings via UMAP.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the data directory\n",
    "datadir = '../Datasets/'\n",
    "\n",
    "## location of the GED code\n",
    "## use the '-S' option to use split JS divergence\n",
    "GED = '../GED/GED'\n",
    "\n",
    "## location of the node2vec code\n",
    "n2v = '~/Tools/node2vec/node2vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "import os\n",
    "import umap\n",
    "import pickle\n",
    "import partition_igraph\n",
    "import subprocess\n",
    "import scipy.sparse.linalg as lg\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import adjusted_mutual_info_score as AMI\n",
    "from graphrole import RecursiveFeatureExtractor, RoleExtractor\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import calinski_harabasz_score as CHS\n",
    "from sklearn.metrics import silhouette_score as SIL\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "## node and edge greyscale colors\n",
    "cls_edges = 'gainsboro'\n",
    "cls = ['silver','dimgray','black']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## as defined in the node2vec paper\n",
    "def binary_operator(u, v, op='had'):\n",
    "    if op=='had':\n",
    "        return u * v\n",
    "    if op=='l1':\n",
    "        return np.abs(u - v)\n",
    "    if op=='l2':\n",
    "        return (u - v) ** 2\n",
    "    if op=='avg':\n",
    "        return (u + v) / 2.0\n",
    "\n",
    "## 'N2K' mapping is used to map between node name and key value in graph when reading results from node2vec\n",
    "def readEmbedding(fn=\"_embed\", N2K=None):\n",
    "    D = pd.read_csv(fn, sep=' ', skiprows=1, header=None)\n",
    "    D = D.dropna(axis=1)\n",
    "    if N2K!=None:\n",
    "        x = [N2K[i] for i in D[0]]\n",
    "        D[0] = x    \n",
    "        D = D.sort_values(by=0)\n",
    "    Y = np.array(D.iloc[:,1:])\n",
    "    return Y\n",
    "\n",
    "## Read embedding from file in node2vec format\n",
    "## Map to layout format\n",
    "## for visualization, we use UMAP if dim > 2\n",
    "def embed2layout(fn=\"_embed\"):\n",
    "    D = pd.read_csv(fn, sep=' ', skiprows=1, header=None)\n",
    "    D = D.dropna(axis=1)\n",
    "    D = D.sort_values(by=0)\n",
    "    Y = np.array(D.iloc[:,1:])\n",
    "    if Y.shape[1]>2:\n",
    "        Y = umap.UMAP().fit_transform(Y)\n",
    "    ly = []\n",
    "    for v in range(Y.shape[0]):\n",
    "        ly.append((Y[v][0],Y[v][1]))\n",
    "    return ly\n",
    "\n",
    "\n",
    "## Computing JS divergence with GED code given edgelist, communities and embedding\n",
    "def JS(edge_file, comm_file, embed_file, entropy=False):\n",
    "    if entropy:\n",
    "        x = GED+' -E -g '+edge_file+' -c '+comm_file+' -e '+embed_file\n",
    "    else:\n",
    "        x = GED+' -g '+edge_file+' -c '+comm_file+' -e '+embed_file\n",
    "    s = subprocess.run(x, shell=True, stdout=subprocess.PIPE)\n",
    "    x = s.stdout.decode().split(' ')\n",
    "    div = float(x[1])\n",
    "    return(div)\n",
    "\n",
    "\n",
    "## Hope embedding with various similarity functions\n",
    "def Hope(g, sim='katz', dim=2, verbose=False, beta=.01, alpha=.5):\n",
    "    ## For undirected graphs, embedding as source and target are identical\n",
    "    if g.is_directed() == False:\n",
    "        dim = dim*2\n",
    "    A = np.array(g.get_adjacency().data)\n",
    "    beta = beta\n",
    "    alpha = alpha\n",
    "    n = g.vcount()\n",
    "    ## Katz\n",
    "    if sim == 'katz':\n",
    "        M_g = np.eye(n) - beta * A\n",
    "        M_l = beta * A\n",
    "    ## Adamic-Adar\n",
    "    if sim == 'aa':\n",
    "        M_g = np.eye(n)\n",
    "        ## fix bug 1/x and take log();\n",
    "        D = np.diag([1/np.log(x) if x>1 else 0 for x in g.degree()]) \n",
    "        # D = np.diag([1/np.log(max(2,x)) for x in g.degree()]) \n",
    "        M_l = np.dot(np.dot(A,D),A)\n",
    "        np.fill_diagonal(M_l,0)\n",
    "    ## Common neighbors\n",
    "    if sim == 'cn':\n",
    "        M_g = np.eye(n)\n",
    "        M_l = np.dot(A,A)\n",
    "    ## presonalized page rank\n",
    "    if sim == 'ppr':\n",
    "        P = []\n",
    "        for i in range(n):\n",
    "            s = np.sum(A[i])\n",
    "            if s>0:\n",
    "                P.append([x/s for x in A[i]])\n",
    "            else:\n",
    "                P.append([1/n for x in A[i]])\n",
    "        P = np.transpose(np.array(P)) ## fix bug - take transpose\n",
    "        M_g = np.eye(n)-alpha*P\n",
    "        M_l = (1-alpha)*np.eye(n)\n",
    "    S = np.dot(np.linalg.inv(M_g), M_l)\n",
    "    u, s, vt = lg.svds(S, k=dim // 2)\n",
    "    X1 = np.dot(u, np.diag(np.sqrt(s)))\n",
    "    X2 = np.dot(vt.T, np.diag(np.sqrt(s)))\n",
    "    X = np.concatenate((X1, X2), axis=1)\n",
    "    p_d_p_t = np.dot(u, np.dot(np.diag(s), vt))\n",
    "    eig_err = np.linalg.norm(p_d_p_t - S)\n",
    "    if verbose:\n",
    "        print('SVD error (low rank): %f' % eig_err)\n",
    "    ## undirected graphs have identical source and target embeddings\n",
    "    if g.is_directed() == False:\n",
    "        d = dim//2\n",
    "        return X[:,:d]\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "## save to disk to compute divergence\n",
    "def saveEmbedding(X, g, fn='_embed'):\n",
    "    with open(fn,'w') as f:\n",
    "        f.write(str(X.shape[0]) + \" \" + str(X.shape[1])+'\\n')\n",
    "        for i in range(X.shape[0]):\n",
    "            f.write(g.vs[i]['name']+' ')\n",
    "            for j in range(X.shape[1]):\n",
    "                f.write(str(X[i][j])+' ')\n",
    "            f.write('\\n')\n",
    "\n",
    "## Laplacian eigenmaps embedding\n",
    "def LE(g, dim=2):\n",
    "    L_sym = np.array(g.laplacian(normalized=True))\n",
    "    w, v = lg.eigs(L_sym, k=dim + 1, which='SM')\n",
    "    idx = np.argsort(w) # sort eigenvalues\n",
    "    w = w[idx]\n",
    "    v = v[:, idx]\n",
    "    X = v[:, 1:]\n",
    "    return X.real\n",
    "\n",
    "## Returns a LaTeX bmatrix\n",
    "def bmatrix(a):\n",
    "    if len(a.shape) > 2:\n",
    "        raise ValueError('bmatrix can at most display two dimensions')\n",
    "    lines = str(a).replace('[', '').replace(']', '').splitlines()\n",
    "    rv = [r'\\begin{bmatrix}']\n",
    "    rv += ['  ' + ' & '.join(l.split()) + r'\\\\' for l in lines]\n",
    "    rv +=  [r'\\end{bmatrix}']\n",
    "    return '\\n'.join(rv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6.1 in the Book\n",
    "\n",
    "This is to illustrate random walks on (directed) graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ig.Graph.Erdos_Renyi(n=4,p=0,directed=True)\n",
    "g.vs['label'] = ['A','B','C','D']\n",
    "g.vs['color'] = 'white'\n",
    "g.add_edges([(0,1),(1,2),(1,3),(2,1),(3,2)])\n",
    "#ig.plot(g,'tiny.eps',bbox=(0,0,300,200),vertex_label_size=10)\n",
    "ig.plot(g,bbox=(0,0,300,200),vertex_label_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare some datasets\n",
    "\n",
    "* $abcd$: is a small ABCD graph (100 nodes), mainly for visualization and quick exampes\n",
    "* $ABCD$: is a larger ABCD graph (1000 nodes), for experiments\n",
    "* $zac$: Zachary (karate club) graph, for visualzation\n",
    "\n",
    "The small ABCD graph was generated with the following parameters:\n",
    "\n",
    "```\n",
    "n = \"100\"                     # number of vertices in graph\n",
    "t1 = \"3\"                      # power-law exponent for degree distribution\n",
    "d_min = \"5\"                   # minimum degree\n",
    "d_max = \"15\"                  # maximum degree\n",
    "d_max_iter = \"1000\"           # maximum number of iterations for sampling degrees\n",
    "t2 = \"2\"                      # power-law exponent for cluster size distribution\n",
    "c_min = \"25\"                  # minimum cluster size\n",
    "c_max = \"50\"                  # maximum cluster size\n",
    "c_max_iter = \"1000\"           # maximum number of iterations for sampling cluster sizes\n",
    "xi = \"0.2\"                    # fraction of edges to fall in background graph\n",
    "isCL = \"false\"                # if \"false\" use configuration model, if \"true\" use Chung-Lu\n",
    "```\n",
    "\n",
    "The larger ABCD graph was generated with the following parameters:\n",
    "\n",
    "```\n",
    "n = \"1000\"                     # number of vertices in graph\n",
    "t1 = \"3\"                       # power-law exponent for degree distribution\n",
    "d_min = \"10\"                   # minimum degree\n",
    "d_max = \"100\"                  # maximum degree\n",
    "d_max_iter = \"1000\"            # maximum number of iterations for sampling degrees\n",
    "t2 = \"2\"                       # power-law exponent for cluster size distribution\n",
    "c_min = \"50\"                   # minimum cluster size\n",
    "c_max = \"150\"                  # maximum cluster size\n",
    "c_max_iter = \"1000\"            # maximum number of iterations for sampling cluster sizes\n",
    "xi = \"0.6\"                     # fraction of edges to fall in background graph\n",
    "isCL = \"false\"                 # if \"false\" use configuration model, if \"true\" use Chung-Lu\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the small ABCD graph and visualize\n",
    "\n",
    "Node names are integers here, and this should not be confused with the key used in igraph to enumerate the nodes.\n",
    "In order to avoid such issues, we define a dictionary, *n2k*, to map between node name and its key value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read graph and communities\n",
    "abcd = ig.Graph.Read_Ncol(datadir+'ABCD/abcd_100.dat',directed=False)\n",
    "c = np.loadtxt(datadir+'ABCD/abcd_100_comms.dat',dtype='uint16',usecols=(1))\n",
    "abcd.vs['comm'] = [c[int(x['name'])-1] for x in abcd.vs]\n",
    "\n",
    "## print a few stats\n",
    "print(abcd.vcount(),'vertices,',abcd.ecount(),'edges,','avg degreee',np.mean(abcd.degree()),\n",
    "      'communities',max(abcd.vs['comm']))\n",
    "\n",
    "## ground truth communities\n",
    "gt = {k:(v-1) for k,v in enumerate(abcd.vs['comm'])}\n",
    "\n",
    "## map between int(name) to key\n",
    "n2k = {int(v):k for k,v in enumerate(abcd.vs['name'])}\n",
    "\n",
    "## define the colors and node sizes here\n",
    "abcd.vs['size'] = 7\n",
    "abcd.es['color'] = cls_edges\n",
    "abcd.vs['color'] = [cls[i-1] for i in abcd.vs['comm']]\n",
    "\n",
    "#ig.plot(abcd, 'abcd.eps', bbox=(0,0,300,200))\n",
    "ig.plot(abcd, bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the larger ABCD graph and visualize\n",
    "\n",
    "This is a larger graph with lots of noise edges ($\\xi$=0.6). Nore colours refer to the communities.\n",
    "With this amount of noise, the communities are far from obvious on a 2-dim layout.\n",
    "\n",
    "We'll use a version with stronger communities ($\\xi$=0.2) for link prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read graph and communities\n",
    "ABCD = ig.Graph.Read_Ncol(datadir+'ABCD/abcd_1000.dat',directed=False)\n",
    "c = np.loadtxt(datadir+'ABCD/abcd_1000_comms.dat',dtype='uint16',usecols=(1))\n",
    "ABCD.vs['comm'] = [c[int(x['name'])-1] for x in ABCD.vs]\n",
    "\n",
    "## print a few stats\n",
    "print(ABCD.vcount(),'vertices,',ABCD.ecount(),'edges,','avg degreee',np.mean(ABCD.degree()),\n",
    "      'communities',max(ABCD.vs['comm']))\n",
    "\n",
    "## ground truth communities\n",
    "GT = {k:(v-1) for k,v in enumerate(ABCD.vs['comm'])}\n",
    "\n",
    "## map between int(name) to key\n",
    "N2K = {int(v):k for k,v in enumerate(ABCD.vs['name'])}\n",
    "\n",
    "## define the colors and node sizes here\n",
    "## node colors refer to communities\n",
    "cls_edges = 'gainsboro'\n",
    "ABCD.vs['size'] = 5\n",
    "ABCD.es['color'] = cls_edges\n",
    "pal = ig.RainbowPalette(n=max(ABCD.vs['comm'])+1) \n",
    "ABCD.vs['color'] = [pal.get(int(i)) for i in ABCD.vs['comm']]\n",
    "#ABCD.vs['color'] = 'black'\n",
    "\n",
    "ig.plot(ABCD, bbox=(0,0,400,300)) ## communities are far from obvious in 2d layout!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zachary (karate club) graph\n",
    "\n",
    "This graph is already included with igraph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zac = ig.Graph.Famous('zachary')\n",
    "zac.vs['size'] = 7\n",
    "zac.vs['name'] = [str(i) for i in range(zac.vcount())]\n",
    "zac.es['color'] = cls_edges\n",
    "zac.vs['comm'] = [0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "zac.vs['color'] = [cls[i*2] for i in zac.vs['comm']]\n",
    "#ig.plot(zac, 'zachary.eps', bbox=(0,0,300,200))\n",
    "ig.plot(zac, bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph layouts \n",
    "\n",
    "We show a variety of graph layout functions available in igraph on the Zachary graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kamada-Kawai layout\n",
    "ly = zac.layout('kk')\n",
    "\n",
    "#ig.plot(zac, 'layout_kk.eps', layout=ly, bbox=(0,0,300,200))\n",
    "ig.plot(zac, layout=ly, bbox=(0,0,300,200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fruchterman-Reingold layout\n",
    "ly = zac.layout('fr')\n",
    "\n",
    "#ig.plot(zac, 'layout_fr.eps', layout=ly, bbox=(0,0,300,200))\n",
    "ig.plot(zac, layout=ly, bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multidimensional scaling layout\n",
    "ly = zac.layout('mds')\n",
    "\n",
    "#ig.plot(zac, 'layout_mds.eps', layout=ly, bbox=(0,0,300,200))\n",
    "ig.plot(zac, layout=ly, bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Circular layout\n",
    "ly = zac.layout('circle')\n",
    "\n",
    "#ig.plot(zac, 'layout_circle.eps', layout=ly, bbox=(0,0,300,200))\n",
    "ig.plot(zac, layout=ly, bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid layout\n",
    "ly = zac.layout('grid')\n",
    "\n",
    "#ig.plot(zac, 'layout_grid.eps', layout=ly, bbox=(0,0,300,200))\n",
    "ig.plot(zac, layout=ly, bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sugiyama layout\n",
    "ly = zac.layout('sugiyama')\n",
    "\n",
    "#ig.plot(zac, 'layout_tree.eps', layout=ly, bbox=(0,0,300,200))\n",
    "ig.plot(zac, layout=ly, bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate several embeddings -- Zachary graph\n",
    "\n",
    "We try a few graph embedding algorithms on the Zachary graph with\n",
    "different parameters. For example, we try different embedding dimensions.\n",
    "\n",
    "We run the following:\n",
    "* node2vec from source code\n",
    "* HOPE with different similarities\n",
    "* Laplacian Eigenmaps\n",
    "\n",
    "For each embedding, we use the ground truth communities along with the framework to compute the \"graph embedding divergence\" (GED). We visualize some good and bad results.\n",
    "\n",
    "For embeddings with low divergence, we see good separation of the communities (even in 2-dim projection, using UMAP), while this is not the case for embeddings with high divergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [] ## to store results\n",
    "DIM = [2, 5, 10, 15]  ## try embedding in different dimensions\n",
    "best_jsd = 1    ## keep track of best JS-divergence\n",
    "worst_jsd = 0   ## and worst one.\n",
    "\n",
    "## Hope with different choices for the similarity\n",
    "for dim in DIM:\n",
    "    for sim in ['katz','ppr','cn','aa']:\n",
    "        X = Hope(zac,sim=sim,dim=dim) \n",
    "        saveEmbedding(X,zac)\n",
    "        jsd = JS(datadir+'Zachary/zachary.edgelist',datadir+'Zachary/zachary.ecg','_embed')        \n",
    "        ## keep track of best and worst embeddings\n",
    "        if jsd < best_jsd:\n",
    "            os.system('cp _embed _embed_best')\n",
    "            best_jsd = jsd\n",
    "        if jsd > worst_jsd:\n",
    "            os.system('cp _embed _embed_worst')\n",
    "            worst_jsd = jsd\n",
    "        L.append([dim,'hope',sim,jsd])\n",
    "\n",
    "## Laplacian Eigenmap\n",
    "for dim in DIM:\n",
    "    X = LE(zac,dim=dim)\n",
    "    saveEmbedding(X,zac)\n",
    "    jsd = JS(datadir+'Zachary/zachary.edgelist',datadir+'Zachary/zachary.ecg','_embed')\n",
    "    ## keep track of best and worst embeddings\n",
    "    if jsd < best_jsd:\n",
    "        os.system('cp _embed _embed_best')\n",
    "        best_jsd = jsd\n",
    "    if jsd > worst_jsd:\n",
    "        os.system('cp _embed _embed_worst')\n",
    "        worst_jsd = jsd\n",
    "    L.append([dim,'le',' ',jsd])\n",
    "    \n",
    "## node2vec \n",
    "## we try a few choices for p and q, parameters for the random walks\n",
    "## on some platforms, we got better results with longer random walks (code commented out below)\n",
    "for dim in DIM:\n",
    "    for (p,q) in [(1,0.5),(0.5,1),(1,1)]:\n",
    "        ## long walks:\n",
    "        #x = n2v + ' -i:'+datadir+'Zachary/zachary.edgelist -o:_embed -d:'+str(dim)+' -p:'+str(p)+' -q:'+str(q)\n",
    "        ## short walks (10-long):\n",
    "        x = n2v + ' -l:10 -i:'+datadir+'Zachary/zachary.edgelist -o:_embed -d:'+str(dim)+' -p:'+str(p)+' -q:'+str(q)\n",
    "        r = os.system(x+' >/dev/null 2>&1')\n",
    "        jsd = JS(datadir+'Zachary/zachary.edgelist',datadir+'Zachary/zachary.ecg','_embed')\n",
    "\n",
    "        ## keep track of best and worst embeddings\n",
    "        if jsd < best_jsd:\n",
    "            os.system('cp _embed _embed_best')\n",
    "            best_jsd = jsd\n",
    "        if jsd > worst_jsd:\n",
    "            os.system('cp _embed _embed_worst')\n",
    "            worst_jsd = jsd\n",
    "        \n",
    "        ## store results\n",
    "        L.append([dim,'n2v',str(p)+' '+str(q),jsd])\n",
    "\n",
    "## store results in dataframe, show top results w.r.t. JS divergence (lower is better)        \n",
    "D = pd.DataFrame(L,columns=['dim','algo','param','jsd'])\n",
    "D = D.sort_values(by='jsd',axis=0)\n",
    "D.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot top results\n",
    "os.system('cp _embed_best _embed')\n",
    "l = embed2layout()\n",
    "zac.vs['ly'] = [l[int(v['name'])] for v in zac.vs]\n",
    "#ig.plot(z, 'zac_high.eps', layout=z.vs['ly'], bbox=(0,0,300,200))\n",
    "ig.plot(zac,layout=zac.vs['ly'], bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## results with largest JS divergence\n",
    "D.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot result with largest divergence\n",
    "os.system('cp _embed_worst _embed')\n",
    "l = embed2layout()\n",
    "zac.vs['ly'] = [l[int(v['name'])] for v in zac.vs]\n",
    "#ig.plot(zac, 'zac_high.eps', layout=z.vs['ly'], bbox=(0,0,300,200))\n",
    "ig.plot(zac,layout=zac.vs['ly'], bbox=(0,0,300,200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate several embeddings -- small ABCD  graph\n",
    "\n",
    "This is the same exercise as what we did above, this time for the 100-nodes ABCD graph.\n",
    "We look at slightly higher embedding dimensions as there are more nodes than the Zachary graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = []\n",
    "DIM = [2,4,8,16,24,32] ## embedding dimensions\n",
    "best_jsd = 1           ## keep track of best result\n",
    "worst_jsd = 0          ## and worst\n",
    "\n",
    "## Hope with different choices for the similarity\n",
    "for dim in DIM:\n",
    "    for sim in ['katz','aa','cn','ppr']:\n",
    "        X = Hope(abcd,sim=sim,dim=dim) \n",
    "        saveEmbedding(X,abcd)\n",
    "        jsd = JS(datadir+'ABCD/abcd_100.dat',datadir+'ABCD/abcd_100.ecg','_embed')\n",
    "        ## keep track of best and worst\n",
    "        if jsd < best_jsd:\n",
    "            os.system('cp _embed _embed_best')\n",
    "            best_jsd = jsd\n",
    "        if jsd > worst_jsd:\n",
    "            os.system('cp _embed _embed_worst')\n",
    "            worst_jsd = jsd\n",
    "        L.append([dim,'hope',sim,jsd])\n",
    "\n",
    "## Laplacian Eigenmap\n",
    "for dim in DIM:\n",
    "    X = LE(abcd,dim=dim)\n",
    "    saveEmbedding(X,abcd)\n",
    "    jsd = JS(datadir+'ABCD/abcd_100.dat',datadir+'ABCD/abcd_100.ecg','_embed')\n",
    "    ## keep track of best and worst\n",
    "    if jsd < best_jsd:\n",
    "        os.system('cp _embed _embed_best')\n",
    "        best_jsd = jsd\n",
    "    if jsd > worst_jsd:\n",
    "        os.system('cp _embed _embed_worst')\n",
    "        worst_jsd = jsd\n",
    "    L.append([dim,'le',' ',jsd])\n",
    "    \n",
    "## node2vec \n",
    "## we try a few choices for p and q, parameters for the random walks\n",
    "## on some platforms, we got better results with longer random walks (code commented out below)for dim in DIM:\n",
    "    for (p,q) in [(1,0.1),(1,.5),(0.1,1),(.5,1),(1,1)]:\n",
    "        ## long walks:\n",
    "        #x = n2v + ' -i:'+datadir+'ABCD/abcd_100.dat -o:_embed -d:'+str(dim)+' -p:'+str(p)+' -q:'+str(q)\n",
    "        ## short walks:\n",
    "        x = n2v + ' -l:15 -i:'+datadir+'ABCD/abcd_100.dat -o:_embed -d:'+str(dim)+' -p:'+str(p)+' -q:'+str(q)\n",
    "        r = os.system(x+' >/dev/null 2>&1')\n",
    "        jsd = JS(datadir+'ABCD/abcd_100.dat',datadir+'ABCD/abcd_100.ecg','_embed')\n",
    "        ## keep track of best and worst\n",
    "        if jsd < best_jsd:\n",
    "            os.system('cp _embed _embed_best')\n",
    "            best_jsd = jsd\n",
    "        if jsd > worst_jsd:\n",
    "            os.system('cp _embed _embed_worst')\n",
    "            worst_jsd = jsd\n",
    "        L.append([dim,'n2v',str(p)+' '+str(q),jsd])\n",
    "\n",
    "## store in dataframe and show best results        \n",
    "D = pd.DataFrame(L,columns=['dim','algo','param','jsd'])\n",
    "D = D.sort_values(by='jsd',axis=0)\n",
    "D.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot result with lowest JS divergence\n",
    "os.system('cp _embed_best _embed')\n",
    "l = embed2layout()\n",
    "abcd.vs['ly'] = [l[int(v['name'])-1] for v in abcd.vs]\n",
    "ig.plot(abcd, layout=abcd.vs['ly'], bbox=(0,0,300,200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## results with high divergence\n",
    "D.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot result with high divergence\n",
    "os.system('cp _embed_worst _embed')\n",
    "l = embed2layout()\n",
    "abcd.vs['ly'] = [l[int(v['name'])-1] for v in abcd.vs]\n",
    "ig.plot(abcd, layout=abcd.vs['ly'], bbox=(0,0,300,200))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on larger ABCD graph\n",
    "\n",
    "We saw that embedding can be used to visualize graphs. Below we use graph embedding as a way to define a feature vector (point in vector space) for each node, and we use this representation to train a classifier.\n",
    "We use a saved embedding (48-dimension running HOPE with 'ppr' similarity).\n",
    "\n",
    "We split the data (the nodes) into a training and testing set. Using the training set, we build a random forest classification model where the classes are the communities for each node.\n",
    "\n",
    "We then apply this model to the test set.\n",
    "\n",
    "The graph has 1000 nodes; we use 250 for training and the rest for testing; we obtain good accuracy (around 90%).\n",
    "What do you think will happen if we increase/decrease the size of the training set?\n",
    "\n",
    "WE also report the confusion matrix (details in section 6.5 of the book).\n",
    "\n",
    "Finally, we compare with results obtained via a random classifier where we supply the correct number of classes only, or the number and relative sizes for the classes.\n",
    "\n",
    "We see that our random forest model gives much better results that with a random classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load a saved embedding for ABCD graph\n",
    "X = readEmbedding(fn=datadir+\"ABCD/abcd_1000_embed_best\")\n",
    "y = ABCD.vs['comm']\n",
    "\n",
    "## train/test split\n",
    "np.random.seed(1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')\n",
    "# Fit on training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Class predictions on test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "## percent correct -- this can vary slightly as we split train/test randomly\n",
    "print('\\naccuracy:',sum(cm.diagonal())/sum(sum(cm)),'\\n')\n",
    "#print(bmatrix(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare with random classifier -- assuming we know only the number of classes (12)\n",
    "acc = []\n",
    "for rep in range(30): ## repeat 30 times, we'll take average\n",
    "    y_pred = [x+1 for x in np.random.choice(12,size=len(y_test),replace=True)]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc.append(sum(cm.diagonal())/sum(sum(cm)))\n",
    "## accuracy\n",
    "print('\\nAverage accuracy:',np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare with random classifier -- using class proportions in training data\n",
    "ctr = Counter(y_train)\n",
    "x = [ctr[i+1] for i in range(12)]\n",
    "s = np.sum(x)\n",
    "p = [i/s for i in x]\n",
    "acc = []\n",
    "for rep in range(30): ## repeat 30 times, we'll take average\n",
    "    y_pred = [x+1 for x in np.random.choice(12,size=len(y_test),replace=True,p=p)]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc.append(sum(cm.diagonal())/sum(sum(cm)))\n",
    "## accuracy\n",
    "print('\\nAverage accuracy:',np.mean(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering in embedded space\n",
    "\n",
    "Again using the larger ABCD graph, we run some graph clustering algorithms (Louvain and ECG).\n",
    "We run each algorithm several times are report two statistics:\n",
    "* the modularity score of the clustering, and\n",
    "* the adjusted mutual information (AMI) score when comparing with ground-truth (GT) communities.\n",
    "\n",
    "We do the same this also with the clusters obtained when running k-means (with 5 choices for k) in embedded vector space. \n",
    "We use the same saved embedding than in the previous experiment. \n",
    "This time, we report:\n",
    "* the CHS score (Calinski and Harabasz score, or Variance Ratio Criterion)\n",
    "* the adjusted mutual information (AMI) score when comparing with ground-truth (GT) communities.\n",
    "\n",
    "In practical applications where we do not have access to the ground-truth, we need some other measure to quantify the quality of the clusters we obtain, such as modularity or CHS. We report AMI for runs with highest score (modularity or CHS) for the 3 clustering algorithms.\n",
    "\n",
    "The cell below can take a few minutes to run. You can decrease the number of repeats (REP) for faster results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the saved embedding\n",
    "X = readEmbedding(fn=datadir+\"ABCD/abcd_1000_embed_best\")\n",
    "\n",
    "L = [] ## to store results\n",
    "K = [6,9,12,15,24] ## for k-means (real number of clusters is 12)\n",
    "REP = 30 ## number of repeats; decrease for faster run\n",
    "\n",
    "for i in range(REP):\n",
    "    \n",
    "    ## run kmeans\n",
    "    for k in K:\n",
    "        cl = KMeans(n_clusters=k, n_init=10).fit(X)\n",
    "        d = {k:v for k,v in enumerate(cl.labels_)}\n",
    "        scr = CHS(X,cl.labels_) ## CHS\n",
    "        ami = AMI(list(GT.values()),list(d.values())) ## AMI vs ground truth\n",
    "        L.append(['km'+str(k),scr,ami])\n",
    "\n",
    "    ## ECG\n",
    "    ec = ABCD.community_ecg().membership\n",
    "    scr = ABCD.modularity(ec) ## modularity\n",
    "    ami = AMI(list(GT.values()),ec) ## AMI vs ground truth\n",
    "    L.append(['ecg',scr,ami])\n",
    "    \n",
    "    ## Louvain -- permute as this is not done in igraph, so we get different results for each repeat\n",
    "    p = np.random.permutation(ABCD.vcount()).tolist()\n",
    "    GG = ABCD.permute_vertices(p)\n",
    "    l = GG.community_multilevel().membership\n",
    "    ll = [-1]*len(l)\n",
    "    for i in range(len(l)):\n",
    "        ll[i] = l[p[i]]\n",
    "    scr = ABCD.modularity(ll) ## modularity\n",
    "    ami = AMI(list(GT.values()),ll) ## AMI vs ground truth\n",
    "    L.append(['ml',scr,ami])\n",
    "\n",
    "## store in dataframe\n",
    "D = pd.DataFrame(L,columns=['algo','scr','ami'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AMI results with best scoring clustering for the 3 algorithms\n",
    "x = list(D[[x.startswith('km') for x in D['algo']]].sort_values(by='scr',ascending=False)['ami'])[0]\n",
    "print('K-Means AMI:',x)\n",
    "\n",
    "x = list(D[D['algo']=='ml'].sort_values(by='scr',ascending=False)['ami'])[0]\n",
    "print('Louvain AMI:',x)\n",
    "\n",
    "x = list(D[D['algo']=='ecg'].sort_values(by='scr',ascending=False)['ami'])[0]\n",
    "print('ECG AMI:',x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we summarize the results for all runs in a boxplot. \n",
    "Results with k-means are best when we supply the correct number of clusters (12). \n",
    "We also see the high variability when using Louvain instead of ECG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## boxplot the AMI results \n",
    "A = []\n",
    "algo = ['km6','km9','km12','km15','km24','ml','ecg']\n",
    "for a in algo:\n",
    "    A.append(D[D['algo']==a]['ami'])\n",
    "\n",
    "B = pd.DataFrame(np.transpose(A), \n",
    "                 columns=['k-means(6)','k-means(9)','k-means(12)','k-means(15)',\n",
    "                          'k-means(24)','Louvain','ECG'])\n",
    "B.boxplot(rot=30,figsize=(7,5))\n",
    "plt.ylabel('Adjusted Mutual Information (AMI)');\n",
    "#plt.savefig('embed_cluster.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we cluster using the DBSCAN algorithm after reducing the dimension via UMAP.\n",
    "We found that running a good dimension reduction algorithm before clustering often gives better results.\n",
    "This is for illustration and\n",
    "you can experiment with different choices of parameter below as well as diffferent clustering algorithms.\n",
    "\n",
    "DBSCAN does not always cluster all the points, which can be quite useful in practice. Some points can be tagged as \"outliers\". Below, we compute AMI with and without the outlying points. \n",
    "Result without outliers is quite good (recall that unlike k-mens, we do not supply the number of communities here).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## DBSCAN -- we tried a few 'min_sample' and 'dim' below\n",
    "## with good results using 8 and 16 resp.\n",
    "## we try various 'eps' and pick the best via calinski_harabasz_score (CHS)\n",
    "top = 0\n",
    "for dim in [16]: ## reduce to this dimension\n",
    "    for ms in [8]: ## min-sample in DBSCAN\n",
    "        U = umap.UMAP(n_components=dim).fit_transform(X)\n",
    "        for e in np.arange(.4,.5,.0025): ## try different values for epsilon\n",
    "            cl = DBSCAN(eps=e, min_samples=ms ).fit(U)\n",
    "            labels = cl.labels_\n",
    "            s = CHS(U,labels) ## CHS score\n",
    "            if s > top:\n",
    "                top=s\n",
    "                e_top=e\n",
    "                d_top=dim\n",
    "                m_top=ms\n",
    "\n",
    "## result with best CHS score\n",
    "U = umap.UMAP(n_components=d_top).fit_transform(X) \n",
    "cl = DBSCAN(eps=e_top, min_samples=m_top).fit(U)\n",
    "\n",
    "b = [x>-1 for x in cl.labels_]\n",
    "l = list(GT.values())\n",
    "v = [l[i] for i in range(len(l)) if b[i]]\n",
    "print('AMI without outliers:',AMI(v,cl.labels_[b]))\n",
    "print('AMI with outliers:',AMI(list(GT.values()),cl.labels_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction\n",
    "\n",
    "Given a graph, link prediction aims at finding pairs of nodes not linked by an edge that are the most likely to actually have an edge between them. This could happen if we have a partial view of a graph, for example if edges \n",
    "are observed over some period of time, which new edges are we most likely to observe next?\n",
    "\n",
    "In order to simulate this situation, we take the ABCD graph with 1,000 nodes and drop 10% of the edges.\n",
    "We re-compute the embedding (since the graph has changed), train a logistic regression model using pairs\n",
    "of nodes with and without an edge, and apply the model to a test set consisting of the dropped edges, and other \n",
    "pairs of nodes not linked by an edge.\n",
    "\n",
    "First we try with the current ABCD graph with noise parameter $\\xi=0.6$.\n",
    "Given the large number of \"noise\" edges, results are not very good, as expected.\n",
    "\n",
    "We do another test this time with another ABCD graph with $\\xi=0.2$, with much better results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link prediction with noisy ABCD graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pick 10% edges at random, save new graph as Gp\n",
    "test_size = int(np.round(.1*ABCD.ecount()))\n",
    "np.random.seed(123456)\n",
    "test_eid = np.random.choice(ABCD.ecount(),size=test_size,replace=False)\n",
    "Gp = ABCD.copy()\n",
    "Gp.delete_edges(test_eid)\n",
    "\n",
    "## are there zero-degree nodes in this subgraph?\n",
    "print('min degree:',np.min(Gp.degree()))\n",
    "\n",
    "## compute embedding on Gp with parameters that yielded a good embedding for G\n",
    "X = Hope(Gp, sim='ppr', dim=48)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a classifier, we take pairs of nodes (some with edge, some without) and we merge the embedding vectors for those 2 nodes using some binary operator. This generates a feature vector for each pair of nodes we consider.\n",
    "\n",
    "We build the training data by considering all edges in the subgraph, and an equal number of node pairs without an edge.\n",
    "\n",
    "From this data, we build a logistic regression model to predict edges vs non-edges.\n",
    "\n",
    "We then apply the model to the test set which includes the dropped edges, and the same number of non-edges.\n",
    "\n",
    "We report the accuracy and AUC (area under the ROC curve). \n",
    "Results are better than random, but not great; recall that $\\xi$=0.6, so the majority of edges are noise to start with, so link prediction is very hard in this case. We try with less noisy graph next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model with Hadamard binary operator (other choices are 'l1', 'l2 and 'avg')\n",
    "op = 'had'\n",
    "\n",
    "## Build training data, first the edges\n",
    "F = []\n",
    "for e in Gp.es:\n",
    "    F.append(binary_operator(X[e.tuple[0]],X[e.tuple[1]],op=op))\n",
    "size = len(F)\n",
    "f = [1]*size\n",
    "\n",
    "## then for equal number of non-edges (we over-sample to drop edges or collisions from the list)\n",
    "## nb: those could include some of the dropped edges, but avoiding those would not be realistic \n",
    "e = [tuple(np.random.choice(Gp.vcount(),size=2,replace=False)) for i in range(2*size)]\n",
    "e = [(min(x),max(x)) for x in e if Gp.get_eid(x[0],x[1],directed=False,error=False) == -1]\n",
    "non_edges = list(set(e))[:size]\n",
    "for e in non_edges:\n",
    "    F.append(binary_operator(X[e[0]],X[e[1]],op=op))\n",
    "F = np.array(F)\n",
    "f.extend([0]*size)\n",
    "\n",
    "## train the model, here a logistic regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(F,f)\n",
    "\n",
    "## prepare test set, first with all dropped edges from G \n",
    "X_test = []\n",
    "for i in test_eid:\n",
    "    e = ABCD.es[i]\n",
    "    X_test.append(binary_operator(X[e.tuple[0]],X[e.tuple[1]],op=op))\n",
    "size = len(X_test)\n",
    "y_test = [1]*size\n",
    "\n",
    "## then for equal number of non-edges (we over-sample to drop edges and collisions from the list)\n",
    "e = [tuple(np.random.choice(ABCD.vcount(),size=2,replace=False)) for i in range(2*size)]\n",
    "e = [(min(x),max(x)) for x in e if ABCD.get_eid(x[0],x[1],directed=False,error=False) == -1]\n",
    "non_edges = list(set(e))[:size]\n",
    "for e in non_edges:\n",
    "    X_test.append(binary_operator(X[e[0]],X[e[1]],op=op))\n",
    "X_test = np.array(X_test)\n",
    "y_test.extend([0]*size)\n",
    "\n",
    "## apply the model to test data\n",
    "print('Accuracy of logistic regression classifier with',op,'on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "print('AUC:',roc_auc_score(y_test, logreg.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link prediction with less noisy ABCD graph\n",
    "\n",
    "Same as above, but with ABCD graph with $\\xi=0.2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read graph and communities - graph with xi=0.2\n",
    "ABCD2 = ig.Graph.Read_Ncol(datadir+'ABCD/abcd_1000_xi2.dat',directed=False)\n",
    "c = np.loadtxt(datadir+'ABCD/abcd_1000_xi2_comms.dat',dtype='uint16',usecols=(1))\n",
    "ABCD2.vs['comm'] = [c[int(x['name'])-1] for x in ABCD2.vs]\n",
    "\n",
    "## pick 10% edges at random, save new graph as Gp\n",
    "test_size = int(np.round(.1*ABCD2.ecount()))\n",
    "np.random.seed(123456) ## for reproducibility\n",
    "test_eid = np.random.choice(ABCD2.ecount(),size=test_size,replace=False)\n",
    "Gp = ABCD2.copy()\n",
    "Gp.delete_edges(test_eid)\n",
    "\n",
    "## are there zero-degree nodes in this subgraph?\n",
    "print('min degree:',np.min(Gp.degree()))\n",
    "\n",
    "## compute embedding on Gp with same parameters as above\n",
    "X = Hope(Gp,sim='ppr', dim=48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train model with Hadamard binary operator (other choices are 'l1', 'l2 and 'avg')\n",
    "op = 'had'\n",
    "\n",
    "## Build training data, first the edges\n",
    "F = []\n",
    "for e in Gp.es:\n",
    "    F.append(binary_operator(X[e.tuple[0]],X[e.tuple[1]],op=op))\n",
    "size = len(F)\n",
    "f = [1]*size\n",
    "\n",
    "## then for equal number of non-edges (we over-sample to drop edges and collisions from the list)\n",
    "e = [tuple(np.random.choice(Gp.vcount(),size=2,replace=False)) for i in range(2*size)]\n",
    "e = [(min(x),max(x)) for x in e if Gp.get_eid(x[0],x[1],directed=False,error=False) == -1]\n",
    "non_edges = list(set(e))[:size]\n",
    "for e in non_edges:\n",
    "    F.append(binary_operator(X[e[0]],X[e[1]],op=op))\n",
    "F = np.array(F)\n",
    "f.extend([0]*size)\n",
    "\n",
    "## train model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(F,f)\n",
    "\n",
    "## prepare test set, first with all dropped edges from G \n",
    "X_test = []\n",
    "for i in test_eid:\n",
    "    e = ABCD2.es[i]\n",
    "    X_test.append(binary_operator(X[e.tuple[0]],X[e.tuple[1]],op=op))\n",
    "size = len(X_test)\n",
    "y_test = [1]*size\n",
    "\n",
    "## then for equal number of non-edges (we over-sample to drop edges and collisions from the list)\n",
    "e = [tuple(np.random.choice(ABCD2.vcount(),size=2,replace=False)) for i in range(2*size)]\n",
    "e = [(min(x),max(x)) for x in e if ABCD2.get_eid(x[0],x[1],directed=False,error=False) == -1]\n",
    "non_edges = list(set(e))[:size]\n",
    "for e in non_edges:\n",
    "    X_test.append(binary_operator(X[e[0]],X[e[1]],op=op))\n",
    "X_test = np.array(X_test)\n",
    "y_test.extend([0]*size)\n",
    "\n",
    "## apply the model to test data\n",
    "print('Accuracy of logistic regression classifier with',op,'on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "print('AUC:',roc_auc_score(y_test, logreg.predict_proba(X_test)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are much better in this case. Below we plot the ROC curve; the dashed line is the expected random case, which yields AUC = 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='gray',label='Logistic Regression (AUC = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('embed_link.eps')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger study -- use classification accuracy for comparing embeddings\n",
    "\n",
    "We saw earlier an **unsupervised** method for selecting good graph embeddings where we computed some divergence score. In **supervised** case, it is usually better to take advantage of the known labels to compare embeddings.\n",
    "With this larger experiment, we do the following using the 1,000 nodes ABCD graph. Recall that in this case, the class is the ground-truth community for each node. \n",
    "\n",
    "* we partition the nodes into training, validation and test sets in proportion 25%/25%/50%\n",
    "* we generate 70 different embeddings (3 algorithms, different parameters)\n",
    "* from each embedding, \n",
    " * we compute the JS divergence (unsupervised score)\n",
    " * we use the training data to build a classification model (random forest)\n",
    " * we apply this model to the validation set \n",
    " * we compute the accuracy score (supervised score) \n",
    "\n",
    "The code to do this is commented out in the cell below as this can take several minutes to run. \n",
    "A pickle file with the results is included in data directory and can be read directly.\n",
    "If you re-run from scratch, the results can differ slightly due to non-deterministic algorithms like node2vec.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# train/val/test, split the id's in proportion 25/25/50\n",
    "np.random.seed(1)\n",
    "ids = [i for i in range(ABCD.vcount())]\n",
    "id_trainval, id_test = train_test_split(ids, test_size=.5)     ## split test\n",
    "id_train, id_val = train_test_split(id_trainval, test_size=.5) ## split train/val\n",
    "\n",
    "y_all = ABCD.vs['comm']\n",
    "y_train = [y_all[i] for i in id_train]\n",
    "y_trainval = [y_all[i] for i in id_trainval]\n",
    "y_val = [y_all[i] for i in id_val]\n",
    "y_test = [y_all[i] for i in id_test]\n",
    "\n",
    "## loop over several algos, parameters\n",
    "L = []\n",
    "DIM = [2,4,8,16,24,32,48]\n",
    "\n",
    "## LE\n",
    "for dim in DIM:\n",
    "    print(dim)\n",
    "    X = LE(ABCD, dim=dim)\n",
    "    X_train = X[id_train,:]\n",
    "    X_val = X[id_val,:]\n",
    "    saveEmbedding(X,ABCD)\n",
    "    jsd = JS(datadir+'ABCD/abcd_1000.dat',datadir+'ABCD/abcd_1000.ecg','_embed')\n",
    "\n",
    "    # Create the model with 100 trees\n",
    "    model = RandomForestClassifier(n_estimators=100, \n",
    "                                   bootstrap = True,\n",
    "                                   max_features = 'sqrt')\n",
    "    # Fit on training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Actual class predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "    scr = accuracy_score(y_val,y_pred)\n",
    "    L.append([dim,'le',0,jsd,scr])    \n",
    "    \n",
    "## HOPE\n",
    "for dim in DIM:\n",
    "    print(dim)\n",
    "    for sim in ['katz','aa','cn','ppr']:    \n",
    "        X = Hope(ABCD,sim=sim,dim=dim) \n",
    "        X_train = X[id_train,:]\n",
    "        X_val = X[id_val,:]\n",
    "        saveEmbedding(X,ABCD)\n",
    "        jsd = JS(datadir+'ABCD/abcd_1000.dat',datadir+'ABCD/abcd_1000.ecg','_embed')\n",
    "\n",
    "        # Create the model with 100 trees\n",
    "        model = RandomForestClassifier(n_estimators=100, \n",
    "                                       bootstrap = True,\n",
    "                                       max_features = 'sqrt')\n",
    "        # Fit on training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Actual class predictions\n",
    "        y_pred = model.predict(X_val)\n",
    "        scr = accuracy_score(y_val,y_pred)\n",
    "        L.append([dim,'hope',sim,jsd,scr])\n",
    "\n",
    "## node2vec\n",
    "## node2vec in your path\n",
    "for dim in DIM:\n",
    "    print(dim)\n",
    "    for (p,q) in [(1,0.01),(1,.5),(0.01,1),(.5,1),(1,1)]:\n",
    "        ## use shorter paths if unstable\n",
    "        x = n2v + ' -l:25 -i:'+datadir+'ABCD/abcd_1000.dat -o:_embed -d:'+str(dim)+' -p:'+str(p)+' -q:'+str(q)+' >_out'\n",
    "        r = os.system(x)\n",
    "        X = readEmbedding(N2K=N2K)\n",
    "        jsd = JS(datadir+'ABCD/abcd_1000.dat',datadir+'ABCD/abcd_1000.ecg','_embed')\n",
    "        X_train = X[id_train,:]\n",
    "        X_val = X[id_val,:]\n",
    "        # Create the model with 100 trees\n",
    "        model = RandomForestClassifier(n_estimators=100, \n",
    "                                       bootstrap = True,\n",
    "                                       max_features = 'sqrt')\n",
    "\n",
    "        # Fit on training data\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Actual class predictions\n",
    "        y_pred = model.predict(X_val)\n",
    "        scr = accuracy_score(y_val,y_pred)\n",
    "        L.append([dim,'n2v',str(p)+' '+str(q),jsd,scr])\n",
    "\n",
    "## save L and train/val/test ids\n",
    "pickle.dump( (id_train,id_val,id_trainval,id_test,L), open( datadir+\"ABCD/abcd_1000_embeddings.pkl\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load results from pickle file\n",
    "with open(datadir+\"ABCD/abcd_1000_embeddings.pkl\",\"rb\") as f:\n",
    "    id_train,id_val,id_trainval,id_test,L = pickle.load(f)\n",
    "\n",
    "## labels for train/validation/test sets\n",
    "y_all = ABCD.vs['comm']\n",
    "y_train = [y_all[i] for i in id_train]\n",
    "y_trainval = [y_all[i] for i in id_trainval] ## training+validation sets\n",
    "y_val = [y_all[i] for i in id_val]\n",
    "y_test = [y_all[i] for i in id_test]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we compute the rank-based  Kendall-tau correlation between the divergence score (unsupervised) and the accuracy score (supervised). We see negative correlation which is to be expected since respectively low divergence and high accuracy are better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation: divergence and accuracy\n",
    "R = pd.DataFrame(L,columns=['dim','algo','param','div','acc'])\n",
    "from scipy.stats import kendalltau as tau\n",
    "print(tau(R['div'],R['acc']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next 2 cells, we show the top results on the validation set respectively for the divergence and accuracy scores. We also add two columns with the respective ranks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort by JS-divergence on validation set\n",
    "R = R.sort_values(by='div',axis=0,ascending=True)\n",
    "size = R.shape[0]\n",
    "R['rank_div'] = np.arange(1,size+1,1)\n",
    "R.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort by Accuracy on validation set\n",
    "R = R.sort_values(by='acc',axis=0,ascending=False)\n",
    "size = R.shape[0]\n",
    "R['rank_acc'] = np.arange(1,size+1,1)\n",
    "R.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show the lowest accuracy results. We see that there is quite a range of accuracy on the validation set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Apply the models to the test set. \n",
    "\n",
    "In the previous cells, we built a table ranking the different algorithms w.r.t. accuracy and divergence using the training and validation sets. Here, we go through the same algorithms in (decreasing) order of accuracy, re-train with each model using the training and validation sets, and apply to the test set.\n",
    "\n",
    "This takes several minutes to run so a pickle file is provided with the results.\n",
    "\n",
    "Uncomment the cell below to re-run; results can differ in that case due to non-deterministic algorithms like node2vec"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## retrain and score in order of validation set's accuracy\n",
    "top_acc = []\n",
    "for i in range(size):\n",
    "    print(i+1, 'out of', size)\n",
    "    dim, algo, param, div, acc, rk_a, rk_d = R.iloc[i]\n",
    "    if algo=='n2v':\n",
    "        s = param.split()\n",
    "        p = float(s[0])\n",
    "        q = float(s[1])\n",
    "        ## use shorter paths if unstable\n",
    "        x = n2v + ' -l:25 -i:'+datadir+'ABCD/abcd_1000.dat -o:_embed -d:'+str(dim)+' -p:'+str(p)+' -q:'+str(q)+' >_out'\n",
    "        r = os.system(x)\n",
    "        X = readEmbedding(N2K=N2K)\n",
    "    if algo=='hope':\n",
    "        X = Hope(ABCD,sim=param,dim=dim)\n",
    "    if algo=='le':\n",
    "        X = LE(ABCD, dim=dim)\n",
    "        \n",
    "    X_trainval = X[id_trainval,:]\n",
    "    X_test = X[id_test,:]\n",
    "    # Create the model with 100 trees\n",
    "    model = RandomForestClassifier(n_estimators=100, \n",
    "                                   bootstrap = True,\n",
    "                                   max_features = 'sqrt')\n",
    "    # Fit on training data\n",
    "    model.fit(X_trainval, y_trainval)\n",
    "\n",
    "    # Actual class predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    scr = accuracy_score(y_test,y_pred)\n",
    "    top_acc.append(scr)\n",
    "\n",
    "pickle.dump( top_acc, open( datadir+\"ABCD/abcd_1000_embeddings_test.pkl\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load test results\n",
    "with open(datadir+\"ABCD/abcd_1000_embeddings_test.pkl\",\"rb\") as f:\n",
    "    top_acc = pickle.load(f)\n",
    "R['test'] = top_acc\n",
    "print('mean accuracy over all models on the test set:',np.mean(R['test']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## top results w.r.t. accuracy on the test set\n",
    "R = R.sort_values(by='test',axis=0,ascending=False)\n",
    "R['rank_test'] = np.arange(1,size+1,1)\n",
    "R.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we take the top-10 algorithms w.r.t. divergence on the validation set, and the top-10 algorithms w.r.t. accuracy on the valudation set. We then plot the distribution of results (accuracy) over the test set via box-plots.\n",
    "\n",
    "As expected, using accuracy (supervised score) yields better results, but the results obtained with the (unsupervised) divergence score are also quite good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R['test'].loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## top results on test set w.r.t. divergence on validation set\n",
    "R = R.sort_values(by='div',axis=0,ascending=True)\n",
    "top_div = R['test'].iloc[:10]\n",
    "\n",
    "## top results on test set w.r.t. accuracy on validation set\n",
    "R = R.sort_values(by='acc',axis=0,ascending=False)\n",
    "top_acc = R['test'].iloc[:10]\n",
    "\n",
    "## pd with mu\n",
    "B = pd.DataFrame(np.transpose(np.array([top_acc,top_div])), \n",
    "                 columns=['Top-10 validation set accuracy','Top-10 divergence score'])\n",
    "B.boxplot(rot=0,figsize=(7,5), widths=.33)\n",
    "plt.ylabel('Test set accuracy',fontsize=14);\n",
    "#plt.savefig('embed_classify.eps')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to compare the results is to plot the accuracy results on the test set as a function of the rank of the algorithms w.r.t. the accuracy score on the validation set (next cell) or the divergence score on the validation set (second next cell).\n",
    "\n",
    "The correlation is very clear in the first case, and is still quite strong in the second case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(R['rank_acc'],R['test'],'.',color='black')\n",
    "plt.xlabel('Rank',fontsize=14)\n",
    "plt.ylabel('Test set accuracy',fontsize=14);\n",
    "#plt.savefig('rank_accuracy.eps');\n",
    "print('correlation:',np.corrcoef(R['rank_acc'],R['test'])[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(R['rank_div'],R['test'],'.',color='black')\n",
    "plt.xlabel('Rank',fontsize=14)\n",
    "plt.ylabel('Test set accuracy',fontsize=14);\n",
    "#plt.savefig('rank_divergence.eps');\n",
    "print('correlation:',np.corrcoef(R['rank_div'],R['test'])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compare with accuracy obtained with a random classifier, averaging over several runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random classification\n",
    "ctr = Counter(y_trainval)\n",
    "x = [ctr[i+1] for i in range(12)]\n",
    "s = np.sum(x)\n",
    "p = [i/s for i in x]\n",
    "acc = []\n",
    "for rep in range(30):\n",
    "    y_pred = [x+1 for x in np.random.choice(12,size=len(y_test),replace=True,p=p)]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc.append(sum(cm.diagonal())/sum(sum(cm)))\n",
    "print('\\nRandom classifier average accuracy on test set:',np.mean(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReFex: illustrate roles on Zachary graph\n",
    "\n",
    "We use the 'graphrole' package here. There are two steps (details in section 6.7 of the book):\n",
    "* extract node features recursively (ReFeX)\n",
    "* apply non-neg. matrix factorization to recover different roles in the graph (RolX)\n",
    "We use 3 dimensions for the RolX step. \n",
    "\n",
    "Results shos that the 3 roles correspond roughly to: hub nodes, peripherial nodes and nodes in-between those.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract features\n",
    "feature_extractor = RecursiveFeatureExtractor(zac, max_generations=4)\n",
    "features = feature_extractor.extract_features()\n",
    "print(f'\\nFeatures extracted from {feature_extractor.generation_count} recursive generations:')\n",
    "features.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign node roles in a dictionary\n",
    "role_extractor = RoleExtractor(n_roles=3)\n",
    "role_extractor.extract_role_factors(features)\n",
    "node_roles = role_extractor.roles\n",
    "role_extractor.role_percentage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "unique_roles = sorted(set(node_roles.values()))\n",
    "# uncomment for color plot\n",
    "# cls = ['red','blue','green']\n",
    "# map roles to colors\n",
    "role_colors = {role: cls[i] for i, role in enumerate(unique_roles)}\n",
    "\n",
    "# store colors for all nodes in G\n",
    "zac.vs()['color'] = [role_colors[node_roles[node]] for node in range(zac.vcount())]\n",
    "\n",
    "## Plot with node labels\n",
    "zac.vs()['size'] = 10\n",
    "#z.vs()['label'] = [v.index for v in z.vs()]\n",
    "zac.vs()['label_size'] = 0\n",
    "#ig.plot(z, 'refex.eps', bbox=(0,0,300,300)) \n",
    "ig.plot(zac, bbox=(0,0,300,300)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New dataset -- American College Football Graph\n",
    "\n",
    "This is a nice, small graph for illustrating anomaly detection methods.\n",
    "The graph consists of 115 US college football teams (nodes) playing games (edges).\n",
    "\n",
    "Teams are part of 12 conferences (the 'communities'):\n",
    "*   0 = Atlantic Coast\n",
    "*   1 = Big East\n",
    "*   2 = Big Ten\n",
    "*   3 = Big Twelve\n",
    "*   4 = Conference USA\n",
    "*   5 = Independents\n",
    "*   6 = Mid-American\n",
    "*   7 = Mountain West\n",
    "*   8 = Pacific Ten\n",
    "*   9 = Southeastern\n",
    "*  10 = Sun Belt\n",
    "*  11 = Western Athletic\n",
    "\n",
    "14 teams out of 115 appear as \"anomalies\" as can be seen in Figure 5 of [REF], namely:\n",
    "- 5 teams in #5 conference (Independent) play teams in other conferences (green triangles in plot below)\n",
    "- 7 teams in #10 conference (Sun Belt) are broken in 2 clumps (pink triangles in plot below) \n",
    "- 2 teams from #11 conference play mainly with #10 conference (red triangles below)\n",
    "\n",
    "[REF]: \"Community structure in social and biological networks\", M. Girvan and M. E. J. Newman\n",
    "PNAS June 11, 2002 99 (12) 7821-7826; https://doi.org/10.1073/pnas.122653799\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read graph and communities\n",
    "cfg = ig.Graph.Read_Ncol(datadir+'Football/football.edgelist',directed=False)\n",
    "c = np.loadtxt(datadir+'Football/football.community',dtype='uint16',usecols=(0))\n",
    "cfg.vs['community'] = [c[int(x['name'])] for x in cfg.vs]\n",
    "\n",
    "## plot the College Football Graph\n",
    "## show communities in dfferent colors\n",
    "## show known anomalies as triangles\n",
    "cfg.vs['shape'] = 'circle'\n",
    "cfg.vs['anomaly'] = 0\n",
    "pal = ig.RainbowPalette(n=max(cfg.vs['community'])+1) \n",
    "cfg.vs['color'] = [pal.get(int(i)) for i in cfg.vs['community']]\n",
    "for v in cfg.vs:\n",
    "    if v['community'] in [5,10] or v['name'] in ['28','58']:\n",
    "        v['shape']='triangle'\n",
    "        v['anomaly']=1\n",
    "ly = cfg.layout_fruchterman_reingold()\n",
    "ig.plot(cfg, layout=ly, bbox=(0,0,500,300), vertex_size=8, edge_color='lightgray')\n",
    "#ig.plot(cfg, target=\"anomaly_0.eps\", layout=ly, bbox=(0,0,500,300), vertex_size=8, edge_color='lightgray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## greyscale version (for the book)\n",
    "pal = ig.GradientPalette(\"white\",\"black\",max(cfg.vs['community'])+1)\n",
    "cfg.vs['color'] = [pal.get(int(i)) for i in cfg.vs['community']]\n",
    "ig.plot(cfg, layout=ly, bbox=(0,0,500,300), vertex_size=8, edge_color='lightgray')\n",
    "#ig.plot(cfg, target=\"anomaly_1.eps\", layout=ly, bbox=(0,0,500,300), vertex_size=8, edge_color='lightgray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we try to recover those anomalous teams by running several node2vec embeddings with different parameters.\n",
    "For each embedding:\n",
    "* compute JS-divergence using the framework\n",
    "* compute the entropy of the b-vector for each node (i.e. the probability distribution of edges w.r.t. every community in the geometric Chung-Lu model)\n",
    "* since we have the ground truth (anomalous nodes), we also compute the area under the ROC curve (AUC)\n",
    "\n",
    "From those results:\n",
    "* plot entropy vs divergence\n",
    "* for some good/bad embedding, we show boxplot for the entropy of anomalous vs other nodes\n",
    "\n",
    "There are several other methods to find anomalous nodes, but this simple approach yields good results. The rationale is that an \"anomalous\" node will be difficult to place in a cluster, so the geometric Chung-Lu model will predict edges to several different clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## keep track of best/worst results\n",
    "best_jsd = 1\n",
    "worst_jsd = 0\n",
    "L = []\n",
    "\n",
    "## node2vec with varying parameters (60 embeddings)\n",
    "## on some platforms, we got better results with longer random walks (code commented out below)\n",
    "for dim in np.arange(2,25,2):\n",
    "    for (p,q) in [(1,0.5),(0.5,1),(1,0.1),(0.1,1),(1,1)]:\n",
    "        ## long walks:\n",
    "        #x = n2v + ' -i:'+datadir+'Football/football.edgelist -o:_embed -d:'+str(dim)+' -p:'+str(p)+' -q:'+str(q)\n",
    "        ## short walks:\n",
    "        x = n2v + ' -l:15 -i:'+datadir+'Football/football.edgelist -o:_embed -d:'+str(dim)+' -p:'+str(p)+' -q:'+str(q)\n",
    "        r = os.system(x+' >/dev/null 2>&1') ## to avoid long output\n",
    "        jsd = JS(datadir+'Football/football.edgelist',datadir+'Football/football.ecg','_embed',entropy=True)\n",
    "        ## keep track of best and worst\n",
    "        if jsd < best_jsd:\n",
    "            os.system('cp _entropy _entropy_best')\n",
    "            best_jsd = jsd\n",
    "        if jsd > worst_jsd:\n",
    "            os.system('cp _entropy _entropy_worst')\n",
    "            worst_jsd = jsd\n",
    "\n",
    "        ent = list(pd.read_csv('_entropy',header=None)[1])\n",
    "        cfg.vs['ent'] = ent\n",
    "        roc = roc_auc_score(cfg.vs['anomaly'], ent)\n",
    "        L.append([dim,'n2v',str(p)+' '+str(q),jsd,roc])        \n",
    "\n",
    "## store results in dataframe and show best ones w.r.t. divergence\n",
    "D = pd.DataFrame(L,columns=['dim','algo','param','jsd','auc'])\n",
    "D = D.sort_values(by='jsd',axis=0)\n",
    "D.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show worst results (high divergence) \n",
    "D.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we plot the AUC (w.r.t. ground truth) as a function of the divergence. We see the (negative) correltion between those quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## auc vs divergence (jsd)\n",
    "plt.plot(D['jsd'],D['auc'],'o',color='black')\n",
    "plt.xlabel('JS Divergence',fontsize=14)\n",
    "plt.ylabel('AUC',fontsize=14);\n",
    "#plt.savefig('anomaly_2.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next two plots, we compare the distributions of entropy for the anomalous and \"regular\" nodes, respectively with a good (low divergence) and bad embedding. Separation is clearer in the first case, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entropy scores - some good embedding\n",
    "cfg.vs['ent'] = list(pd.read_csv('_entropy_best',header=None)[1])\n",
    "X = [v['ent'] for v in cfg.vs if v['anomaly']==0]\n",
    "Y = [v['ent'] for v in cfg.vs if v['anomaly']==1]\n",
    "plt.boxplot([X,Y],labels=['Regular','Anomalous'],sym='.',whis=(0,100), widths=.5)\n",
    "plt.title(\"Low divergence embedding\",fontsize=14)\n",
    "plt.ylabel('Entropy',fontsize=14);\n",
    "#plt.savefig('anomaly_3.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entropy scores - some not so good embedding\n",
    "cfg.vs['ent'] = list(pd.read_csv('_entropy_worst',header=None)[1])\n",
    "X = [v['ent'] for v in cfg.vs if v['anomaly']==0]\n",
    "Y = [v['ent'] for v in cfg.vs if v['anomaly']==1]\n",
    "plt.boxplot([X,Y],labels=['Regular','Anomalous'],sym='.',whis=(0,100), widths=.5)\n",
    "plt.title(\"High divergence embedding\",fontsize=14)\n",
    "plt.ylabel('Entropy',fontsize=14);\n",
    "#plt.savefig('anomaly_4.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation:  combining several good embeddings\n",
    "\n",
    "We consider the top-$k$ embeddings w.r.t. divergence and compare sum ranks w.r.t. entropy score over those.\n",
    "The hope is to add stability by using a ensemble of models.\n",
    "You can try other ideas for combining results from different models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "\n",
    "## try with top-k embeddings together - hopefully this consistently yields high AUC\n",
    "k = 7\n",
    "cfg.vs['rank'] = 0\n",
    "for i in range(k):\n",
    "    dim = D.iloc[i]['dim']\n",
    "    p = float(D.iloc[i]['param'].split()[0])\n",
    "    q = float(D.iloc[i]['param'].split()[1])\n",
    "    x = 'node2vec -i:'+datadir+'Football/football.edgelist -o:_embed -d:'+str(dim)+' -p:'+str(p)+' -q:'+str(q)\n",
    "    ## if you get unstable results, you can try with shorter random walks, for example:\n",
    "    ## x = 'node2vec -l:15 -i:'+datadir+'Football/football.edgelist -o:_embed -d:'+str(dim)+' -p:'+str(p)+' -q:'+str(q)\n",
    "    r = os.system(x+' >/dev/null 2>&1') ## to avoid long output\n",
    "    jsd = JS(datadir+'Football/football.edgelist',datadir+'Football/football.ecg','_embed',entropy=True)\n",
    "    cfg.vs['ent'] = list(pd.read_csv('_entropy',header=None)[1])\n",
    "    rk = rankdata(cfg.vs['ent'])\n",
    "    for i in range(len(rk)):\n",
    "        cfg.vs[i]['rank'] += rk[i] ## add ranks\n",
    "print('AUC: ',roc_auc_score(cfg.vs['anomaly'], cfg.vs['rank']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphmining",
   "language": "python",
   "name": "graphmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
