{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 - Centrality Measures\n",
    "\n",
    "In this notebook, we explore various centrality measures on a weighted, directed graph which represents the volume of passengers between US airports in 2008. \n",
    "\n",
    "As with the previous notebooks, make sure to set the data directory properly in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../Datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define edges color\n",
    "cls_edges = 'gainsboro'\n",
    "\n",
    "## we will consider 3 types of nodes with the following colors and sizes:\n",
    "cls = ['silver','dimgray','black']\n",
    "sz = [6,9,12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US Airport Graph -  Volume of Passengers\n",
    "\n",
    "The nodes are represented by the 3-letter airport codes such as LAX (Los Angeles); we also read in the volume of passengers that we use as **edge weights**. The edges are directed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read edges and build weighted directed graph\n",
    "D = pd.read_csv(datadir+'Airports/connections.csv')\n",
    "g = ig.Graph.TupleList([tuple(x) for x in D.values], directed=True, edge_attrs=['weight'])\n",
    "D.head() ## look at a few edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read node attributes\n",
    "\n",
    "We read the node attributes in data frame A:\n",
    "* lat/lon, which we will use as the graph layout\n",
    "* state (2-letter code)\n",
    "* city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read vertex attributes and add to graph\n",
    "A = pd.read_csv(datadir+'Airports/airports_loc.csv')\n",
    "lookup = {k:v for v,k in enumerate(A['airport'])}\n",
    "l = [lookup[x] for x in g.vs()['name']]\n",
    "g.vs()['layout'] = [(A['lon'][i],A['lat'][i]) for i in l]\n",
    "g.vs()['state'] = [A['state'][i] for i in l]\n",
    "g.vs()['city'] = [A['city'][i] for i in l]\n",
    "A.head() ## first few rows in A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add a few more attributes for visualization\n",
    "g.vs()['size'] = sz[1]\n",
    "g.vs()['color'] = cls[1]\n",
    "g.es()['color'] = cls_edges\n",
    "g.es()['arrow_size'] = 0.33\n",
    "print(g.vcount(),'nodes and',g.ecount(),'directed edges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for loops and multiple edges\n",
    "\n",
    "There are no multiedges (not surprising, edges are weighted here), but there are some loops in the raw data,\n",
    "for example:\n",
    "``` \n",
    "SEA,SEA,69\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of loop edges:',sum(g.is_loop()))\n",
    "print('number of multiple edges:',sum(g.is_multiple()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connected components\n",
    "\n",
    "The graph is weakly connected (that is, ignoring directionality) except for 2 airports: DET and WVL that are connected by a single directed edge.\n",
    "\n",
    "With strong connectivity, the giant component has size 425.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count the number of nodes in the giant component (weak connectivity)\n",
    "print(g.connected_components(mode='WEAK').giant().vcount(),'out of',g.vcount(),'are in giant (weak) component')\n",
    "print(g.connected_components(mode='STRONG').giant().vcount(),'out of',g.vcount(),'are in giant (strong) component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## which airports are NOT weakly connected to the rest?\n",
    "cl = g.connected_components(mode='WEAK').membership\n",
    "giant = mode(cl) ## giant component\n",
    "for i in range(g.vcount()):\n",
    "    if cl[i] != giant:\n",
    "        print(g.vs[i]['name'],'which has in degree',g.degree(i,mode='IN'),'and out degree',g.degree(i,mode='OUT'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few more statistics\n",
    "\n",
    "Looking at coreness (mode = 'ALL' means that we merge in and out edges, so undirected coreness).\n",
    "We see a group of nodes with very high coreness, a group of highly connected hub airports.\n",
    "There are also several nodes with low coreness, more peripherial airports.\n",
    "\n",
    "We also plot the degree distribution, again with mode='ALL' (total degree, in and out).\n",
    "Which airport has maximal degree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = g.coreness(mode='ALL')\n",
    "plt.hist(gc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## print a few airports with maximal coreness:\n",
    "mc = np.max(gc)\n",
    "top = 0\n",
    "for i in range(g.vcount()):\n",
    "    if gc[i] == mc:\n",
    "        print(g.vs[i]['name'])\n",
    "        top += 1\n",
    "        if top==5:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## degree distribution\n",
    "gd = g.degree(mode='ALL')\n",
    "plt.hist(gd, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## max degree airport\n",
    "print('max degree for:',g.vs[np.argmax(gd)]['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## California Subgraph \n",
    "\n",
    "We now look at several centrality measures. To speed up the computation and plotting, we consider only the airports in California, and the edges within the state.\n",
    "\n",
    "You can try other states by changing the first line below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build smaller subgraph 'G' for California\n",
    "G = g.subgraph([v for v in g.vs() if v['state'] == 'CA'])\n",
    "\n",
    "## drop isolated vertices (i.e. without in-state connections)\n",
    "G = G.subgraph([v for v in G.vs() if v.degree()>0])\n",
    "\n",
    "## remove loops if any\n",
    "G = G.simplify(multiple=False)\n",
    "print(G.vcount(),'nodes and',G.ecount(),'directed edges')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## The graph is weakly connected except for 2 airports\n",
    "## We color those in red for now\n",
    "cl = G.connected_components(mode='WEAK').membership\n",
    "giant = mode(cl)\n",
    "for i in range(G.vcount()):\n",
    "    if cl[i] != giant:\n",
    "        print(G.vs[i]['name'],'which has in degree',G.degree(i,mode='IN'),'and out degree',G.degree(i,mode='OUT'))\n",
    "        G.vs[i]['color'] = 'red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot using lat/lon as layout\n",
    "ly = ig.Layout(G.vs['layout'])\n",
    "## y-axis goes top-down thus the inversion\n",
    "ly.mirror(1)\n",
    "ig.plot(G, bbox=(0,0,300,300), layout=ly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centrality measures\n",
    "\n",
    "Most measures defined in Chapter 3 of the book are available directly in igraph.\n",
    "\n",
    "We compute the following centrality measures for the weighted graph G:\n",
    "**PageRank**, **Authority** and **Hub**.\n",
    "\n",
    "For **degree centrality**, we define our own function below (directed degree centrality) and we normalize the weights to get values bounded above by 1.\n",
    "\n",
    "For the distance based centrality measures **closeness** and **betweenness**, we do not use the edges weights, so the distance between nodes is the number of hops, and not based on the number of passengers. This is a natural choice here, since distance between airports (cities) can be viewed as the number of flights needed to travel between those cities.\n",
    "\n",
    "We compute the above centrality for every node in the CA subgraph.\n",
    "\n",
    "#### Warning for disconnected graphs\n",
    "\n",
    "We get a warning when running closeness centrality, since the graph is not connected. \n",
    "Here are the details of what is going on from the help file:\n",
    "\n",
    "*If the graph is not connected, and there is no path between two\n",
    "vertices, the number of vertices is used instead the length of\n",
    "the geodesic. This is always longer than the longest possible\n",
    "geodesic.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute normalized weights \n",
    "mw = np.max(G.es['weight'])\n",
    "G.es()['normalized_weight'] = [w/mw for w in G.es()['weight']]\n",
    "\n",
    "## directed degree centrality\n",
    "def degree_centrality(g, weights=None):\n",
    "    n = g.vcount()\n",
    "    if g.is_directed():\n",
    "        dc = [sum(x)/(2*(n-1)) for x in zip(g.strength(mode='in',weights=weights),\\\n",
    "              g.strength(mode='out',weights=weights))]\n",
    "    else:\n",
    "        dc = [x/(n-1) for x in g.strength(weights=weights)]\n",
    "    return dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute several centrality measures for the CA subgraph G\n",
    "C = pd.DataFrame({'airport':G.vs()['name'],\\\n",
    "                  'degree':degree_centrality(G,weights='normalized_weight'),\\\n",
    "                  'pagerank':G.pagerank(weights='weight'),'authority':G.authority_score(weights='weight'),\\\n",
    "                  'hub':G.hub_score(weights='weight'),'between':G.betweenness(),\\\n",
    "                  'closeness':G.closeness()})\n",
    "\n",
    "## normalize betweenness\n",
    "n = G.vcount()\n",
    "C['between'] = [2*x/((n-1)*(n-2)) for x in C['between']]\n",
    "\n",
    "## sort w.r.t. degree centrality, look at top airports\n",
    "Cs = C.sort_values(by='degree', ascending=False)\n",
    "Cs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bottom ones\n",
    "Cs.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top airports\n",
    "\n",
    "The above results agree with intuition in terms of the most central airports in California.\n",
    "Note however that SAN (San Diego) has high values *except* for betweenness, an indication that connecting flights transit mainly via LAX or SFO. \n",
    "\n",
    "Below, we plot the CA graph again, highlighting the top-3 airports w.r.t. pagerank: LAX, SFO, SAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset node colours\n",
    "G.vs()['color'] = cls[1]\n",
    "\n",
    "## highlight top-3 airports w.r.t. pagerank\n",
    "G.vs()['prk'] = C['pagerank']\n",
    "for x in np.argsort(G.vs()['prk'])[-3:]:\n",
    "    G.vs()[x]['color'] = cls[2]\n",
    "    G.vs()[x]['size'] = sz[2]\n",
    "\n",
    "#ig.plot(G,'California.eps',bbox=(0,0,300,300),layout=ly)\n",
    "ig.plot(G,bbox=(0,0,300,300),layout=ly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between measures\n",
    "\n",
    "We use the kendall-tau (rank-based) correlation measure below.\n",
    "\n",
    "We observe high agreement between all measures.\n",
    "In particular, degree-centrality, hub and authority measures are very highly correlated,\n",
    "and so are the distance-based measures (betweenness, closeness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rank-based correlation between measures\n",
    "df = C.corr('kendall', numeric_only=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at coreness\n",
    "\n",
    "We already looked at coreness for the whole US graph, now we look at the CA subgraph, again with mode='ALL'.\n",
    "\n",
    "Below we show nodes with max coreness as larger black dots, and nodes with minimal coreness as smaller dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot nodes w.r.t. coreness\n",
    "G.vs['color'] = cls[1]\n",
    "G.vs['size'] = sz[1]\n",
    "G.vs()['core'] = G.coreness()\n",
    "Mc = np.max(G.vs()['core'])\n",
    "mc = np.min(G.vs()['core'])\n",
    "for v in G.vs():\n",
    "    if v['core'] == Mc:\n",
    "        v['color'] = cls[2]\n",
    "        v['size'] = sz[2]\n",
    "    if v['core'] <= mc+1:\n",
    "        v['color'] = cls[0]\n",
    "        v['size'] = sz[0]\n",
    "#ig.plot(G,\"California_coreness.eps\",bbox=(0,0,300,300),layout=ly)\n",
    "ig.plot(G,bbox=(0,0,300,300),layout=ly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above uses the geographical layout, so it is not clear what is going on.\n",
    "\n",
    "Let's use a force directed layout to make the difference between high and low core number clearer. \n",
    "\n",
    "The high coreness nodes are clearly seen, and we aso observe a small connected component that was buried in the previous visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Coreness is more clear here\n",
    "c = [1 if v['core']==Mc else 2 if v['core']==mc else 0 for v in G.vs()]\n",
    "ly = G.layout_kamada_kawai()\n",
    "#ig.plot(G,\"California_kamada.eps\",bbox=(0,0,300,300),layout=ly)\n",
    "ig.plot(G,bbox=(0,0,300,300),layout=ly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vertices with max coreness (13-core) \n",
    "## note that there are less than 14 nodes, this is an interesting remark and\n",
    "## it is because we consider both in and out-going edges by default for directed graph.\n",
    "V = [v['name'] for v in G.vs() if v['core']==Mc]\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at closeness centrality\n",
    "\n",
    "Using the same layout as above (high coreness nodes in the middle), we display the closeness centrality scores.\n",
    "\n",
    "Recall the warning -- this is normal for disconnected graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show closeness centralities, same layout\n",
    "ix = np.round(G.closeness(),decimals=2)\n",
    "G.vs['size'] = 3\n",
    "#ig.plot(G,\"California_closeness.eps\",vertex_label=ix,layout=ly,bbox=(0,0,300,300))\n",
    "ig.plot(G,vertex_label=ix,layout=ly,bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparing coreness with other centrality measures\n",
    "\n",
    "We add coreness to data frame with centrality measures (C).\n",
    "\n",
    "We then group the data in 3 categories: high coreness (13), low (2 or less) or mid-range, and we compute and plot the mean for every other measure.\n",
    "\n",
    "We see that for all centrality measures except closeness centrality, the values are clearly higher for nodes with high coreness.\n",
    "\n",
    "The slightly higher pagerank value for 'low' coreness nodes vs 'mid' ones is due to the two airports that are not part of the giant component.\n",
    "\n",
    "As expected, nodes with small coreness generally have smaller centrality scores. \n",
    "This is why for example we often remove the small core nodes (for example, keeping only the 2-core) to reduce\n",
    "the size of large graphs without destroying its main structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## group in 3 categories\n",
    "G.vs()['Core'] = ['low' if v['core']<=2 else 'high' if v['core']==13 else 'mid' for v in G.vs()]\n",
    "C['Coreness'] = G.vs['Core']\n",
    "df = C.groupby('Coreness').mean(numeric_only=True)\n",
    "df.sort_values(by='degree',inplace=True,ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## grouped barplot\n",
    "bh = np.array(df.loc[['high']])[0]\n",
    "bm = np.array(df.loc[['mid']])[0]\n",
    "bl = np.array(df.loc[['low']])[0]\n",
    "barWidth = 0.25\n",
    "\n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bh))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "\n",
    "# Make the plot\n",
    "plt.bar(r1, bh, color=cls[2], width=barWidth, edgecolor='white', label='high coreness')\n",
    "plt.bar(r2, bm, color=cls[1], width=barWidth, edgecolor='white', label='mid coreness')\n",
    "plt.bar(r3, bl, color=cls[0], width=barWidth, edgecolor='white', label='low coreness')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xlabel('measure',fontsize=14)\n",
    "plt.xticks([r + barWidth for r in range(len(bh))], df.columns, fontsize=10)\n",
    "plt.ylabel('score',fontsize=14) \n",
    "\n",
    "# Create legend & Show graphic\n",
    "plt.legend(fontsize=12);\n",
    "\n",
    "# un-comment to save in file\n",
    "#plt.savefig('California_core_vs_measures.eps',dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta-centrality example\n",
    "\n",
    "This is the simple pandemic example detailed in the book:\n",
    "\n",
    "*The pandemic starts at exactly one airport selected uniformly at random from all the airports. Then, the following rules for spreading are applied: (i) in a given airport pandemic lasts only for one round and (ii) in the next round, with probability α, the pandemic spreads independently along the flight routes to the destination airports for all connections starting from this airport. Airports can interact with the pandemic many times, and the process either goes on forever or the pandemic eventually dies out. Our goal is to find the expected number of times a given airport interacted with the pandemic, which amounts to the sum over all airports of the expected number of times this airport has the pandemic.*\n",
    "\n",
    "We use alpha = 0.1 and plot the (decreasing) delta centrality values in a barplot, using the same 3 colors are with the coreness plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delta-centrality with a simple pandemic spread model\n",
    "def spread(g, alpha=0.1):\n",
    "    n = g.vcount()\n",
    "    I = np.diag(np.repeat(1,n))\n",
    "    A = np.array(g.get_adjacency().data)\n",
    "    One = np.ones((n,1))\n",
    "    X = np.linalg.inv(I-alpha*np.transpose(A))\n",
    "    Y = np.reshape(X.dot(One)/n,n)\n",
    "    return np.sum(Y)\n",
    "\n",
    "def spread_delta_centrality(g, alpha=0.1):\n",
    "    dc = []\n",
    "    spr = spread(g, alpha=alpha)\n",
    "    ## print(spr) # P(G) in the book\n",
    "    for i in g.vs():\n",
    "        G = g.copy()\n",
    "        el = g.incident(i, mode='ALL')\n",
    "        G.delete_edges(el)\n",
    "        dc.append((spr-spread(G, alpha=alpha))/spr)\n",
    "    return dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute with alpha = 0.1, show top airports\n",
    "G.vs['delta'] = spread_delta_centrality(G, alpha=.1)\n",
    "DC = pd.DataFrame(np.transpose([G.vs['name'],G.vs['delta'],G.vs['color']]),columns=['airport','delta','color'])\n",
    "DC.sort_values(by='delta',ascending=False, inplace=True)\n",
    "DC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot using the same colors as with coreness plot\n",
    "heights = [float(x) for x in DC['delta']]\n",
    "bars = DC['airport']\n",
    "y_pos = range(len(bars))\n",
    "plt.bar(y_pos, heights, color=DC['color'] )\n",
    "\n",
    "# Rotation of the bars names\n",
    "plt.ylabel('Delta Centrality',fontsize=12)\n",
    "plt.xticks(y_pos, bars, rotation=90)\n",
    "plt.yticks();\n",
    "\n",
    "\n",
    "#plt.savefig('California_delta.eps',dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group centrality and centralization\n",
    "\n",
    "We go back to the full US airports graph, abd ask the following questions:\n",
    "\n",
    "* which states have highest delta centralities w.r.t. efficiency?\n",
    "* what about centralization for each state subgraph?\n",
    "\n",
    "Computing efficiency involves the computation of shortest path lengths, which will cause a warning if the graph is disconnected. Warnings can be turned off by un-commenting the next cell."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## efficiency function given g\n",
    "def efficiency(g):\n",
    "    n = g.vcount()\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        v = g.get_shortest_paths(i)\n",
    "        s += np.sum([1/(len(x)-1) for x in v if len(x) > 1])\n",
    "    return s/(n*(n-1))\n",
    "\n",
    "## group delta centrality -- compute for each state\n",
    "states = list(set(g.vs()['state']))\n",
    "eff_us = efficiency(g)\n",
    "dc = []\n",
    "for s in states:\n",
    "    v = [x for x in g.vs() if x['state']==s]\n",
    "    G = g.copy()\n",
    "    e = []\n",
    "    for x in v:\n",
    "        e.extend(g.incident(x, mode='ALL'))\n",
    "    G.delete_edges(e)\n",
    "    dc.append((eff_us-efficiency(G))/eff_us)\n",
    "\n",
    "## sort and show top-3\n",
    "DC = pd.DataFrame({'state':states, 'delta_centrality':dc})\n",
    "DC = DC.sort_values(by='delta_centrality', ascending=False)\n",
    "DC.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ... and bottom 3\n",
    "DC.tail(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For group centralization, we use the PageRank measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## group centralization (using PageRank) -- by state\n",
    "states = list(set(g.vs()['state']))\n",
    "pr = []\n",
    "st = []\n",
    "for s in states:\n",
    "    v = [x for x in g.vs() if x['state']==s]\n",
    "    if len(v)>5: ## look at states with more than 5 airports only\n",
    "        G = g.subgraph(v)\n",
    "        G = G.simplify(multiple=False) ## drop self-loops\n",
    "        p = G.pagerank(weights='weight')\n",
    "        pr.append(np.max(p) - np.mean(p))\n",
    "        st.append(s)\n",
    "\n",
    "## sort and show top-3\n",
    "DC = pd.DataFrame({'State':st, 'Pagerank Centralization':pr})\n",
    "DC = DC.sort_values(by='Pagerank Centralization', ascending=False)\n",
    "DC.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the state with highest PageRank centralization (Michigan).\n",
    "\n",
    "This is a state with one high degree airport (DTW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [x for x in g.vs() if x['state']=='MI']\n",
    "G = g.subgraph(v)\n",
    "G = G.subgraph([v for v in G.vs() if v.degree()>0])\n",
    "G = G.simplify(multiple=False)\n",
    "#ig.plot(G, 'central_MI.eps', bbox=(0,0,300,300))\n",
    "ig.plot(G,bbox=(0,0,300,300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one big hub city: Detroit\n",
    "G.vs['deg'] = G.degree() # overall degree\n",
    "for v in G.vs:\n",
    "    print(v['city'],v['name'],'has degree',v['deg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the state with lowest PageRank centralization (ND).\n",
    "\n",
    "This is a state without high degree (hub) airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now the bottom 3\n",
    "DC.tail(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [x for x in g.vs() if x['state']=='ND']\n",
    "G = g.subgraph(v)\n",
    "G = G.subgraph([v for v in G.vs() if v.degree()>0])\n",
    "G = G.simplify(multiple=False)\n",
    "\n",
    "#ig.plot(G, 'central_ND.eps', bbox=(0,0,300,300))\n",
    "ig.plot(G, bbox=(0,0,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## no big hub city here\n",
    "G.vs['city']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should we expect for California? There are hub airports, but several ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what about California?\n",
    "DC[DC['State']=='CA']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphmining",
   "language": "python",
   "name": "graphmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
