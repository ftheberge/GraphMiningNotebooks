{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8 -  Detecting Overlapping communities\n",
    "\n",
    "The problem of graph clustering is well studied, in particular the case where the vertices are partitioned into\n",
    "non-overlapping communities.\n",
    "\n",
    "Here, we look at the problem of graph clustering where:\n",
    "* vertices can be part of several communities (overlapping communities)\n",
    "* vertices can be part of no community (\"noise\" vertices)\n",
    "\n",
    "We explore the following three methods:\n",
    "* methods based on finding overlapping cliques (a clique is a complete subgraph)\n",
    "* methods based on splitting vertices into multiple personae, and\n",
    "* methods based on clustering the edges.\n",
    "\n",
    "We also look at some post-processing based on Community Association Strength scores (CAS), which can be used after running the above, or some graph partioning algorithm (such as ECG ou Leiden)\n",
    "\n",
    "We illustrate those methods using the small Karate Club graph.\n",
    "Next we conaider larger graphs: a word association graph and artificial ABCD benchmark graphs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New requirements\n",
    "\n",
    "* overlapping NMI measure (oNMI): download and compile from: https://github.com/aaronmcdaid/Overlapping-NMI \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PythonCall\n",
    "using CondaPkg\n",
    "using Random\n",
    "using DelimitedFiles\n",
    "using Combinatorics\n",
    "using StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = pyimport(\"igraph\")\n",
    "random = pyimport(\"random\")\n",
    "pd = pyimport(\"pandas\")\n",
    "pickle = pyimport(\"pickle\")\n",
    "plt = pyimport(\"matplotlib.pyplot\")\n",
    "pyimport(\"partition_igraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../Datasets/\"\n",
    "## oNMI executable:\n",
    "oNMI = \"../oNMI/onmi\"             ## overlapping NMI executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calls the oNMI executable, format of inputs: list of lists (communities)\n",
    "function compute_oNMI(First::Vector{Vector{Int}},\n",
    "    Second::Vector{Vector{Int}},\n",
    "    oNMI_path::String)\n",
    "    fn1 = \"__\" * string(rand(UInt))[1:10]\n",
    "    fn2 = \"__\" * string(rand(UInt))[1:10]\n",
    "\n",
    "    open(fn1, \"w\") do f\n",
    "        for row in First\n",
    "            println(f, join(row, \" \"))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    open(fn2, \"w\") do f\n",
    "        for row in Second\n",
    "            println(f, join(row, \" \"))\n",
    "        end\n",
    "    end\n",
    "    output = read(`$oNMI_path $fn1 $fn2`, String)\n",
    "    tokens = split(output)\n",
    "    x = parse(Float64, tokens[2])\n",
    "    rm(fn1)\n",
    "    rm(fn2)\n",
    "    return x\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## assign colors and shapes w.r.t. overlapping clusters\n",
    "## white: no cluster\n",
    "## black square: overlap\n",
    "## the rest are shown as colored circles\n",
    "function color_nodes(g, communities, greyscale=false)\n",
    "    g.vs[\"_oc\"] = [pylist([]) for i in 0:pyconvert(Int, g.vcount())-1]\n",
    "    for i in 1:length(communities)\n",
    "        for j in communities[i]\n",
    "            g.vs.find(j)[\"_oc\"].append(i)\n",
    "        end\n",
    "    end\n",
    "    if greyscale\n",
    "        pal = ig.drawing.colors.GradientPalette(\"white\", \"black\", n=length(communities) + 2)\n",
    "    else\n",
    "        pal = ig.drawing.colors.ClusterColoringPalette(n=length(communities))\n",
    "    end\n",
    "    g.vs[\"shape\"] = \"circle\"\n",
    "    for v in g.vs\n",
    "        if length(v[\"_oc\"]) == 0\n",
    "            v[\"color\"] = \"white\"\n",
    "        else\n",
    "            if length(v[\"_oc\"]) > 1\n",
    "                v[\"color\"] = \"black\"\n",
    "                v[\"shape\"] = \"square\"\n",
    "            else\n",
    "                if greyscale\n",
    "                    v[\"color\"] = pal[v[\"_oc\"][0]]\n",
    "                else\n",
    "                    v[\"color\"] = pal[v[\"_oc\"][0]-1]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CPM (clique percolation method)\n",
    "\n",
    "The first algorithm we consider is the Clique Percolation Method, which can\n",
    "be summarized as:\n",
    "* fix the clique size $k$ (typically $k$=3 or 4)\n",
    "* for each $k$-clique, join all other $k$-cliques with $k-1$ vertices in common, in turn (the percolation)\n",
    "* continue until all $k$-cliques are exhausted\n",
    "\n",
    "Is is based on:\n",
    "\n",
    "Derényi I., *et al.*, Clique percolation in random networks, Phys. Rev. Lett., 2005, vol. 94 (pg. 160-202)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function CPM(g, k=3)\n",
    "    cls = collect(map(Set, g.cliques(min=k, max=k)))\n",
    "    edgelist = []\n",
    "    for i in 0:length(cls)-1\n",
    "        push!(edgelist, (i, i))\n",
    "    end\n",
    "    for (i, j) in combinations(0:length(cls)-1, 2)\n",
    "        if length(intersect(cls[i+1], cls[j+1])) >= (k - 1)\n",
    "            push!(edgelist, (i, j))\n",
    "        end\n",
    "    end\n",
    "    cg = ig.Graph(edgelist, directed=false)\n",
    "    clusters = cg.connected_components()\n",
    "    L = []\n",
    "    members = Set()\n",
    "    for cluster in clusters\n",
    "        members = Set()\n",
    "        for i in cluster\n",
    "            push!(members, cls[pyconvert(Int, i)+1]...)\n",
    "        end\n",
    "        push!(L, Set(g.vs[pyset(members)][\"name\"]))\n",
    "    end\n",
    "    return L\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPM on the Zachary Graph\n",
    "\n",
    "We illustrate the different CPM-based algorithms with the well-known Karate Club dataset, which model interaction between 34 members. The 2 communities correspond to groups forming after a split in two \"factions\". Modularity-based algorithms usually find 4 or 5 communities.\n",
    "Below, we color the nodes according to the 2 factions after the split.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zachary graph and its two communities\n",
    "zac = ig.Graph.Read_Ncol(datadir * \"Zachary/zachary.edgelist\", directed=false)\n",
    "c = vec(readdlm(datadir * \"Zachary/zachary.communities\", Int))\n",
    "zac.vs[\"comm\"] = [c[parse(Int, pyconvert(String, x[\"name\"]))+1] for x in zac.vs]\n",
    "\n",
    "## plotting parameters\n",
    "zac.vs[\"size\"] = 12\n",
    "zac.es[\"color\"] = \"gainsboro\"\n",
    "pal = ig.drawing.colors.ClusterColoringPalette(n=maximum(zac.vs[\"comm\"]) + 1)\n",
    "zac.vs[\"color\"] = [pal[i] for i in zac.vs[\"comm\"]]\n",
    "\n",
    "# ## plot\n",
    "ig.plot(zac, bbox=(0, 0, 300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Running the CPM algorithm\n",
    "\n",
    "* We run the CPM algorithm as is on the Karate graph.\n",
    "* Nodes that belong to 2 or more clusters are represented as squares.\n",
    "* You can select col=\"grey\" for greyscale, but this is hard to distinguish with several clusters\n",
    "* We obtain one large community, two small ones and two orphan nodes (shown in white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ground-truth communities\n",
    "zac_gt = []\n",
    "for i in Set(pyconvert(Vector{Int}, zac.vs[\"comm\"]))\n",
    "    push!(zac_gt, [v[\"name\"] for v in zac.vs if pyconvert(Int, v[\"comm\"]) == i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CPM with k=3\n",
    "X = CPM(zac, 3)\n",
    "color_nodes(zac, X, false)\n",
    "println(\"oNMI:\", compute_oNMI([collect(i) for i in X], zac_gt))\n",
    "\n",
    "## plot\n",
    "ig.plot(zac, bbox=(0, 0, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CPM with k=4\n",
    "X = CPM(zac, 4)\n",
    "color_nodes(zac, X, false)\n",
    "print(\"oNMI:\", compute_oNMI([collect(i) for i in X], zac_gt))\n",
    "\n",
    "## plot\n",
    "ig.plot(zac, bbox=(0, 0, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter edges with small ECG weight (threshold or under)\n",
    "threshold = 0 ## filer edges with NO vote\n",
    "random.seed(123)\n",
    "zac.es[\"ecg_w\"] = zac.community_ecg(ens_size=32, min_weight=0).W\n",
    "zac_sg = zac.subgraph_edges([e for e in zac.es if pyconvert(Float64, e[\"ecg_w\"]) > threshold])\n",
    "X = CPM(zac_sg, 3)\n",
    "color_nodes(zac, X, false)\n",
    "print(\"oNMI:\", compute_oNMI([collect(i) for i in X], zac_gt))\n",
    "\n",
    "## plot\n",
    "ig.plot(zac, bbox=(0, 0, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random clusterings with same sizes as above\n",
    "random.seed(123)\n",
    "Nodes = []\n",
    "for x in X\n",
    "    Nodes=[Nodes; collect(x)]\n",
    "end\n",
    "Sizes = [[0]; cumsum(length.(X))]\n",
    "Results = []\n",
    "for rep in 1:100\n",
    "    R = []\n",
    "    P = shuffle(Nodes)\n",
    "    for s in 1:length(Sizes)-1:\n",
    "        push!(R,(P[Sizes[s]:Sizes[s+1]]))\n",
    "    end\n",
    "    push!(Results,(compute_oNMI(R,zac_gt)))\n",
    "end\n",
    "## report mean and stdv\n",
    "println(\"mean:\", mean(Results), \"stdv:\", std(Results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Ego-Splitting method\n",
    "\n",
    "The Ego-Splitting framework is based on paper by A. Epasto, S. Lattanzi and R.P. Leme at KDD 2017:\n",
    "\n",
    "https://www.kdd.org/kdd2017/papers/view/ego-splitting-framework-from-non-overlapping-to-overlapping-clusters\n",
    "\n",
    "\n",
    "In summary, the steps are:\n",
    "* For each vertex $v$:\n",
    " * build the ego-net for $v$ (minus self)\n",
    " * cluster this ego-net using a local method, such as label propagation (LP) or connected components (CC)\n",
    " * \"split\" vertex $v$ into one persona per ego-net cluster\n",
    "* Cluster this new graph (with duplicated vertices) with some graph partitioning algorithm such as LP or ECG. \n",
    " * We can set a minimum community size to avoid tiny ones.\n",
    "\n",
    "The original paper uses a LP method based on the Potts model, but we will use the Label Propagation from Raghavan *et. al.* which is implemented in igraph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function EgoSplit(G, split=\"CC\", algo=\"LP\")\n",
    "    g = G.copy()\n",
    "    ## implement ego-split approach with LP+LP and LP+ECG\n",
    "    g.vs[\"original\"] = g.vs[\"name\"]\n",
    "    ## use the vertex names to avoid issues when vertices are re-mapped ...\n",
    "    names = g.vs[\"name\"]\n",
    "    ## step 1 - ego-net splits\n",
    "    for nm in names\n",
    "        v = g.vs.find(nm).index\n",
    "        n = g.neighbors(v)\n",
    "        sg = g.subgraph(n)\n",
    "        if split == \"LP\"\n",
    "            x = sg.community_label_propagation().membership\n",
    "        else\n",
    "            x = sg.connected_components().membership\n",
    "        end\n",
    "        if minimum(pyconvert(Vector{Int}, x)) == -1\n",
    "            x = [i + 1 for i in x]\n",
    "        end\n",
    "        for j in Set(x)\n",
    "            g.add_vertex(name=nm + Py(\".\") + pystr(j), original=nm)\n",
    "        end\n",
    "        l = sg.vs[\"name\"]\n",
    "        for j in 0:length(x)-1\n",
    "            g.add_edge(nm + Py(\".\") + pystr(x[j]), l[j])\n",
    "        end\n",
    "        g.delete_vertices(v)\n",
    "    end\n",
    "    ## step 2 -- cluster w.r.t. multiple personae\n",
    "    if algo == \"LP\"\n",
    "        cl = g.community_label_propagation()\n",
    "    else\n",
    "        cl = g.community_ecg(ens_size=32)\n",
    "    end\n",
    "    C = [Set(sg.vs[\"original\"]) for sg in cl.subgraphs()]\n",
    "    return C\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ego-split\n",
    "random.seed(1)\n",
    "X = EgoSplit(zac, \"LP\") ## pick final algorithm as parameter (LP or ECG)\n",
    "X = [Set(l) for l in X if length(l) >= 3] ## min community size set to 3\n",
    "color_nodes(zac, X, false)\n",
    "println(\"oNMI:\", compute_oNMI([collect(i) for i in X], zac_gt))\n",
    "ig.plot(zac, bbox=(0, 0, 300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Edge Clustering \n",
    "\n",
    "We can obtain overlapping communities by clustering edges instead of vertices.\n",
    "The algorithm can be described as follows:\n",
    "* for each pair of edges sharing a node, say $(i,k)$ and $(j,k)$, compute some similarity measure between the neighborhoods of vertices $i$ and $j$, such as the Jaccard measure\n",
    "* perform hierarchical clustering on the edges with this similarity matrix\n",
    "\n",
    "It is based on:\n",
    "\n",
    "Ahn, YY., Bagrow, J., Lehmann, S. Link communities reveal multiscale complexity in networks. Nature 466, 761–764 (2010). https://doi.org/10.1038/nature09182\n",
    "\n",
    "This can be implemented by considering the connected components for the line-graph of the original graph using varying thresholds for the Jaccard measure.\n",
    "* line graph Lg(G) represents ties between edges of G\n",
    "* Lg(G) nodes are edges in G\n",
    "* edges sharing a node in G are linked by an edge in Lg(G)\n",
    "\n",
    "We pick the \"best\" clustering in the hierarchy based on the modularity scores on the line graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Jaccard(a, b)\n",
    "    x = length(intersect(Set(a), Set(b))) / length(union(Set(a), Set(b)))\n",
    "    return x\n",
    "end\n",
    "\n",
    "function weightedLinegraph(g)\n",
    "    lg = g.linegraph()\n",
    "    w = []\n",
    "    for e in lg.es\n",
    "        A = Set(g.es[e.tuple[0]].tuple)\n",
    "        B = Set(g.es[e.tuple[1]].tuple)\n",
    "        x = collect(union(setdiff(A, B), setdiff(B, A)))\n",
    "        push!(w, Jaccard(g.neighbors(x[1]), g.neighbors(x[2])))\n",
    "    end\n",
    "    lg.es[\"weight\"] = w\n",
    "    return lg\n",
    "end\n",
    "\n",
    "function edgeCluster(g)\n",
    "    q = -999\n",
    "    D = weightedLinegraph(g)\n",
    "    for th in sort(pyconvert(Vector{Float64}, collect(Set(D.es[\"weight\"]))))\n",
    "        ## filter edges w.r.t. similarity and find CC\n",
    "        dg = D.copy()\n",
    "        dg.delete_edges(pylist([e for e in dg.es if pyconvert(Float64, e[\"weight\"]) <= th]))\n",
    "        cc = dg.connected_components().membership\n",
    "        mod = pyconvert(Float64, D.modularity(cc))\n",
    "        if mod > q\n",
    "            q = mod\n",
    "            g.es[\"lc\"] = cc\n",
    "        end\n",
    "    end\n",
    "    ## Now gather the nodes for each edge cluster\n",
    "    L = []\n",
    "    for i in 0:pyconvert(Int, maximum(g.es[\"lc\"]))\n",
    "        sg = g.subgraph_edges(pylist([e for e in g.es if pyconvert(Int, e[\"lc\"]) == i]))\n",
    "        push!(L, sg.vs[\"name\"])\n",
    "    end\n",
    "    return L\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cluster\n",
    "X = edgeCluster(zac) ## pick final algorithm as parameter (LP or ECG)\n",
    "X = [Set(l) for l in X if length(l) >= 3] ## min community size set to 3\n",
    "# print(\"oNMI:\",compute_oNMI([collect(i) for i in X], zac_gt))\n",
    "color_nodes(zac, X, false)\n",
    "ig.plot(zac, bbox=(0, 0, 300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing with CAS scores\n",
    "\n",
    "From the previous result, drop community memberships with low CAS scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## community association strength for partitions\n",
    "function cas(G, A)\n",
    "    deg = pyconvert(Vector{Int}, G.degree())\n",
    "    deg_int = [sum([A[pyconvert(Int, i)+1] == A[pyconvert(Int, j)+1] for i in G.neighbors(j)]) for j in 0:pyconvert(Int, G.vcount())-1]\n",
    "    Vol = sum(deg)\n",
    "    Vol_A = zeros(Int, pyconvert(Int, maximum(A)) + 1)\n",
    "    for i in 1:pyconvert(Int, G.vcount())\n",
    "        Vol_A[A[i]+1] += deg[i]\n",
    "    end\n",
    "    return deg_int ./ deg - ([Vol_A[A[i]+1] for i in 1:pyconvert(Int, G.vcount())] - deg) ./ Vol\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop comminity memberships with low scores\n",
    "threshold = 0.1\n",
    "Y = []\n",
    "for i in 1:length(X)\n",
    "    zac.vs[\"_com\"] = pylist(1:pyconvert(Int, zac.vcount())) ## initialize each node in its own community\n",
    "    for x in X[i]\n",
    "        zac.vs.find(x)[\"_com\"] = 0 ## consider community X[i] only\n",
    "    end\n",
    "    c = cas(zac, pyconvert(Vector{Int}, zac.vs[\"_com\"])) ## cas w.r.t. X[i] for nodes in that community only\n",
    "    push!(Y, Set([zac.vs[i][\"name\"] for i in 0:length(c)-1 if c[i+1] >= threshold])) ## keep only cas results above threshold\n",
    "end\n",
    "## plot and compute oNMI\n",
    "color_nodes(zac, Y, false)\n",
    "## plot\n",
    "print(\"oNMI:\", compute_oNMI([collect(i) for i in Y], zac_gt))\n",
    "ig.plot(zac, bbox=(0, 0, 300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Association Graph Example\n",
    "\n",
    "We consider a graph built from the Word Association dataset (U of South Florida) based on:\n",
    "\n",
    "* G. Palla *et al.*, \"Uncovering the overlapping structure of complex networks in nature and society\", Nature 435, 814-818 (2005).\n",
    "\n",
    "In a nutshell, we build a graph with edges between pairs of similar words. We used a threshold of $w^*=.025$ for the association strength and use $k=4$ for the clique size. We use this dataset to illustrate the usefulness of overlapping clusters to discover various contexts of words. \n",
    "\n",
    "We look at two versions of CPM:\n",
    "* using the ECG-based version, and\n",
    "* using the association strength as edge weight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build the graph\n",
    "wg = ig.Graph.Read_Ncol(datadir * \"Words/words.txt\", names=true, directed=false, weights=true)\n",
    "wg = wg.simplify(combine_edges=\"sum\") ## sum association strength scores\n",
    "wg = wg.subgraph_edges([e for e in wg.es if pyconvert(Float64, e[\"weight\"]) >= 0.025]) ## prune low weight edges\n",
    "wg.vs[\"label\"] = wg.vs[\"name\"]\n",
    "println(wg.vcount(), \" nodes and \", wg.ecount(), \" edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use ECG-based weights\n",
    "random.seed(123)\n",
    "\n",
    "for word in [\"MATH\", \"DOG\", \"MONEY\"] ## you can try other words; all words are CAPITALIZED\n",
    "\n",
    "    ## get 2-hop ego-net\n",
    "    v = wg.vs.find(name=word)\n",
    "    n = wg.neighborhood(v, order=2)\n",
    "    sg = wg.subgraph(n)\n",
    "\n",
    "    ## filter edges w.r.t. ECG score\n",
    "    threshold = 0\n",
    "    random.seed(123)\n",
    "    sg.es[\"ecg_w\"] = sg.community_ecg(ens_size=32, min_weight=0).W\n",
    "    sg = sg.subgraph_edges([e for e in sg.es if pyconvert(Float64, e[\"ecg_w\"]) > threshold])\n",
    "\n",
    "    ## cluster and show results containing the given word\n",
    "    X = CPM(sg, 4)\n",
    "    println(\"\\nShowing clusters for the word \", word)\n",
    "    for x in X\n",
    "        if word in pyconvert(Set{String}, x)\n",
    "            println(join(sort(collect(x)), \" \"))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use association scores as weights\n",
    "\n",
    "for word in [\"MATH\", \"DOG\", \"MONEY\"] ## you can try other words; all words are CAPITALIZED\n",
    "\n",
    "    ## get 2-hop ego-net\n",
    "    v = wg.vs.find(name=word)\n",
    "    n = wg.neighborhood(v, order=2)\n",
    "    sg = wg.subgraph(n)\n",
    "\n",
    "    ## filter edges w.r.t. association strength scores\n",
    "    threshold = 0.025\n",
    "    sg = sg.subgraph_edges([e for e in sg.es if pyconvert(Float64, e[\"weight\"]) > threshold])\n",
    "\n",
    "    ## cluster and show results containing the given word\n",
    "    X = CPM(sg, 4)\n",
    "    println(\"\\nShowing clusters for the word\", word)\n",
    "    for x in X\n",
    "        if word in pyconvert(Set{String}, x)\n",
    "            println(join(sort(collect(x)), \" \"))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study over ABCD-$o^2$ benchmark graphs\n",
    "\n",
    "We generated 1,320 ABCD-$o^2$ graphs with the following parameters:\n",
    "* $n = 1,000$ nodes, no outliers\n",
    "* power law degree exponent $\\tau_1=2.5$ with degrees in range [5,50]\n",
    "* community size degree exponent $\\tau_2=1.5$ with sizes in range [50,200]\n",
    "* noise parameter $0.1 \\le \\xi \\le 0.65$\n",
    "* overlap parameter $1.0 \\le \\eta \\le 2.0$\n",
    "* $d=2$ (dimension of the spatial model for overlaps) and $\\rho=0$ (correlation between degree and number of community memberships)\n",
    "\n",
    "For the CAS-based post-processing, we used thresholds $t_1 = t_2 = 0.1$ (respectively to remove or add nodes to communities).\n",
    "\n",
    "The configuration file to build the graphs can be found in the ```Datasets/ABCDoo``` subdirectory, as well as a ```pickle``` file that contains the results from the experiments performed in `../Python_Notebooks_2nd/Chapter_8.ipynb` notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the results from the experiment above\n",
    "open(datadir * \"ABCDoo/abcdoo.pkl\", \"r\") do fp\n",
    "    global df = pickle.load(fp)\n",
    "end\n",
    "df = DataFrame(PyTable(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix xi\n",
    "xi = 0.1\n",
    "cls = [\"black\", \"black\", \"black\"]\n",
    "algos = [\"ego-split\", \"ego-split+cas\", \"ecg+cas\"]\n",
    "stdv = [\"ego-split(sd)\", \"ego-split+cas(sd)\", \"ecg+cas(sd)\"]\n",
    "style = [\":\", \"--\", \"-\"]\n",
    "_df = df[(df.xi.==xi), :]\n",
    "for j in 1:3\n",
    "    s = algos[j]\n",
    "    e = stdv[j]\n",
    "    plt.plot(_df.eta, _df[!, s], label=s, color=cls[j], linestyle=style[j])\n",
    "    plt.fill_between(_df.eta, _df[!, s] + 2 * _df[!, e], _df[!, s] - 2 * _df[!, e], alpha=0.1, color=cls[j])\n",
    "end\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(raw\"ABCD-oo graphs with $\\xi$=\" * string(xi), fontsize=16)\n",
    "plt.ylabel(\"oNMI\", fontsize=14)\n",
    "plt.xlabel(raw\"$\\eta$\", fontsize=14)\n",
    "plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix eta\n",
    "eta = 1.5\n",
    "cls = [\"black\", \"black\", \"black\"]\n",
    "algos = [\"ego-split\", \"ego-split+cas\", \"ecg+cas\"]\n",
    "stdv = [\"ego-split(sd)\", \"ego-split+cas(sd)\", \"ecg+cas(sd)\"]\n",
    "style = [\":\", \"--\", \"-\"]\n",
    "_df = df[(df.eta.==eta), :]\n",
    "for j in 1:3\n",
    "    s = algos[j]\n",
    "    e = stdv[j]\n",
    "    plt.plot(_df.xi, _df[!, s], label=s, color=cls[j], linestyle=style[j])\n",
    "    plt.fill_between(_df.xi, _df[!, s] + 2 * _df[!, e], _df[!, s] - 2 * _df[!, e], alpha=0.1, color=cls[j])\n",
    "end\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(raw\"ABCD-oo graphs with $\\eta$=\" * string(eta), fontsize=16)\n",
    "plt.ylabel(\"oNMI\", fontsize=14)\n",
    "plt.xlabel(raw\"$\\xi$\", fontsize=14)\n",
    "plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fix eta\n",
    "eta = 1.1\n",
    "#cls = [\"blue\",\"green\",\"red\",\"purple\"]\n",
    "cls = [\"black\", \"black\", \"black\"]\n",
    "algos = [\"ego-split\", \"ego-split+cas\", \"ecg+cas\"]\n",
    "stdv = [\"ego-split(sd)\", \"ego-split+cas(sd)\", \"ecg+cas(sd)\"]\n",
    "style = [\":\", \"--\", \"-\"]\n",
    "_df = df[(df.eta.==eta), :]\n",
    "for j in 1:3\n",
    "    s = algos[j]\n",
    "    e = stdv[j]\n",
    "    plt.plot(_df.xi, _df[!, s], label=s, color=cls[j], linestyle=style[j])\n",
    "    plt.fill_between(_df.xi, _df[!, s] + 2 * _df[!, e], _df[!, s] - 2 * _df[!, e], alpha=0.1, color=cls[j])\n",
    "end\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(raw\"ABCD-oo graphs with $\\eta$=\" * string(eta), fontsize=16)\n",
    "plt.ylabel(\"oNMI\", fontsize=14)\n",
    "plt.xlabel(raw\"$\\xi$\", fontsize=14)\n",
    "plt.gcf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
