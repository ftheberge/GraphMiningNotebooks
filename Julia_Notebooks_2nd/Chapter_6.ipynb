{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - Graph Embeddings\n",
    "\n",
    "In this notebook, we illustrate several graph embedding algorithms, we show how we can compare embeddings using an unsupervised framework, and we look at various applications such as visualization, clustering, link prediction and classification.\n",
    "\n",
    "### Things to install:\n",
    "\n",
    "We use a Julia package from https://github.com/KrainskiL/CGE.jl to compare graph embeddings.\n",
    "Follow the instructions from that GitHub repository to install it.\n",
    "\n",
    "Results presented in the book were run on MacOS. Most results are identical on Linux (we use seeds), but we found that Node2Vec can yield slightly different results. This can lead to small differences in some results, but not in the conclusions. \n",
    "\n",
    "Set the path(s) in the cell below. \n",
    "\n",
    "### Windows users:\n",
    "\n",
    "You need to change ```cp``` to ```copy``` in the ```test_embeddings``` function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the data directory\n",
    "datadir = \"../Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Arpack\n",
    "using CGE\n",
    "using CSV, DataFrames\n",
    "using DelimitedFiles\n",
    "using Graphs\n",
    "using GraphMakie, GLMakie\n",
    "using LinearAlgebra\n",
    "using NetworkLayout\n",
    "using PyPlot\n",
    "using Random\n",
    "using ScikitLearn\n",
    "using ScikitLearn.CrossValidation: train_test_split\n",
    "using Serialization\n",
    "using StatsBase\n",
    "using StatsPlots\n",
    "using UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sk_import linear_model:LogisticRegression\n",
    "@sk_import ensemble:RandomForestClassifier\n",
    "@sk_import cluster:(KMeans, DBSCAN)\n",
    "@sk_import metrics:(accuracy_score, roc_auc_score, roc_curve, confusion_matrix)\n",
    "@sk_import metrics:(calinski_harabasz_score, adjusted_mutual_info_score)\n",
    "@sk_import manifold:TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using PyCall\n",
    "run(`$(PyCall.python) -m pip install fastnode2vec numpy igraph partition_igraph scikit-network`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig = pyimport(\"igraph\")\n",
    "skn = pyimport(\"sknetwork\")\n",
    "pyimport(\"partition_igraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## as defined in Table 1 of node2vec paper for link prediction:\n",
    "## https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf\n",
    "function binary_operator(u, v, op::String=\"had\")\n",
    "    if op == \"had\"\n",
    "        return u .* v\n",
    "    elseif op == \"l1\"\n",
    "        return abs.(u .- v)\n",
    "    elseif op == \"l2\"\n",
    "        return (u .- v) .^ 2\n",
    "    elseif op == \"avg\"\n",
    "        return (u .+ v) ./ 2.0\n",
    "    else\n",
    "        error(\"Unsupported operation: $op\")\n",
    "    end\n",
    "end\n",
    "\n",
    "## read embedding from disk, in node2vec format\n",
    "function readEmbedding(fn::String=\"_embed\", sort::Bool=true)\n",
    "    df = CSV.File(fn; delim=' ', header=false, skipto=2) |> DataFrame\n",
    "    # Drop any columns that are entirely missing\n",
    "    df = df[:, all.(!ismissing, eachcol(df))]\n",
    "    sort && sort!(df, :Column1)\n",
    "    Y = Matrix(df[:, 2:end])\n",
    "    return Y\n",
    "end\n",
    "\n",
    "## Read embedding from file in node2vec format\n",
    "## Map to 2d layout format, using UMAP if dim > 2\n",
    "function embed2layout(fn::String=\"_embed\", seed::Int=123, n_jobs::Int=1)\n",
    "    df = CSV.File(fn; delim=' ', header=false, skipto=2) |> DataFrame\n",
    "    df = df[:, all.(!ismissing, eachcol(df))]\n",
    "    sort!(df, :Column1)  # sort by first column\n",
    "    Y = Matrix(df[:, 2:end])\n",
    "\n",
    "    if size(Y, 2) > 2\n",
    "        Random.seed!(seed)\n",
    "        Y = umap(Y', 2)\n",
    "        Y = Y'\n",
    "    end\n",
    "    return Tuple.(eachrow(Matrix(Y)))\n",
    "end\n",
    "\n",
    "## Computing Jensen-Shannon (JS) divergence with the Julia CGE framework code\n",
    "## given files: edgelist, communities and embedding\n",
    "function JS(edge_file, comm_file, embed_file, return_local=true, seed=123)\n",
    "    out = Pipe()\n",
    "    cmd = `julia --project ../CGE/CGE_CLI.jl -g $(edge_file) -c $(comm_file) -e $(embed_file) --seed $(string(seed))`\n",
    "    run(pipeline(cmd, stdout=out, stderr=Pipe()))\n",
    "    close(out.in)\n",
    "    result = String(read(out))\n",
    "    x = parse.(Float64, split(result[2:end-2], \", \"))\n",
    "    return_local && return (x[2], x[6])\n",
    "    return x[2]\n",
    "end\n",
    "\n",
    "## save embedding to disk to compute divergence with Julia CGE framework\n",
    "function saveEmbedding(X::AbstractMatrix, g, fn::String=\"_embed\")\n",
    "    open(fn, \"w\") do f\n",
    "        println(f, \"$(size(X, 1)) $(size(X, 2))\")\n",
    "        for i in 1:size(X, 1)\n",
    "            print(f, i - 1, \" \")\n",
    "            for j in 1:size(X, 2)\n",
    "                print(f, X[i, j], \" \")\n",
    "            end\n",
    "            print(f, \"\\n\")\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "## Hope embedding with various similarity functions\n",
    "\n",
    "function Hope(g::AbstractGraph, sim::String=\"katz\", dim::Int=2, verbose::Bool=false, beta::Float64=0.01, alpha::Float64=0.5)\n",
    "    if !is_directed(g)\n",
    "        dim *= 2\n",
    "    end\n",
    "\n",
    "    A = Matrix(adjacency_matrix(g))\n",
    "    n = nv(g)\n",
    "    M_g = I\n",
    "    M_l = I\n",
    "\n",
    "    if sim == \"katz\"\n",
    "        M_g = I - beta * A\n",
    "        M_l = beta * A\n",
    "    elseif sim == \"aa\"\n",
    "        M_g = I\n",
    "        D = Diagonal([x > 1 ? 1 / log(x) : 0.0 for x in degree(g)])\n",
    "        M_l = A * D * A\n",
    "        M_l[diagind(M_l)] .= 0.0\n",
    "    elseif sim == \"cn\"\n",
    "        M_g = I\n",
    "        M_l = A * A\n",
    "    elseif sim == \"ppr\"\n",
    "        P = zeros(n, n)\n",
    "        for i in 1:n\n",
    "            s = sum(A[i, :])\n",
    "            if s > 0\n",
    "                P[i, :] = A[i, :] ./ s\n",
    "            else\n",
    "                P[i, :] .= 1 / n\n",
    "            end\n",
    "        end\n",
    "        P = transpose(P)\n",
    "        M_g = I - alpha * P\n",
    "        M_l = (1 - alpha) * I\n",
    "    end\n",
    "\n",
    "    S = inv(M_g) * M_l\n",
    "    u, s, v = svd(S)\n",
    "    k = dim รท 2\n",
    "    u = u[:, begin:k]\n",
    "    s = s[begin:k]\n",
    "    v = v[begin:k, :]\n",
    "    sqrt_s = Diagonal(sqrt.(s))\n",
    "    X1 = u * sqrt_s\n",
    "    X2 = v' * sqrt_s\n",
    "    X = hcat(X1, X2)\n",
    "\n",
    "    p_d_p_t = u * Diagonal(s) * v\n",
    "    eig_err = norm(p_d_p_t - S)\n",
    "\n",
    "    if verbose\n",
    "        println(\"SVD error (low rank): $eig_err\")\n",
    "    end\n",
    "\n",
    "    if !is_directed(g)\n",
    "        d = dim รท 2\n",
    "        return X[:, 1:d]\n",
    "    else\n",
    "        return X\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "## Laplacian eigenmaps embedding\n",
    "function LE(g, dim::Int=2)\n",
    "    adjmat = Graphs.LinAlg.CombinatorialAdjacency(adjacency_matrix(g))\n",
    "    L_sym = Matrix(I - Diagonal(adjmat.D .^ (-1 / 2)) * (adjmat.A) * Diagonal(adjmat.D .^ (-1 / 2)))\n",
    "    w, v = eigs(L_sym, nev=dim + 1, which=:SM)  # Smallest magnitude eigenvalues\n",
    "    idx = sortperm(real(w))  # Sort eigenvalues\n",
    "    w = w[idx]\n",
    "    v = v[:, idx]\n",
    "    X = v[:, 2:end]\n",
    "    return X\n",
    "end\n",
    "\n",
    "# ## Returns a LaTeX bmatrix\n",
    "function bmatrix(a::AbstractArray)\n",
    "    if ndims(a) > 2\n",
    "        throw(ArgumentError(\"bmatrix can at most display two dimensions\"))\n",
    "    end\n",
    "\n",
    "    lines = split(replace(string(a), ['[', ']'] => \"\"), '\\n')\n",
    "    rv = [raw\"\\begin{bmatrix}\"]\n",
    "    append!(rv, [\"  \" * join(split(l), \" & \") * raw\"\\\\\" for l in lines])\n",
    "    push!(rv, raw\"\\end{bmatrix}\")\n",
    "    return join(rv, \"\\n\")\n",
    "end\n",
    "\n",
    "## plot graph without axes and background grid\n",
    "function clean_graphplot(G::AbstractGraph; kwargs...)\n",
    "    f, ax, p = graphplot(G; kwargs...)\n",
    "    hidedecorations!(ax)\n",
    "    hidespines!(ax)\n",
    "    return f\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6.2 in the Book\n",
    "\n",
    "This is to illustrate random walks on (directed) graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = SimpleDiGraph(4)\n",
    "for e in [(1, 2), (2, 3), (2, 4), (3, 2), (4, 3)]\n",
    "    add_edge!(g, e...)\n",
    "end\n",
    "\n",
    "clean_graphplot(g,\n",
    "    node_size=20,\n",
    "    ilabels=[\"A\", \"B\", \"C\", \"D\"],\n",
    "    arrow_size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "* ```abcd```: is a small ABCD graph (100 nodes), mainly for visualization and quick examples\n",
    "* ```ABCD1```: is a larger ABCD graph (1000 nodes), for experiments. It is noisy with $\\xi=0.6$.\n",
    "* ```ABCD2```: Similar to ```ABCD1``` but less noisy with $\\xi=0.2$.\n",
    "* ```zac```: Zachary (karate club) graph, mainly for visualzation\n",
    "\n",
    "The small ```abcd``` graph was generated with the following parameters:\n",
    "\n",
    "```\n",
    "n = \"100\"                     # number of vertices in graph\n",
    "t1 = \"3\"                      # power-law exponent for degree distribution\n",
    "d_min = \"5\"                   # minimum degree\n",
    "d_max = \"15\"                  # maximum degree\n",
    "d_max_iter = \"1000\"           # maximum number of iterations for sampling degrees\n",
    "t2 = \"2\"                      # power-law exponent for cluster size distribution\n",
    "c_min = \"25\"                  # minimum cluster size\n",
    "c_max = \"50\"                  # maximum cluster size\n",
    "xi = \"0.2\"                    # fraction of edges to fall in background graph\n",
    "```\n",
    "\n",
    "The larger ```ABCD1``` and ```ABCD2``` graphs were generated with the following parameters:\n",
    "\n",
    "```\n",
    "n = \"1000\"                     # number of vertices in graph\n",
    "t1 = \"3\"                       # power-law exponent for degree distribution\n",
    "d_min = \"10\"                   # minimum degree\n",
    "d_max = \"100\"                  # maximum degree\n",
    "d_max_iter = \"1000\"            # maximum number of iterations for sampling degrees\n",
    "t2 = \"2\"                       # power-law exponent for cluster size distribution\n",
    "c_min = \"50\"                   # minimum cluster size\n",
    "c_max = \"150\"                  # maximum cluster size\n",
    "xi = \"0.6\" or \"0.2\"            # fraction of edges to fall in background graph\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the small ABCD graph and visualize\n",
    "\n",
    "Beware: node names are 1-based and are distinct from vertex ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read graph and communities\n",
    "abcd_edgelist = readdlm(datadir * \"ABCD/abcd_100.dat\", Int)\n",
    "c_abcd = readdlm(datadir * \"ABCD/abcd_100_comms.dat\", Int)[:, 2]\n",
    "n = length(c_abcd)\n",
    "\n",
    "abcd = SimpleGraph(n)\n",
    "for row in eachrow(abcd_edgelist)\n",
    "    add_edge!(abcd, row...)\n",
    "end\n",
    "\n",
    "## print a few stats\n",
    "println(nv(abcd), \" vertices, \", ne(abcd), \" edges, \", \"mean degree: \", mean(degree(abcd)),\n",
    "    \", no. of communities: \", maximum(c_abcd))\n",
    "\n",
    "## define the colors and node sizes here\n",
    "clean_graphplot(abcd,\n",
    "    node_size=15,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:white, :gray, :black][c_abcd],\n",
    "    edge_color=:lightgray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the larger ABCD graphs and visualize\n",
    "\n",
    "```ABCD1```: this is a larger graph with lots of noise edges ($\\xi$=0.6). Node colours refer to the communities.\n",
    "With this amount of noise, the communities are far from obvious on a 2-dimensional layout.\n",
    "\n",
    "```ABCD2```: the second graph has stronger communities ($\\xi$=0.2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read graph and communities\n",
    "abcd_edgelist = readdlm(datadir * \"ABCD/abcd_1000.dat\", Int)\n",
    "c_abcd1 = readdlm(datadir * \"ABCD/abcd_1000_comms.dat\", Int)[:, 2]\n",
    "n = length(c_abcd1)\n",
    "\n",
    "ABCD1 = SimpleGraph(n)\n",
    "for row in eachrow(abcd_edgelist)\n",
    "    add_edge!(ABCD1, row...)\n",
    "end\n",
    "\n",
    "## print a few stats\n",
    "println(nv(ABCD1), \" vertices, \", ne(ABCD1), \" edges, \", \"mean degree: \", mean(degree(ABCD1)),\n",
    "    \", no. of communities: \", maximum(c_abcd1))\n",
    "\n",
    "## define the colors and node sizes here\n",
    "clean_graphplot(ABCD1,\n",
    "    node_size=15,\n",
    "    node_strokewidth=1,\n",
    "    node_color=c_abcd1,\n",
    "    node_attr=(colormap=:lightrainbow,),\n",
    "    edge_color=:lightgray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read graph and communities\n",
    "abcd_edgelist = readdlm(datadir * \"ABCD/abcd_1000_xi2.dat\", Int)\n",
    "c_abcd2 = readdlm(datadir * \"ABCD/abcd_1000_xi2_comms.dat\", Int)[:, 2]\n",
    "n = length(c_abcd2)\n",
    "\n",
    "ABCD2 = SimpleGraph(n)\n",
    "for row in eachrow(abcd_edgelist)\n",
    "    add_edge!(ABCD2, row...)\n",
    "end\n",
    "\n",
    "## print a few stats\n",
    "println(nv(ABCD2), \" vertices, \", ne(ABCD2), \" edges, \", \"mean degree: \", mean(degree(ABCD2)),\n",
    "    \", no. of communities: \", maximum(c_abcd2))\n",
    "\n",
    "## define the colors and node sizes here\n",
    "clean_graphplot(ABCD2,\n",
    "    node_size=15,\n",
    "    node_strokewidth=1,\n",
    "    node_color=c_abcd2,\n",
    "    node_attr=(colormap=:lightrainbow,),\n",
    "    edge_color=:lightgray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph layouts \n",
    "\n",
    "We show a variety of graph layout functions available in `GraphMakie` on the Zachary graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zachary (karate club) graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zac_edgelist = readdlm(datadir * \"Zachary/zachary.edgelist\", Int) .+ 1\n",
    "c = vec(readdlm(datadir * \"Zachary/zachary.communities\", Int)) .+ 1\n",
    "n = length(c)\n",
    "zac = SimpleGraph(n)\n",
    "for row in eachrow(zac_edgelist)\n",
    "    add_edge!(zac, row...)\n",
    "end\n",
    "zac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spring (repulsion) layout\n",
    "clean_graphplot(zac,\n",
    "    layout=Spring(),\n",
    "    node_size=10,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:gray, :black][c],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(300, 300),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scalable Force Directed Placement layout\n",
    "clean_graphplot(zac,\n",
    "    layout=SFDP(),\n",
    "    node_size=10,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:gray, :black][c],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(300, 300),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stress Majorization layout\n",
    "clean_graphplot(zac,\n",
    "    layout=Stress(),\n",
    "    node_size=10,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:gray, :black][c],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(300, 300),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shell (circular) layout\n",
    "clean_graphplot(zac,\n",
    "    layout=Shell(),\n",
    "    node_size=10,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:gray, :black][c],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(300, 300),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grid layout\n",
    "clean_graphplot(zac,\n",
    "    layout=SquareGrid(),\n",
    "    node_size=10,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:gray, :black][c],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(300, 300),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spectral layout\n",
    "clean_graphplot(zac,\n",
    "    layout=Spectral(dim=2),\n",
    "    node_size=10,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:gray, :black][c],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(300, 300),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and compare several embeddings -- Zachary graph\n",
    "\n",
    "We run a few graph embedding algorithms on the Zachary graph with\n",
    "different parameters. \n",
    "\n",
    "For example, we try different embedding dimensions.\n",
    "\n",
    "We run the following:\n",
    "* node2vec with different values for $p$ and $q$\n",
    "* HOPE with different similarities\n",
    "* Laplacian Eigenmaps (LE)\n",
    "\n",
    "For each embedding, we use the communities obtained with **ECG** along with the **CGE** framework to compute the **graph embedding divergence** with the **CGE** Julia package. We visualize some good and bad results w.r.t. the global divergence score.\n",
    "\n",
    "For embeddings with low divergence, we see good separation of the communities (even in 2-dim projection, using **UMAP**), while this is not the case for embeddings with high divergence.\n",
    "\n",
    "Since we are going to compare embeddings for several graphs, we write the procedure as a function below. This function keeps a local copy of the best (`_embed_best`) and worst (`_embed_worst`) embeddings on disk, and returns the JS divergence (including local) for every test.\n",
    "\n",
    "#### Windows users:\n",
    "\n",
    "change ```cp``` to ```copy``` below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### compare several embedding methods\n",
    "function test_embeddings(\n",
    "    G,\n",
    "    edgefile::String,\n",
    "    commfile::String;\n",
    "    run_hope::Bool=true,\n",
    "    run_le::Bool=true,\n",
    "    run_n2v::Bool=true,\n",
    "    Dims::Vector{Int}=[2, 4, 8],\n",
    "    local_flag::Bool=false,\n",
    "    verbose::Bool=true,\n",
    "    seed::Int=123\n",
    ")\n",
    "    L = Vector{Any}[]  # to store results\n",
    "    best_jsd = 1.0\n",
    "    worst_jsd = 0.0\n",
    "\n",
    "    if run_hope\n",
    "        for dim in Dims, sim in [\"katz\", \"ppr\", \"cn\", \"aa\"]\n",
    "            X = Hope(G, sim, dim)\n",
    "            saveEmbedding(X, G)\n",
    "            div = JS(edgefile, commfile, \"_embed\")\n",
    "            jsd = local_flag ? div[2] : div[1]\n",
    "            if verbose\n",
    "                println(\"HOPE: dim=$dim sim=$sim jsd=$jsd\")\n",
    "            end\n",
    "            if jsd < best_jsd\n",
    "                run(`cp _embed _embed_best`)\n",
    "                best_jsd = jsd\n",
    "            end\n",
    "            if jsd > worst_jsd\n",
    "                run(`cp _embed _embed_worst`)\n",
    "                worst_jsd = jsd\n",
    "            end\n",
    "            push!(L, [dim, \"hope\", sim, div[1], div[2]])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if run_le\n",
    "        for dim in Dims\n",
    "            X = LE(G, dim)\n",
    "            saveEmbedding(X, G)\n",
    "            div = JS(edgefile, commfile, \"_embed\")\n",
    "            jsd = local_flag ? div[2] : div[1]\n",
    "            if verbose\n",
    "                println(\"LE: dim=$dim jsd=$jsd\")\n",
    "            end\n",
    "            if jsd < best_jsd\n",
    "                run(`cp _embed _embed_best`)\n",
    "                best_jsd = jsd\n",
    "            end\n",
    "            if jsd > worst_jsd\n",
    "                run(`cp _embed _embed_worst`)\n",
    "                worst_jsd = jsd\n",
    "            end\n",
    "            push!(L, [dim, \"le\", \" \", div[1], div[2]])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if run_n2v\n",
    "        for dim in Dims, (p, q) in [(1, 0.5), (0.5, 1), (1, 1)]\n",
    "            cmd = `$(PyCall.python) ./n2v_to_file.py $(edgefile) $(dim) $(p) $(q) $(seed)`\n",
    "            run(pipeline(cmd, stderr=Pipe()))\n",
    "            div = JS(edgefile, commfile, \"_embed\")\n",
    "            jsd = local_flag ? div[2] : div[1]\n",
    "            if verbose\n",
    "                println(\"n2v: dim=$dim p=$p q=$q jsd=$jsd\")\n",
    "            end\n",
    "            if jsd < best_jsd\n",
    "                run(`cp _embed _embed_best`)\n",
    "                best_jsd = jsd\n",
    "            end\n",
    "            if jsd > worst_jsd\n",
    "                run(`cp _embed _embed_worst`)\n",
    "                worst_jsd = jsd\n",
    "            end\n",
    "            push!(L, [dim, \"n2v\", \"$p $q\", div[1], div[2]])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    D = DataFrame(permutedims(hcat(L...)), [:dim, :algo, :param, :jsd, :local_jsd])\n",
    "    if local_flag\n",
    "        sort!(D, :local_jsd)\n",
    "    else\n",
    "        sort!(D, :jsd)\n",
    "    end\n",
    "    return D\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below takes about one minute to run as several embeddings are tested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D = test_embeddings(zac,\n",
    "    datadir * \"Zachary/zachary.edgelist\",\n",
    "    datadir * \"Zachary/zachary.ecg\",\n",
    "    Dims=[2, 4])\n",
    "first(D, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot top results\n",
    "l = embed2layout(\"_embed_best\", 123)\n",
    "clean_graphplot(zac,\n",
    "    layout=l,\n",
    "    node_size=10,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:gray, :black][c],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(300, 300),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## plot result with largest divergence\n",
    "l = embed2layout(\"_embed_worst\", 123)\n",
    "clean_graphplot(zac,\n",
    "    layout=l,\n",
    "    node_size=10,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:gray, :black][c],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(300, 300),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare embeddings - small ABCD  graph\n",
    "\n",
    "This is the same exercise as what we did above, this time for the 100-nodes ABCD graph.\n",
    "\n",
    "We look at slightly higher embedding dimension as there are more nodes than the Zachary graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### effect of local divergence score\n",
    "\n",
    "So far we considered the global Jenssen-Shannon divergence, where the objective is to preserve the community structure.\n",
    "\n",
    "We show the best result with respect to the global divergence below, and we see that it preserves the community structure. We may want better separation of the nodes within community, based on their connectivity. This is what the local Jenssen-Shannon divergence can provide. \n",
    "\n",
    "Below we also show an embedding with lower local divergence. The result is an embedding that still preserves community structure, but nodes within community are more separated than with the global divergence.\n",
    "\n",
    "The code below takes about one minute to run as several embeddings are tested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D = test_embeddings(abcd,\n",
    "    datadir * \"ABCD/abcd_100.dat\",\n",
    "    datadir * \"ABCD/abcd_100.ecg\",\n",
    "    Dims=[2, 16])\n",
    "first(D, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyPlot.loglog(D.jsd ./ minimum(D.jsd), D.local_jsd ./ minimum(D.local_jsd), \"o\", color=\"black\", base=2)\n",
    "xlabel(\"Global divergence score (normalized)\", fontsize=14)\n",
    "ylabel(\"Local divergence score (normalized)\", fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot result with lowest global JS divergence\n",
    "l = embed2layout(\"_embed_best\", 123)\n",
    "clean_graphplot(abcd,\n",
    "    layout=l,\n",
    "    node_size=10,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:white, :lightgray, :black][c_abcd],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(300, 300),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## look at results with low local divergence\n",
    "first(sort(D, \"local_jsd\"), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot one of the top ones\n",
    "X = Hope(abcd, \"ppr\", 16)\n",
    "saveEmbedding(X, abcd)\n",
    "l = embed2layout(\"_embed\", 123)\n",
    "clean_graphplot(abcd,\n",
    "    layout=l,\n",
    "    node_size=10,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:white, :lightgray, :black][c_abcd],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(300, 300),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last(D, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot one of the bottom ones\n",
    "X = Hope(abcd, \"katz\", 2)\n",
    "saveEmbedding(X, abcd)\n",
    "l = embed2layout(\"_embed\", 123)\n",
    "clean_graphplot(abcd,\n",
    "    layout=l,\n",
    "    node_size=10,\n",
    "    node_strokewidth=1,\n",
    "    node_color=[:white, :lightgray, :black][c_abcd],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(300, 300),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on the larger ABCD graph\n",
    "\n",
    "We saw that embedding can be used to visualize graphs. Below we use graph embedding as a way to define a feature vector (a point in vector space) for each node, and we use this representation to train a classifier.\n",
    "\n",
    "We use the ```ABCD1``` (noisy) graph.\n",
    "\n",
    "We use a saved embedding (48-dimension running HOPE with \"ppr\" similarity).\n",
    "\n",
    "We split the data (the nodes) into a training and testing set. Using the training set, we build a **random forest** classification model where the classes are the communities for each node.\n",
    "\n",
    "We then apply this model to the test set.\n",
    "\n",
    "The graph has 1000 nodes; we use 250 nodes for training and the rest for testing; we obtain good accuracy (around 90%).\n",
    "\n",
    "What do you think will happen if we increase/decrease the size of the training set?\n",
    "\n",
    "We also report the confusion matrix (details in section 6.7 of the book).\n",
    "\n",
    "Finally, we compare with results obtained via a baseline **random** classifier where we supply the correct number of classes and their relative sizes. We see that our random forest model gives much better results than with a random classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load a saved embedding for the ABCD graph\n",
    "X = readEmbedding(datadir * \"ABCD/abcd_1000_embed_best\", true)\n",
    "y = c_abcd1\n",
    "\n",
    "## train/test split\n",
    "Random.seed!(1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, random_state=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 100 trees\n",
    "model = RandomForestClassifier(n_estimators=100,\n",
    "    bootstrap=true,\n",
    "    max_features=\"sqrt\")\n",
    "# Fit on training data\n",
    "ScikitLearn.fit!(model, X_train, y_train)\n",
    "\n",
    "# Class predictions on test data\n",
    "y_pred = ScikitLearn.predict(model, X_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## percent correct -- this can vary slightly as we split train/test randomly\n",
    "println(\"accuracy:\", sum(diag(cm)) / sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare with random classifier\n",
    "## assuming we know the number of classes (12)\n",
    "## and using class proportions from training data\n",
    "ctr = countmap(y_train)\n",
    "x = [ctr[i] for i in 1:12]\n",
    "s = sum(x)\n",
    "p = [i / s for i in x]\n",
    "acc = []\n",
    "for rep in 1:30 ## repeat 30 times, we\"ll take average\n",
    "    y_pred = [x + 1 for x in StatsBase.sample(1:12, Weights(p), length(y_test))]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    push!(acc, sum(diag(cm)) / sum(cm))\n",
    "end\n",
    "## accuracy\n",
    "println(\"Average accuracy:\", mean(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering in embedded space\n",
    "\n",
    "Again using the larger (noisy) ```ABCD1``` graph, we run some graph clustering algorithms (Leiden and ECG).\n",
    "\n",
    "We run each algorithm several times are report two statistics:\n",
    "* the modularity score of the clustering, and\n",
    "* the adjusted mutual information (AMI) score when comparing with ground-truth (GT) communities.\n",
    "\n",
    "We also try seeding Leiden with initial clusters obtained with k-means (in embedded space) where k=100.\n",
    "\n",
    "We also run k-means (with 5 choices for k, including correct value) in embedded vector space.\n",
    "\n",
    "We use the same saved embedding than in the previous experiment. \n",
    "\n",
    "This time, we report:\n",
    "* the CHS score (Calinski and Harabasz score, or Variance Ratio Criterion); higher value is indicative of better quality clustering\n",
    "* the adjusted mutual information (AMI) score when comparing with ground-truth (GT) communities.\n",
    "\n",
    "In practical applications where we do not have access to the ground-truth, we need some other measure to quantify the quality of the clusters we obtain, such as modularity or CHS. We report AMI for runs with highest score (w.r.t. modularity or CHS) for each clustering algorithm.\n",
    "\n",
    "The cell below can take a few minutes to run. Results are provided in a .ser file. Uncomment the cell below to re-run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd_edgelist = readdlm(datadir * \"ABCD/abcd_1000.dat\", Int)\n",
    "c_abcd1 = readdlm(datadir * \"ABCD/abcd_1000_comms.dat\", Int)[:, 2]\n",
    "n = length(c_abcd1)\n",
    "ig_ABCD1 = ig.Graph()\n",
    "ig_ABCD1.add_vertices(n)\n",
    "ig_ABCD1.add_edges([(src - 1, dst - 1) for (src, dst) in eachrow(abcd_edgelist)])\n",
    "set!(ig_ABCD1.vs, \"comm\", c_abcd1);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## load the saved low divergence embedding\n",
    "ABCD1_emb = readEmbedding(datadir*\"ABCD/abcd_1000_embed_best\", true)\n",
    "\n",
    "L = Vector{Any}[] ## to store results\n",
    "K = [6,9,12,15,24] ## for k-means (real number of clusters is 12)\n",
    "Repeats = 30 ## number of repeats; decrease for faster run\n",
    "\n",
    "for i in 1:Repeats\n",
    "\n",
    "    ## run kmeans\n",
    "    for k in K\n",
    "        cl = ScikitLearn.fit!(KMeans(n_clusters=k, n_init=10), ABCD1_emb).labels_\n",
    "        d = Dict(enumerate(cl))\n",
    "        scr = calinski_harabasz_score(ABCD1_emb, cl) ## CHS\n",
    "        ami = adjusted_mutual_info_score(get(ig_ABCD1.vs,\"comm\"), cl) ## AMI vs ground truth\n",
    "        push!(L,[\"km\"*string(k),scr,ami])\n",
    "    end\n",
    "    ## ECG\n",
    "    ec = ig_ABCD1.community_ecg().membership\n",
    "    scr = ig_ABCD1.modularity(ec) ## modularity\n",
    "    ami = adjusted_mutual_info_score(get(ig_ABCD1.vs,\"comm\"),ec) ## AMI vs ground truth\n",
    "    push!(L,[\"ecg\",scr,ami])\n",
    "\n",
    "    ## Leiden\n",
    "    lei = ig_ABCD1.community_leiden(objective_function=\"modularity\")\n",
    "    scr = ig_ABCD1.modularity(lei) ## modularity\n",
    "    ami = adjusted_mutual_info_score(get(ig_ABCD1.vs,\"comm\"),lei.membership) ## AMI vs ground truth\n",
    "    push!(L,[\"lei\", scr, ami])\n",
    "\n",
    "    ## kmeans+Leiden\n",
    "    cl = ScikitLearn.fit!(KMeans(n_clusters=100, n_init=10), ABCD1_emb).labels_\n",
    "    d = Dict(enumerate(cl))\n",
    "    lei = ig_ABCD1.community_leiden(objective_function=\"modularity\", initial_membership=cl)\n",
    "    scr = ig_ABCD1.modularity(lei) ## modularity\n",
    "    ami = adjusted_mutual_info_score(get(ig_ABCD1.vs,\"comm\"),lei.membership) ## AMI vs ground truth\n",
    "    push!(L,[\"km+lei\", scr, ami])\n",
    "end\n",
    "## store in dataframe\n",
    "D = DataFrame(permutedims(hcat(L...)), [\"algo\",\"scr\",\"ami\"])\n",
    "\n",
    "## save results\n",
    "serialize(datadir*\"ABCD/abcd_1000_clustering_jl.ser\", D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load results from above cell\n",
    "## load test results\n",
    "D = deserialize(datadir * \"ABCD/abcd_1000_clustering_jl.ser\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AMI results with best scoring clustering for the 3 algorithms\n",
    "x = first(sort(filter(row -> startswith(row.algo, \"km\"), D), :scr, rev=true).ami)\n",
    "println(\"K-Means best, AMI:\", x)\n",
    "\n",
    "x = first(sort(D[D.algo.==\"lei\", :], :scr, rev=true).ami)\n",
    "println(\"Leiden best, AMI:\", x)\n",
    "\n",
    "x = first(sort(D[D.algo.==\"ecg\", :], :scr, rev=true).ami)\n",
    "println(\"ECG best, AMI:\", x)\n",
    "\n",
    "x = first(sort(D[D.algo.==\"km+lei\", :], :scr, rev=true).ami)\n",
    "println(\"K-Means+Leiden best, AMI:\", x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we summarize the results for all runs in a boxplot. \n",
    "\n",
    "Results with k-means are best when we supply the correct number of clusters (12). \n",
    "\n",
    "We see excellent results when using ECG or Leiden, in particular with the initial partition provided by k-means with large k=100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## boxplot the AMI results\n",
    "algos = [\"km6\", \"km9\", \"km12\", \"km15\", \"km24\", \"lei\", \"km+lei\", \"ecg\"]\n",
    "colnames = [\"k-means(6)\", \"k-means(9)\", \"k-means(12)\", \"k-means(15)\",\n",
    "    \"k-means(24)\", \"Leiden\", \"k-Leiden\", \"ECG\"]\n",
    "\n",
    "A = [D[D.algo.==a, :ami] for a in algos]\n",
    "B = DataFrame(A, colnames)\n",
    "PyPlot.boxplot(Matrix(B)', labels=names(B))\n",
    "PyPlot.xticks(rotation=30)\n",
    "ylabel(\"Adjusted Mutual Information (AMI)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we cluster using the DBSCAN algorithm after reducing the dimension via UMAP.\n",
    "Running a good dimension reduction algorithm such as UMAP before clustering in vector space often gives better results. This is for illustration and you can experiment with different choices of parameter below.\n",
    "\n",
    "DBSCAN does not always cluster all the points, which can be quite useful in practice. Some points can be tagged as *outliers*. Below, we compute AMI with and without the outlying points. \n",
    "Result without outliers is quite good (recall that unlike k-means, we do not supply the number of communities here).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the saved low divergence embedding\n",
    "ABCD1_emb = readEmbedding(datadir * \"ABCD/abcd_1000_embed_best\", true)\n",
    "\n",
    "## We tried a few \"min_sample\" and \"dim\" with good results using 8 and 16 resp.\n",
    "top = 0\n",
    "e_top = 0\n",
    "dim = 16  ## reduce to this dimension\n",
    "ms = 8    ## min-sample in DBSCAN\n",
    "U = Matrix(umap(ABCD1_emb', dim)')\n",
    "## We try various \"eps\" and pick the best via calinski_harabasz_score (CHS)\n",
    "for e in 0.4:0.0025:0.5\n",
    "    cl = ScikitLearn.fit!(DBSCAN(eps=e, min_samples=ms), U)\n",
    "    labels = cl.labels_\n",
    "    s = calinski_harabasz_score(U, labels) ## CHS score\n",
    "    if s > top\n",
    "        top = s\n",
    "        e_top = e\n",
    "    end\n",
    "end\n",
    "## result with best CHS score\n",
    "cl = ScikitLearn.fit!(DBSCAN(eps=e_top, min_samples=ms), U)\n",
    "b = [x > -1 for x in cl.labels_]\n",
    "l = get(ig_ABCD1.vs, \"comm\")\n",
    "v = [l[i] for i in 1:length(l) if b[i]]\n",
    "println(\"AMI without outliers:\", adjusted_mutual_info_score(v, cl.labels_[b]))\n",
    "println(\"AMI with outliers:\", adjusted_mutual_info_score(l, cl.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction\n",
    "\n",
    "Given a graph, link prediction aims at finding pairs of nodes not linked by an edge that are the most likely to actually have an edge between them. This could happen if we have a partial view of a graph. For example if edges \n",
    "are observed over some period of time, which new edges are we most likely to observe next?\n",
    "\n",
    "In order to simulate this situation, we take the ```ABCD1``` graph with 1,000 nodes and drop 10% of the edges.\n",
    "We re-compute the embedding (since the graph has changed), train a logistic regression model using pairs\n",
    "of nodes with and without an edge, and apply the model to a test set consisting of the dropped edges, and other \n",
    "pairs of nodes not linked by an edge.\n",
    "\n",
    "Given node embeddings $e(u)$ and $e(v)$, a representation for the node pair $(u,v)$ is obtained via some binary operator $B(e(u),e(v))$. We defined the same 4 operators as in https://arxiv.org/pdf/1607.00653.pdf at the beginning of this notebook, and will use the **Hadamar** operator in the experiments below.\n",
    "\n",
    "We build the training data by considering all edges in the reduced graph, and an equal number of node pairs without an edge. From this data, we build a logistic regression model to predict edges vs non-edges. We then apply the model to the test set which includes the dropped edges, and the same number of non-edges.\n",
    "\n",
    "First we tried with the ```ABCD1``` graph with noise parameter $\\xi=0.6$.\n",
    "Given the large number of \"noise\" edges, results are not very good, as expected.\n",
    "\n",
    "We do another set of tests, this time with the ```ABCD2``` graph with lower noise parameter $\\xi=0.2$, with better results.\n",
    "\n",
    "Since we are going to run this experiment for several graphs, we write the procedure as a function below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default: model with Hadamard binary operator (other choices are \"l1\", \"l2 and \"avg\")\n",
    "## test_eid: the list of edges in the test set (dropped edges)\n",
    "## Emb: the embedding\n",
    "function link_pred_exp(G::SimpleGraph, test_eid::Vector{Int}, Emb::Matrix{Float64};\n",
    "    seed::Int=123, op::String=\"had\",\n",
    "    return_plot::Bool=false,\n",
    "    verbose::Bool=true)\n",
    "    ## make a copy of the graph and drop some edges\n",
    "    Gp = deepcopy(G)\n",
    "    gp_e = collect(edges(Gp))\n",
    "    for eid in test_eid\n",
    "        src, dst = gp_e[eid].src, gp_e[eid].dst\n",
    "        rem_edge!(Gp, src, dst)\n",
    "    end\n",
    "    X = collect.(eachrow(Emb))\n",
    "\n",
    "    ## Build training data, first the edges\n",
    "    F = [binary_operator(X[src(e)], X[dst(e)], op) for e in edges(Gp)]\n",
    "    f = ones(Int, length(F))\n",
    "\n",
    "    ## then for equal number of non-edges (we over-sample to drop edges or collisions from the list)\n",
    "    n = length(F)\n",
    "    Random.seed!(seed)\n",
    "    non_edges = Set{Tuple{Int,Int}}()\n",
    "    while length(non_edges) < n\n",
    "        u, v = rand(1:nv(G), 2)\n",
    "        u == v && continue\n",
    "        u, v = min(u, v), max(u, v)\n",
    "        has_edge(Gp, u, v) && continue\n",
    "        push!(non_edges, (u, v))\n",
    "    end\n",
    "    append!(F, [binary_operator(X[u], X[v], op) for (u, v) in non_edges])\n",
    "    append!(f, zeros(Int, n))\n",
    "\n",
    "    ## train the model, here a logistic regression\n",
    "    logreg = LogisticRegression(random_state=seed)\n",
    "    ScikitLearn.fit!(logreg, hcat(F...)', f)\n",
    "\n",
    "    ## prepare test set, first with all dropped edges from G\n",
    "    g_e = collect(edges(G))\n",
    "    X_test = [binary_operator(X[g_e[i].src], X[g_e[i].dst], op) for i in test_eid]\n",
    "    y_test = ones(Int, length(X_test))\n",
    "\n",
    "    ## then for equal number of non-edges (we over-sample to drop edges and collisions from the list)\n",
    "    n = length(X_test)\n",
    "    Random.seed!(seed)\n",
    "    non_edges_test = Set{Tuple{Int,Int}}()\n",
    "    while length(non_edges_test) < n\n",
    "        u, v = rand(1:nv(G), 2)\n",
    "        u == v && continue\n",
    "        u, v = min(u, v), max(u, v)\n",
    "        has_edge(G, u, v) && continue\n",
    "        push!(non_edges_test, (u, v))\n",
    "    end\n",
    "    append!(X_test, [binary_operator(X[u], X[v], op) for (u, v) in non_edges_test])\n",
    "    append!(y_test, zeros(Int, n))\n",
    "\n",
    "    ## apply the model to test data\n",
    "    X_test_mat = Matrix(hcat(X_test...)')\n",
    "    _acc = ScikitLearn.score(logreg, X_test_mat, y_test)\n",
    "    probs = predict_proba(logreg, X_test_mat)[:, 2]\n",
    "    _auc = roc_auc_score(y_test, probs)\n",
    "    if verbose\n",
    "        println(\"Accuracy of logistic regression classifier with $op on test set: $(round(_acc, digits=2))\")\n",
    "        println(\"AUC: \", round(_auc, digits=4))\n",
    "    end\n",
    "    if return_plot\n",
    "        logit_roc_auc = roc_auc_score(y_test, predict_proba(logreg, X_test_mat)[:, 2])\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, predict_proba(logreg, X_test_mat)[:, 2])\n",
    "        PyPlot.figure()\n",
    "        PyPlot.plot(fpr, tpr, color=\"gray\", label=\"Logistic Regression (AUC = $(round(logit_roc_auc,digits=2)))\")\n",
    "        PyPlot.plot([0, 1], [0, 1], \"k--\")\n",
    "        PyPlot.xlim([0.0, 1.0])\n",
    "        PyPlot.ylim([0.0, 1.05])\n",
    "        PyPlot.xlabel(\"False Positive Rate\", fontsize=14)\n",
    "        PyPlot.ylabel(\"True Positive Rate\", fontsize=14)\n",
    "        PyPlot.title(\"\")\n",
    "        PyPlot.legend(loc=\"lower right\")\n",
    "    end\n",
    "    if !verbose\n",
    "        return _acc, _auc\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link prediction with noisy ABCD graph $\\xi = 0.6$\n",
    "\n",
    "The results are better than random, but not great; recall that $\\xi$=0.6, so the majority of edges are noise to start with, so link prediction is very hard in this case. We try with less noisy graph next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pick 10% edges at random for test set, save new graph as Gp\n",
    "Random.seed!(123)\n",
    "test_size = round(Int, 0.1 * ne(ABCD1))\n",
    "test_eid = StatsBase.sample(1:ne(ABCD1), test_size, replace=false)\n",
    "Gp = deepcopy(ABCD1)\n",
    "gp_e = collect(edges(Gp))\n",
    "for eid in test_eid\n",
    "    src, dst = gp_e[eid].src, gp_e[eid].dst\n",
    "    rem_edge!(Gp, src, dst)\n",
    "end\n",
    "\n",
    "## select a low divergence embedding (from separate tests)\n",
    "X = LE(Gp, 8)\n",
    "\n",
    "## run the experiment - link prediction\n",
    "link_pred_exp(ABCD1, test_eid, X, return_plot=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link prediction with less noisy ABCD graph $\\xi = 0.2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test all embeddings on the modified ```ABCD2``` graph, after removing the test set edges.\n",
    "\n",
    "We also perform the link prediction experiment for several different embeddings, and store the **accuracy** and **AUC** for each run.\n",
    "\n",
    "Again the cell below can take a few minutes - uncomment to run.\n",
    "\n",
    "We saved the results in a .ser file."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## pick 10% edges at random, save new graph ABCD2_sampled\n",
    "test_size = round(Int,.1*ne(ABCD2))\n",
    "Random.seed!(123) ## for reproducibility\n",
    "test_eid = StatsBase.sample(1:ne(ABCD2),test_size,replace=false)\n",
    "ABCD2_sampled = deepcopy(ABCD2)\n",
    "abcd2_e = collect(edges(ABCD2_sampled))\n",
    "for eid in test_eid\n",
    "    src, dst = abcd2_e[eid].src, abcd2_e[eid].dst\n",
    "    rem_edge!(ABCD2_sampled, src, dst)\n",
    "end\n",
    "\n",
    "## save edgelist and ecg communities for use by the framework\n",
    "Edges = Matrix(hcat([[e.src-1, e.dst-1] for e in edges(ABCD2_sampled)]...)')\n",
    "writedlm(\"_edges.dat\",Edges)\n",
    "ig_ABCD2_sampled = ig.Graph()\n",
    "ig_ABCD2_sampled.add_vertices(nv(ABCD2_sampled))\n",
    "ig_ABCD2_sampled.add_edges([(e.src-1,e.dst-1) for e in edges(ABCD2_sampled)])\n",
    "ecg = [x+1 for x in ig_ABCD2_sampled.community_ecg(ens_size=32, final=\"leiden\").membership]\n",
    "writedlm(\"_ecg.dat\",ecg)\n",
    "\n",
    "## test and rank some embeddings w.r.t. the local JS divergence score\n",
    "## on ABCD_sampled, i.e.  with 10% edges removed\n",
    "D = test_embeddings(ABCD2_sampled,\n",
    "    \"_edges.dat\",\n",
    "    \"_ecg.dat\",\n",
    "    Dims=[2,4,8],\n",
    "    local_flag=true)\n",
    "# link prediction for each embedding in turn\n",
    "L = []\n",
    "for x in eachrow(D)\n",
    "    if x.algo == \"le\"\n",
    "        X = LE(ABCD2_sampled, x.dim)\n",
    "        push!(L, link_pred_exp(ABCD2, test_eid, X, verbose=false))\n",
    "    elseif x.algo == \"hope\"\n",
    "        X = Hope(ABCD2_sampled, x.param, x.dim)\n",
    "        push!(L,link_pred_exp(ABCD2, test_eid, X, verbose=false))\n",
    "    else\n",
    "        p,q = parse.(Float64,split(x.param,\" \"))\n",
    "        cmd = `$(PyCall.python) ./n2v_to_file.py _edges.dat $(x.dim) $(p) $(q) 123`\n",
    "        run(pipeline(cmd,stderr=Pipe()))\n",
    "        X = readEmbedding(\"_embed\",true)\n",
    "        push!(L,link_pred_exp(ABCD2, test_eid, X, verbose=false))\n",
    "    end\n",
    "end\n",
    "D.acc = [x[1] for x in L]\n",
    "D.auc = [x[2] for x in L]\n",
    "\n",
    "# save data frame\n",
    "serialize(datadir*\"ABCD/abcd_1000_xi2_linkpred_jl.ser\",D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load results from pickle file\n",
    "D = deserialize(datadir * \"ABCD/abcd_1000_xi2_linkpred_jl.ser\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## accuracy values vary from about 60% to 83% - top values shown here\n",
    "first(sort(D, \"acc\", rev=true), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## kendall-tau divengence: Accuracy vs global/local divergence scores\n",
    "println(\"global divergence:\", corkendall(Float64.(D.jsd), D.acc))\n",
    "println(\"local divergence:\", corkendall(Float64.(D.local_jsd), D.acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_balls = size(D, 1)\n",
    "\n",
    "## normalize the scores (divide by the min values)\n",
    "x = D.jsd ./ minimum(D.jsd)\n",
    "y = D.local_jsd ./ minimum(D.local_jsd)\n",
    "\n",
    "## plot results as \"balls\" with area proportional to the accuracy\n",
    "acc = D.acc\n",
    "areas = [(25 * i - 10)^2 for i in acc]\n",
    "PyPlot.figure()\n",
    "PyPlot.scatter(x, y, s=areas, alpha=0.85, color=\"dimgrey\")\n",
    "PyPlot.xlabel(\"Global divergence score (normalized)\", fontsize=13)\n",
    "PyPlot.ylabel(\"Local divergence score (normalized)\", fontsize=13)\n",
    "\n",
    "# pick markersize to approximate the size ball sizes corresponding to 60% and 83% accuracy\n",
    "p1 = PyPlot.plot([], [], color=\"white\", marker=\"o\", markersize=6, markerfacecolor=\"dimgrey\")\n",
    "p2 = PyPlot.plot([], [], color=\"white\", marker=\"o\", markersize=11, markerfacecolor=\"dimgrey\")\n",
    "PyPlot.legend((p1[1], p2[1]), (\"50%\", \"80%\",), numpoints=1, loc=4, title=\"test set accuracy\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## redo experiment for best case and draw the ROC curve\n",
    "\n",
    "## low divergence embedding from tests in previous cells\n",
    "Edges = Matrix(hcat([[e.src - 1, e.dst - 1] for e in edges(ABCD2)]...)')\n",
    "writedlm(\"_edges.dat\", Edges)\n",
    "cmd = `$(PyCall.python) ./n2v_to_file.py _edges.dat 8 1.0 0.5 123`\n",
    "run(pipeline(cmd, stderr=Pipe()))\n",
    "X = readEmbedding(\"_embed\", true)\n",
    "link_pred_exp(ABCD2, test_eid, X, return_plot=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now try with high local divergence embedding from test in previous cell\n",
    "X = Hope(ABCD2, \"cn\", 2)\n",
    "link_pred_exp(ABCD2, test_eid, X, return_plot=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning - using classification accuracy to compare embeddings\n",
    "\n",
    "We saw earlier an **unsupervised** method for selecting good graph embeddings where we computed some divergence score. \n",
    "\n",
    "In **supervised** case, it is usually better to take advantage of the known labels to compare embeddings.\n",
    "\n",
    "With this experiment, we do the following using the 1,000 nodes ```ABCD1``` graph. Recall that in this case, the class is the ground-truth community for each node. \n",
    "\n",
    "* we partition the nodes into training, validation and test sets in proportion 25%/25%/50%\n",
    "* we generate 40 different embeddings (3 algorithms, different parameters)\n",
    "* from each embedding, \n",
    "  * we compute the JS divergences (unsupervised score)\n",
    "  * we use the training data to build a classification model (random forest)\n",
    "  * we apply this model to the validation set \n",
    "  * we compute the accuracy score (supervised score) \n",
    "\n",
    "The code to do this is commented out in the cell below as this can take several minutes to run. \n",
    "A serialized results are included in data directory and can be read directly."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# train/val/test, split the id\"s in proportion 25/25/50\n",
    "Random.seed!(123)\n",
    "ids = collect(1:nv(ABCD1))\n",
    "id_trainval, id_test = train_test_split(ids, test_size=.5)     ## split test\n",
    "id_train, id_val = train_test_split(id_trainval, test_size=.5) ## split train/val\n",
    "\n",
    "y_all = c_abcd1\n",
    "y_train = [y_all[i] for i in id_train]\n",
    "y_trainval = [y_all[i] for i in id_trainval]\n",
    "y_val = [y_all[i] for i in id_val]\n",
    "y_test = [y_all[i] for i in id_test]\n",
    "\n",
    "## loop over several algos, parameters\n",
    "L = Vector{Any}[]\n",
    "DIM = [2,4,8,16,32]\n",
    "\n",
    "## LE\n",
    "println(\"running LE\")\n",
    "for dim in DIM\n",
    "    X = LE(ABCD1, dim)\n",
    "    X_train = X[id_train,:]\n",
    "    X_val = X[id_val,:]\n",
    "    saveEmbedding(X,ABCD1)\n",
    "    jsd=JS(datadir*\"ABCD/abcd_1000.dat\",datadir*\"ABCD/abcd_1000.ecg\",\"_embed\",true)\n",
    "\n",
    "    # Create the model with 100 trees\n",
    "    model = RandomForestClassifier(n_estimators=100,\n",
    "                                   bootstrap = true,\n",
    "                                   max_features = \"sqrt\",\n",
    "                                   random_state=123)\n",
    "    # Fit on training data\n",
    "    ScikitLearn.fit!(model, X_train, y_train)\n",
    "\n",
    "    # Actual class predictions\n",
    "    y_pred = ScikitLearn.predict(model, X_val)\n",
    "    acc = accuracy_score(y_val,y_pred)\n",
    "    push!(L,[dim,\"le\",0,jsd[1],jsd[2],acc])\n",
    "end\n",
    "\n",
    "## HOPE\n",
    "println(\"running HOPE\")\n",
    "for dim in DIM\n",
    "    for sim in [\"katz\",\"aa\",\"cn\",\"ppr\"]\n",
    "        X = Hope(ABCD1,sim,dim)\n",
    "        X_train = X[id_train,:]\n",
    "        X_val = X[id_val,:]\n",
    "        saveEmbedding(X,ABCD1)\n",
    "        jsd = JS(datadir*\"ABCD/abcd_1000.dat\",datadir*\"ABCD/abcd_1000.ecg\",\"_embed\",true)\n",
    "\n",
    "        # Create the model with 100 trees\n",
    "        model = RandomForestClassifier(n_estimators=100,\n",
    "                                       bootstrap = true,\n",
    "                                       max_features = \"sqrt\",\n",
    "                                       random_state=123)\n",
    "        # Fit on training data\n",
    "        ScikitLearn.fit!(model,X_train, y_train)\n",
    "\n",
    "        # Actual class predictions\n",
    "        y_pred = ScikitLearn.predict(model, X_val)\n",
    "        acc = accuracy_score(y_val,y_pred)\n",
    "        push!(L,[dim,\"hope\",sim,jsd[1],jsd[2],acc])\n",
    "    end\n",
    "end\n",
    "\n",
    "## node2vec\n",
    "println(\"running node2vec\")\n",
    "for dim in DIM\n",
    "    for (p,q) in [(1,.5),(.5,1),(1,1)]\n",
    "        cmd = `$(PyCall.python) ./n2v_to_file.py $(datadir*\"ABCD/abcd_1000.dat\") $(dim) $(p) $(q) 123`\n",
    "        run(pipeline(cmd,stderr=Pipe()))\n",
    "        X = readEmbedding(\"_embed\",true)\n",
    "        jsd = JS(datadir*\"ABCD/abcd_1000.dat\",datadir*\"ABCD/abcd_1000.ecg\",\"_embed\",true)\n",
    "        X_train = X[id_train,:]\n",
    "        X_val = X[id_val,:]\n",
    "        # Create the model with 100 trees\n",
    "        model = RandomForestClassifier(n_estimators=100,\n",
    "                                       bootstrap = true,\n",
    "                                       max_features = \"sqrt\",\n",
    "                                       random_state=123)\n",
    "\n",
    "        # Fit on training data\n",
    "        ScikitLearn.fit!(model, X_train, y_train)\n",
    "\n",
    "        # Actual class predictions\n",
    "        y_pred = ScikitLearn.predict(model,X_val)\n",
    "        acc = accuracy_score(y_val,y_pred)\n",
    "        push!(L,[dim,\"n2v\",string(p)*\" \"*string(q),jsd[1],jsd[2],acc])\n",
    "    end\n",
    "end\n",
    "## save L and train/val/test ids\n",
    "serialize(datadir*\"ABCD/abcd_1000_embeddings_jl.ser\", (id_train,id_val,id_trainval,id_test,L))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load results from the above\n",
    "id_train, id_val, id_trainval, id_test, L = deserialize(datadir * \"ABCD/abcd_1000_embeddings_jl.ser\")\n",
    "\n",
    "## labels for train/validation/test sets\n",
    "y_all = c_abcd1\n",
    "y_train = [y_all[i] for i in id_train]\n",
    "y_trainval = [y_all[i] for i in id_trainval] ## training+validation sets\n",
    "y_val = [y_all[i] for i in id_val]\n",
    "y_test = [y_all[i] for i in id_test];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we compute the rank-based  Kendall-tau correlation between the divergence score (unsupervised) and the accuracy score (supervised). We see negative correlation which is to be expected since respectively low divergence and high accuracy are better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation: divergence and accuracy\n",
    "R = DataFrame(permutedims(hcat(L...)), [\"dim\", \"algo\", \"param\", \"div_glb\", \"div_loc\", \"val_acc\"])\n",
    "println(\"global divergence:\", corkendall(Float64.(R.div_glb), Float64.(R.val_acc)))\n",
    "println(\"local divergence:\", corkendall(Float64.(R.div_loc), Float64.(R.val_acc)))\n",
    "first(R, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next 2 cells, we show the top results on the validation set respectively for the divergence and accuracy scores. We also add two columns with the respective ranks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort by JS-divergence on validation set\n",
    "df_size = nrow(R)\n",
    "R = sort(R, :div_glb)\n",
    "R.rank_div_glb = 1:df_size\n",
    "R = sort(R, :div_loc)\n",
    "R.rank_div_loc = 1:df_size\n",
    "R.rank_div = (R.rank_div_glb .+ R.rank_div_loc) ./ 2\n",
    "R = sort(R, :rank_div)\n",
    "first(R, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort by Accuracy on validation set\n",
    "R = sort(R, :val_acc, rev=true)\n",
    "R.rank_val_acc = 1:nrow(R)\n",
    "first(R, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show the lowest accuracy results. We see that there is quite a range of accuracy on the validation set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last(R, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Apply the models to the test set. \n",
    "\n",
    "In the previous cells, we built a table ranking the different algorithms w.r.t. accuracy and divergence using the training and validation sets. Here, we go through the same algorithms in (decreasing) order of accuracy, re-train with each model using the training and validation sets, and apply to the test set.\n",
    "\n",
    "A serialized results are provided.\n",
    "\n",
    "Uncomment the cell below to re-run.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## retrain and score in order of validation set\"s accuracy\n",
    "Random.seed!(123)\n",
    "top_acc = []\n",
    "for i in 1:nrow(R)\n",
    "    dim, algo, param, div_g, div_l, acc, rk_dg, rk_dl, rk_d, rk_a = R[i,:]\n",
    "    if algo==\"n2v\"\n",
    "        s = split(param, \" \")\n",
    "        p = parse(Float64,s[1])\n",
    "        q = parse(Float64,s[2])\n",
    "        cmd = `$(PyCall.python) ./n2v_to_file.py $(datadir*\"ABCD/abcd_1000.dat\") $(dim) $(p) $(q) 123`\n",
    "        run(pipeline(cmd,stderr=Pipe()))\n",
    "        X = readEmbedding(\"_embed\",true)\n",
    "    elseif algo==\"hope\"\n",
    "        X = Hope(ABCD1, param, dim)\n",
    "    elseif algo==\"le\"\n",
    "        X = LE(ABCD1, dim)\n",
    "    end\n",
    "    X_trainval = X[id_trainval,:]\n",
    "    X_test = X[id_test,:]\n",
    "    # Create the model with 100 trees\n",
    "    model = RandomForestClassifier(n_estimators=100,\n",
    "                                   bootstrap = true,\n",
    "                                   max_features = \"sqrt\",\n",
    "                                   random_state=123)\n",
    "    # Fit on training data\n",
    "    ScikitLearn.fit!(model,X_trainval, y_trainval)\n",
    "\n",
    "    # Actual class predictions\n",
    "    y_pred = ScikitLearn.predict(model,X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    push!(top_acc, acc)\n",
    "end\n",
    "serialize(datadir*\"ABCD/abcd_1000_embeddings_test_jl.ser\", top_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load test results\n",
    "top_acc = deserialize(datadir * \"ABCD/abcd_1000_embeddings_test_jl.ser\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add test results\n",
    "R.test_acc = top_acc\n",
    "println(\"mean accuracy over all models on the test set: \", mean(R.test_acc))\n",
    "\n",
    "## top results w.r.t. accuracy on the test set\n",
    "R = sort(R, :test_acc, rev=true)\n",
    "R.rank_test_acc = 1:nrow(R)\n",
    "first(R, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last(R, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we take the top-10 algorithms w.r.t. divergence on the validation set, and the top-10 algorithms w.r.t. accuracy on the validation set. \n",
    "\n",
    "We then plot the distribution of results (accuracy) over the test set via box-plots.\n",
    "\n",
    "As expected, using accuracy (supervised score) yields better results, but the results obtained with the (unsupervised) global divergence score are also quite good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## top results on test set w.r.t. divergence on validation set\n",
    "R = sort(R, :rank_div)\n",
    "top_div = R.test_acc[1:10]\n",
    "\n",
    "## top results on test set w.r.t. accuracy on validation set\n",
    "R = sort(R, :val_acc, rev=true)\n",
    "top_acc = R.test_acc[1:10]\n",
    "\n",
    "## pd with mu\n",
    "B = DataFrame(hcat([top_acc, top_div]...),\n",
    "    [\"Top-10 validation set accuracy\", \"Top-10 divergence score\"])\n",
    "PyPlot.boxplot(Matrix(B), labels=names(B))\n",
    "PyPlot.ylim((0, 1))\n",
    "PyPlot.ylabel(\"Test set accuracy\", fontsize=14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to compare the results is to plot the accuracy results on the test set as a function of the rank of the algorithms w.r.t. the accuracy score on the validation set (next cell) or the divergence score on the validation set (second next cell).\n",
    "\n",
    "The correlation is very clear in the first case, and is still quite strong in the second case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyPlot.plot(R.rank_val_acc, R.test_acc, \".\", color=\"black\")\n",
    "PyPlot.xlabel(\"Rank (vadidation set accuracy)\", fontsize=14)\n",
    "PyPlot.ylabel(\"Test set accuracy\", fontsize=14);\n",
    "println(\"correlation:\", cor(R.rank_val_acc, R.test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyPlot.plot(R.rank_div, R.test_acc, \".\", color=\"black\")\n",
    "PyPlot.xlabel(\"Rank (divergence score)\", fontsize=14)\n",
    "PyPlot.ylabel(\"Test set accuracy\", fontsize=14);\n",
    "println(\"correlation:\", cor(R.rank_div, R.test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compare with accuracy obtained with a random classifier, averaging over several runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## random classification\n",
    "Random.seed!(123)\n",
    "ctr = countmap(y_trainval)\n",
    "x = [ctr[i] for i in 1:12]\n",
    "s = sum(x)\n",
    "p = [i / s for i in x]\n",
    "acc = []\n",
    "for rep in 1:30\n",
    "    y_pred = [x + 1 for x in StatsBase.sample(1:12, Weights(p), length(y_test), replace=true)]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    push!(acc, sum(diag(cm)) / sum(cm))\n",
    "end\n",
    "println(\"Random classifier average accuracy on test set:\", mean(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set accuracy vs both divergence scores\n",
    "\n",
    "Recall that we took the average rank of the global and local and divergence scores to obtain the (unsupervised) ranking of the embeddings. \n",
    "\n",
    "Below, we plot the test set accuracy vs both divergence scores.\n",
    "As we already saw with the correlation valuers, the global score is a better predictor here, but the local score is still correlated as expected, with a few points having high local divergence, low global divergence and high accuracy (so using only the local score would ranked those as bad).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_balls = nrow(R)\n",
    "x = R.div_glb ./ minimum(R.div_glb)\n",
    "y = R.div_loc ./ minimum(R.div_loc)\n",
    "acc = R.test_acc\n",
    "areas = [(10 * x)^2 for x in acc]\n",
    "\n",
    "PyPlot.figure()\n",
    "PyPlot.scatter(x, y, s=areas, alpha=0.85, color=\"dimgrey\")\n",
    "#plt.axis([0.0, 1.0, 0.0, 1.0])\n",
    "PyPlot.xlabel(\"Global divergence score (normalized)\", fontsize=13)\n",
    "PyPlot.ylabel(\"Local divergence score (normalized)\", fontsize=13)\n",
    "p1 = PyPlot.plot([], [], color=\"white\", marker=\"o\", markersize=5.5, markerfacecolor=\"dimgrey\")\n",
    "p2 = PyPlot.plot([], [], color=\"white\", marker=\"o\", markersize=8.5, markerfacecolor=\"dimgrey\")\n",
    "p3 = PyPlot.plot([], [], color=\"white\", marker=\"o\", markersize=11.5, markerfacecolor=\"dimgrey\")\n",
    "PyPlot.legend((p1[1], p2[1], p3[1]), (\"35%\", \"65%\", \"95%\",), numpoints=1, loc=4, title=\"test set accuracy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN structural embedding of Zachary graph\n",
    "\n",
    "In the cells below, we embed the nodes from the Zachary graph using a simple GCN model (graph convolution net) with one hidden layer and 3-dimensional output. \n",
    "\n",
    "We use the implementation from the ```sknetwork``` package. \n",
    "\n",
    "For **structural** node features, we use each node\"s degree and number of edges in its egonet. We cluster the resulting embedding with k-means setting k=3. \n",
    "\n",
    "We plot the embedding (after dimension reduction via UMAP) with colors representing the k-means clusters.\n",
    "We see good separation between the 3 clusters.\n",
    "\n",
    "In the next cell we plot the graph this time using the ... layout we saw before.\n",
    "We see that this embedding finds the central/intermediate/peripheral nodes as its clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GCN embedding of karate graph + kmeans with 3 communities\n",
    "ig_zac = ig.Graph.Famous(\"Zachary\")\n",
    "zac_A = ig_zac.get_adjacency_sparse()\n",
    "\n",
    "## GCN\n",
    "hidden_dim = 5\n",
    "n_labels = 3\n",
    "gnn = skn.gnn.GNNClassifier(dims=[hidden_dim, n_labels],\n",
    "    layer_types=\"Conv\",\n",
    "    activations=\"ReLu\",\n",
    "    verbose=false)\n",
    "\n",
    "## for structural features, use degree and number of edges in egonet\n",
    "features = hcat(\n",
    "    ig_zac.degree(),\n",
    "    [ig_zac.subgraph(V).ecount() for V in ig_zac.neighborhood()]\n",
    ")\n",
    "labels = zeros(nv(zac)) ## embedding, no need for node labels\n",
    "\n",
    "## compute the embedding\n",
    "zac_emb = gnn.fit_transform(zac_A, features, labels=labels, n_epochs=25, random_state=42)\n",
    "\n",
    "## apply k-means to this embedding and color the nodes\n",
    "cl = ScikitLearn.fit!(KMeans(n_clusters=3, random_state=123, n_init=\"auto\"), zac_emb).labels_\n",
    "\n",
    "# ## map the structural embedding to 2-d via UMAP for visualization\n",
    "Random.seed!(4)\n",
    "Y = umap(zac_emb')\n",
    "clean_graphplot(zac,\n",
    "    layout=Tuple.(eachrow(Y')),\n",
    "    ilabels=1:nv(zac),\n",
    "    node_color=[:white, :lightgray, :gray][cl.+1],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(400, 400),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now with Spring layout\n",
    "clean_graphplot(zac,\n",
    "    ilabels=1:nv(zac),\n",
    "    node_color=[:white, :lightgray, :gray][cl.+1],\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(400, 400),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we train another GCN, but with 1-dimension output layer (using same node features), so we get a 1dimensional embedding that we can use to order the nodes, which we show in the second cell below (where the node labels are replaced by their respective ranks in the ordering). \n",
    "\n",
    "We see a clear ranking from the most central nodes to the peripherial nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1-d embedding allows for node ordering\n",
    "n_labels = 1\n",
    "gnn = skn.gnn.GNNClassifier(dims=[hidden_dim, n_labels],\n",
    "    layer_types=\"Conv\",\n",
    "    activations=\"ReLu\",\n",
    "    verbose=false)\n",
    "emb_1 = gnn.fit_transform(zac_A, features, labels=labels, n_epochs=20, random_state=42)\n",
    "roles = sortperm(vec(emb_1))\n",
    "plot_labels = zeros(Int, nv(zac))\n",
    "i = 1\n",
    "for pos in roles\n",
    "    plot_labels[pos] = i\n",
    "    i += 1\n",
    "end\n",
    "clean_graphplot(zac,\n",
    "    ilabels=plot_labels,\n",
    "    edge_color=:lightgray,\n",
    "    figure=(size=(400, 400),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## semi-supervised learning with GCN\n",
    "\n",
    "Below we consider the ground-truth labels in the Zachary graphs; recall that there are two communities. \n",
    "\n",
    "We mask 1/3 of the labels and train a GCN model using the other 2/3, given the ground-truth labels for those. \n",
    "\n",
    "We then use the trained model to predict the labels for the masked 1/3 of the nodes (a.k.a. the test set).\n",
    "\n",
    "We see that we get a good accuracy, around 90%, on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## classification - karate graph\n",
    "labels = deepcopy(c) .- 1\n",
    "\n",
    "Random.seed!(123)\n",
    "train_mask = rand(length(labels)) .< 0.33 ## mask 1/3 of the nodes for training\n",
    "labels[train_mask] .= -1 ## the negative labels are ignored in the training\n",
    "\n",
    "# GNN classifier with a single hidden layer\n",
    "hidden_dim = 5\n",
    "n_labels = 2 ## 2 ground-truth communities\n",
    "gnn = skn.gnn.GNNClassifier(dims=[hidden_dim, n_labels],\n",
    "    layer_types=\"Conv\",\n",
    "    activations=\"ReLu\",\n",
    "    verbose=false)\n",
    "\n",
    "## for features, we simply use the adjacency matrix\n",
    "## fit the GCN\n",
    "Pred = gnn.fit_predict(zac_A, zac_A, labels=labels, n_epochs=50, random_state=42)\n",
    "\n",
    "## apply to test set and compute accuracy\n",
    "acc = accuracy_score((c.-1)[train_mask], Pred[train_mask])\n",
    "print(\"accuracy on the test set:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding the Twitch dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running node2vec and UMAP/t-SNE\n",
    "\n",
    "Here are the steps to follow to re-create the experiment below:\n",
    "* get the dataset from https://snap.stanford.edu/data/twitch_gamers.html (168,114 nodes, 6,797,557 edges)\n",
    "* build a dataframe with all node features\n",
    "* build the graph from the edge list and run node2vec on the graph\n",
    "* run UMAP and t-SNE to get 2-dim mappings for visualization, \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get the node features\n",
    "twitch = CSV.read(\"/Users/lukasz/Desktop/twitch_gamers/large_twitch_features.csv\", DataFrame)\n",
    "\n",
    "# get the edgelist\n",
    "df = CSV.read(\"/Users/lukasz/Desktop/twitch_gamers/large_twitch_edges.csv\", DataFrame)\n",
    "\n",
    "## build the graph and compute node2vec embedding\n",
    "twitch_edgelist = \"/Users/lukasz/Desktop/twitch_gamers/large_twitch_edges.csv\"\n",
    "cmd = `$(PyCall.python) ./n2v_to_file.py $(twitch_edgelist) 128 1.0 1.0 123 twitch`\n",
    "run(pipeline(cmd,stderr=Pipe()))\n",
    "Embedding = readEmbedding(\"_embed\")\n",
    "println(size(Embedding))\n",
    "\n",
    "# compute UMAP projection in 2-dim for visualization\n",
    "Embedding_umap = umap(Embedding')\n",
    "Embedding_umap = Matrix(Embedding_umap')\n",
    "# add 2-dim node coordinates to the node features dataframe\n",
    "twitch.X = Embedding_umap[:,1]\n",
    "twitch.Y = Embedding_umap[:,2]\n",
    "\n",
    "# same with t-SNE\n",
    "Embedding_tsne = ScikitLearn.fit!(TSNE(n_components=2, learning_rate=\"auto\", init=\"random\", perplexity=3, n_jobs=32), Embedding).embedding_\n",
    "twitch.X_tsne = Embedding_tsne.embedding_[:,1]\n",
    "twitch.Y_tsne = Embedding_tsne.embedding_[:,2]\n",
    "\n",
    "# save the dataframe and the node2vec embedding\n",
    "serialize(datadir*\"Twitch/twitch_jl.ser\",twitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the data obtained from the above experiment\n",
    "twitch = deserialize(datadir * \"Twitch/twitch_jl.ser\")\n",
    "first(twitch, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### greyscale plot - highlight a few languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a greyscale palette without the extremes\n",
    "colors = pyimport(\"matplotlib.colors\")\n",
    "function truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100)\n",
    "    new_colors = cmap.(range(minval, stop=maxval, length=n))\n",
    "    return colors.LinearSegmentedColormap.from_list(\n",
    "        \"trunc($(cmap.name), $(round(minval, digits=2)), $(round(maxval, digits=2)))\",\n",
    "        new_colors, N=n\n",
    "    )\n",
    "end\n",
    "cmap = get_cmap(\"binary\")\n",
    "greyscale = truncate_colormap(cmap, 0.1, 1.0)\n",
    "\n",
    "## select a few languages to highlight\n",
    "languages = [\"French\", \"Spanish\", \"German\"]\n",
    "language_codes = [\"FR\", \"ES\", \"DE\"]\n",
    "twitch.color = zeros(Int, nrow(twitch))\n",
    "\n",
    "twitch.color[twitch.language.==language_codes[1]] .= 1\n",
    "twitch.color[twitch.language.==language_codes[2]] .= 2\n",
    "twitch.color[twitch.language.==language_codes[3]] .= 3\n",
    "\n",
    "## plot - change ticklabels as required\n",
    "figure(figsize=(12, 8))\n",
    "PyPlot.scatter(twitch.X, twitch.Y, c=twitch.color, cmap=greyscale, s=5)\n",
    "gca().set_aspect(\"equal\", \"datalim\")\n",
    "cb = colorbar(boundaries=0:5 .- 0.5, shrink=0.7)\n",
    "cb.set_ticks(0:3)\n",
    "cb.set_ticklabels([\"Other\"; languages])\n",
    "PyPlot.xticks([])\n",
    "PyPlot.yticks([])\n",
    "PyPlot.title(\"Twitch dataset embedding\", fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute the average position for every language in mapped 2-dim space\n",
    "L = combine(groupby(twitch, :language), [:X, :Y] .=> mean)\n",
    "X = collect(L.X_mean)\n",
    "Y = collect(L.Y_mean)\n",
    "Z = collect(L.language)\n",
    "fig, ax = subplots(figsize=(9, 9))\n",
    "ax.scatter(X, Y, s=0)\n",
    "PyPlot.xticks([])\n",
    "PyPlot.yticks([])\n",
    "PyPlot.xlim(minimum(X) - 2, maximum(X) + 2)\n",
    "PyPlot.ylim(minimum(Y) - 2, maximum(Y) + 2)\n",
    "for (i, txt) in enumerate(Z)\n",
    "    if txt != \"OTHER\"\n",
    "        ax.annotate(string(txt), (X[i], Y[i]), color=\"black\", size=14)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## colorplot - all languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sort(collect(Set(twitch.language)))\n",
    "x = filter(!=(\"OTHER\"), x)\n",
    "lang_list = vcat(\"OTHER\", reverse(x))\n",
    "num_lang = length(lang_list)\n",
    "lang_dict = Dict(lang => i-1 for (i, lang) in enumerate(lang_list))\n",
    "\n",
    "cvals = [lang_dict[i] for i in twitch.language]\n",
    "\n",
    "## plot - change ticklabels as required\n",
    "figure(figsize=(12, 8))\n",
    "PyPlot.scatter(twitch.X, twitch.Y, c=cvals, cmap=\"Spectral\", s=5)\n",
    "gca().set_aspect(\"equal\", \"datalim\")\n",
    "\n",
    "ax = colorbar(boundaries=0:num_lang .- 0.5, shrink=0.9)\n",
    "ax.set_ticks(0:num_lang - 1 .+ 0.2)\n",
    "ax.set_ticklabels(lang_list, fontsize=12)\n",
    "\n",
    "PyPlot.xticks([])\n",
    "PyPlot.yticks([])\n",
    "PyPlot.title(\"Twitch dataset embedding\", fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtering - users with high number of view only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitch.log_num_views = round.(Int, log10.(twitch.views .+ 1))\n",
    "\n",
    "subset = filter(row -> row.log_num_views > 5, twitch)\n",
    "cvals = [lang_dict[i] for i in subset.language]\n",
    "\n",
    "figure(figsize=(12, 8))\n",
    "PyPlot.scatter(subset.X, subset.Y, c=cvals, cmap=\"Spectral\", s=5)\n",
    "gca().set_aspect(\"equal\", \"datalim\")\n",
    "\n",
    "ax = colorbar(boundaries=0:num_lang .- 0.5, shrink=0.9)\n",
    "ax.set_ticks(0:num_lang - 1 .+ 0.2)\n",
    "ax.set_ticklabels(lang_list, fontsize=12)\n",
    "\n",
    "PyPlot.xticks([])\n",
    "PyPlot.yticks([])\n",
    "PyPlot.title(\"Twitch dataset embedding - subset\", fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE views of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot - change ticklabels as required\n",
    "figure(figsize=(12, 8))\n",
    "PyPlot.scatter(twitch.X_tsne, twitch.Y_tsne, c=twitch.color, cmap=greyscale, s=5)\n",
    "gca().set_aspect(\"equal\", \"datalim\")\n",
    "\n",
    "ax = colorbar(boundaries=0:5 .- 0.5, shrink=0.7)\n",
    "ax.set_ticks(0:3 .+ 0.2)\n",
    "ax.set_ticklabels([\"Other\"; languages], fontsize=12)\n",
    "\n",
    "PyPlot.xticks([])\n",
    "PyPlot.yticks([])\n",
    "PyPlot.title(\"Twitch dataset embedding\", fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot - change ticklabels as required\n",
    "cvals = [lang_dict[i] for i in twitch.language]\n",
    "\n",
    "figure(figsize=(12, 8))\n",
    "PyPlot.scatter(twitch.X_tsne, twitch.Y_tsne, c=cvals, cmap=\"Spectral\", s=5)\n",
    "gca().set_aspect(\"equal\", \"datalim\")\n",
    "\n",
    "ax = colorbar(boundaries=0:num_lang .- 0.5, shrink=0.9)\n",
    "ax.set_ticks(0:num_lang - 1 .+ 0.2)\n",
    "ax.set_ticklabels(lang_list, fontsize=12)\n",
    "\n",
    "PyPlot.xticks([])\n",
    "PyPlot.yticks([])\n",
    "PyPlot.title(\"Twitch dataset embedding\", fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot\n",
    "subset = filter(row -> row.log_num_views > 5, twitch)\n",
    "cvals = [lang_dict[i] for i in subset.language]\n",
    "\n",
    "figure(figsize=(12, 8))\n",
    "PyPlot.scatter(subset.X_tsne, subset.Y_tsne, c=cvals, cmap=\"Spectral\", s=5)\n",
    "gca().set_aspect(\"equal\", \"datalim\")\n",
    "\n",
    "ax = colorbar(boundaries=0:num_lang .- 0.5, shrink=0.9)\n",
    "ax.set_ticks(0:num_lang - 1 .+ 0.2)\n",
    "ax.set_ticklabels(lang_list, fontsize=12)\n",
    "\n",
    "PyPlot.xticks([])\n",
    "PyPlot.yticks([])\n",
    "PyPlot.title(\"Twitch dataset embedding - subset\", fontsize=20);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
