{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 - Random Graph Models\n",
    "\n",
    "In the first part of this notebook, we provide the code required to generate the Figures in Chapter 2 of the textbook.\n",
    "\n",
    "In the second part, we consider the GitHub machine learning (ml) developers graph that we introduced in Chapter 1, and compare various statistics for this graph with the values we get for the random graphs models introduced in Chapter 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "Add `powerlaw` package using the following commands in a Julia session (you can also copy-paste it to a Jupyter Notebook cell and run it):\n",
    "```\n",
    "using PyCall\n",
    "run(`$(PyCall.python) -m pip install --upgrade cython`)\n",
    "run(`$(PyCall.python) -m pip install powerlaw`)\n",
    "```\n",
    "These commands need to be run only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Graphs\n",
    "using GraphPlot\n",
    "using PyCall\n",
    "using PyPlot\n",
    "using Statistics\n",
    "using Optim\n",
    "using Distributions\n",
    "using FreqTables\n",
    "using StatsBase\n",
    "using Random\n",
    "using CSV\n",
    "using DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the previous notebook, make sure to set the data directory properly in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"../Datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Generating figures from the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2.1: size of the giant component\n",
    "\n",
    "We generate several binomial random graphs with $n$ nodes, where we vary the average node degree (thus, the number of edges). We consider $n=100$ below, and you can try for different $n$. Un-comment the second line to run with $n=10,000$ nodes as in the second plot in the book (this will be much slower).\n",
    "\n",
    "We plot the theoretical giant component size (black line) and the 90% confidence interval from the empirical data in grey, both as a function of the average degree; we see good agreement and we observe the various phases as described in the book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# n=10000\n",
    "gc_avg = Float64[]\n",
    "gc_std = Float64[]\n",
    "REP = 1000 ## repeats\n",
    "ad = 0.1:0.1:10.0\n",
    "for d in ad\n",
    "    x = Int[]\n",
    "    for rep in 1:REP\n",
    "        p = d / (n - 1)\n",
    "        g = erdos_renyi(n, p)\n",
    "        push!(x, maximum(length, connected_components(g)))\n",
    "    end\n",
    "    push!(gc_avg, mean(x))\n",
    "    push!(gc_std, std(x))\n",
    "end\n",
    "\n",
    "## theoretical\n",
    "th = fill(log(n), 10)\n",
    "\n",
    "fn(x, d) = x + exp(-x * d) - 1\n",
    "\n",
    "for i in 1.1:0.1:10.0\n",
    "    push!(th, n * optimize(x -> fn(x, i)^2, 0, 1).minimizer[1])\n",
    "end\n",
    "\n",
    "fill_between(ad, [a - 1.654 * s for (a, s) in zip(gc_avg, gc_std)],\n",
    "    [a + 1.645 * s for (a, s) in zip(gc_avg, gc_std)], color=\"lightgray\")\n",
    "plot(ad, th, color=\"black\")\n",
    "suptitle(\"Random graph with \" * string(n) * \" nodes\", fontsize=14)\n",
    "title(\"Theoretical predictions (black) vs empirical results (grey)\", fontsize=12)\n",
    "xlabel(\"average degree\", fontsize=14)\n",
    "ylabel(\"giant component size\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2.2: probability that the graph is connected\n",
    "\n",
    "This is a similar experiment as above, but this time we look at the probability that the random graph is connected.\n",
    "We vary some constant $c$ introduced in the book such that the edge probability for the binomial graphs is given by $(\\log(n)+c)/n$. Once again we compare theory (black line) and experimental results (in grey) with $n=100$ nodes. Un-comment the second line to run with $n=10,000$ nodes as in the second plot in the book (this will be much slower).\n",
    "\n",
    "In the cell below, the grey area corresponds to a 90% confidence interval for proportions; for empirical proportion $x$ obtained from sample of size $n$, the formula is given by $x \\pm 1.645 \\sqrt{x(1-x)/n}$.\n",
    "\n",
    "Here also we see good agreement between theory and experimental results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# n = 10000\n",
    "REP = 1000 ## repeats\n",
    "lo = max(-floor(log(n) * 10) / 10, -10)\n",
    "C = lo:0.1:10.0\n",
    "ic_avg = Float64[]\n",
    "for c in C\n",
    "    x = Bool[]\n",
    "    for rep in 1:REP\n",
    "        p = (c + log(n)) / n\n",
    "        g = erdos_renyi(n, p)\n",
    "        push!(x, is_connected(g))\n",
    "    end\n",
    "    push!(ic_avg, mean(x))\n",
    "end\n",
    "\n",
    "## theoretical\n",
    "th = [exp(-exp(-c)) for c in C]\n",
    "\n",
    "## plot\n",
    "fill_between(C, [x - 1.654 * sqrt(x * (1 - x) / n) for x in ic_avg],\n",
    "    [x + 1.645 * sqrt(x * (1 - x) / n) for x in ic_avg], color=\"lightgray\")\n",
    "plot(C, th, color=\"black\")\n",
    "suptitle(\"Random graph with \" * string(n) * \" nodes\", fontsize=14)\n",
    "title(\"Theoretical predictions (black) vs empirical results (grey)\", fontsize=12)\n",
    "xlabel(\"constant c\", fontsize=14)\n",
    "ylabel(\"P(graph is connected)\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2.4: Distribution of shortest path lengths\n",
    "\n",
    "We consider a series of binomial random graphs with expected average degree 5, where we vary the number of nodes from $n=64$ to $n=2,048$.\n",
    "\n",
    "We see that as we double the number of nodes, the average shortest path lengths (in the giant component) increases slowly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = Vector{Int}[]\n",
    "N = [64, 128, 256, 512, 1024, 2048]\n",
    "Random.seed!(123)\n",
    "for n in N\n",
    "    p = 5 / (n - 1)\n",
    "    g = erdos_renyi(n, p)\n",
    "    z = Int[]\n",
    "    for i in 1:n\n",
    "        d = [e for e in gdistances(g, i) if e > 0]\n",
    "        z = [z; d]\n",
    "    end\n",
    "    push!(sp, z)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show as histograms (boxplots in the first edition)\n",
    "bins = 0.5:1:8.5\n",
    "fig, axs = subplots(2, 3)\n",
    "suptitle(\"Shortest path length distribution\")\n",
    "for i in 1:2\n",
    "    for j in 1:3\n",
    "        axs[i, j].hist(\n",
    "            sp[3*(i-1)+j], bins=bins, width=0.9, density=true, color=\"darkgrey\"\n",
    "        )\n",
    "        axs[i, j].set_ylim(0, 0.48)\n",
    "        axs[i, j].set_xticks([1, 3, 5, 7])\n",
    "        axs[i, j].set_title(string(N[3*(i-1)+j]) * \" nodes\", fontsize=10)\n",
    "        axs[i, j].set_xlabel(\"path length\")\n",
    "        axs[i, j].set_ylabel(\"proportion\")\n",
    "    end\n",
    "end\n",
    "for ax in fig.get_axes()\n",
    "    ax.label_outer()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2.5 Poisson vs degree distributions\n",
    "\n",
    "We plot the degree distribution for binomial random graphs with expected average degree 10, and $n=100$ nodes (the black dots), and we compare with the corresponding Poisson distribution (dashed line).\n",
    "\n",
    "Try increasing $n$; the dots should get closer to the Poisson distribution.\n",
    "\n",
    "We used $n=10,000$ for the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 100\n",
    "n = 10000\n",
    "p = 10 / (n - 1)\n",
    "g = erdos_renyi(n, p)\n",
    "z = proptable(degree(g))\n",
    "x = names(z)[1]\n",
    "pmf = pdf(Poisson(10), x)\n",
    "plot(x, z, \"o\", color=\"black\")\n",
    "plot(x, pmf, \":\", color=\"black\")\n",
    "title(\"Empirical degree distribution vs Poisson distribution\")\n",
    "xlabel(\"degree\", fontsize=14)\n",
    "ylabel(\"frequency/pmf\", fontsize=14);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(countmap(degree(g)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2.6 -  Power law graphs\n",
    "\n",
    "We generate a random graph with $n=10,000$ nodes following power law degree distribution with exponent $\\gamma=2.5$.\n",
    "We do so using the Chung-Lu models described in section 2.5 of the book; we generate simple graphs (no loops or multiedges) and discard 0-degree nodes.\n",
    "\n",
    "We then fit and plot the degree distribution of the obtained graph using the ```powerlaw``` package, see: https://arxiv.org/pdf/1305.0215.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fast Chung-Lu: generate m edges w.r.t. distribution d\n",
    "function fastCL(d, m)\n",
    "    p = Weights(d)\n",
    "    n = length(d)\n",
    "    target = m\n",
    "    g = SimpleGraph(n)\n",
    "    while ne(g) < target\n",
    "        a, b = sample(1:n, p), sample(1:n, p)\n",
    "        a != b && add_edge!(g, a, b)\n",
    "    end\n",
    "    return g\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## power law graph\n",
    "gamma = 2.5\n",
    "n = 10000\n",
    "delta = 1\n",
    "Delta = sqrt(n)\n",
    "W = Float64[]\n",
    "for i in 1:n\n",
    "    push!(W, delta * (n / (i - 1 + n / (Delta / delta)^(gamma - 1)))^(1 / (gamma - 1)))\n",
    "end\n",
    "\n",
    "deg = round.(Int, W)\n",
    "m = trunc(Int, mean(deg) * n / 2)\n",
    "g = fastCL(deg, m)\n",
    "\n",
    "## number of isolated nodes\n",
    "print(\"isolates: \", count(==(0), degree(g)))\n",
    "\n",
    "g1 = induced_subgraph(g, findall(>(0), degree(g)))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KS statistic\n",
    "d = degree(g1)\n",
    "powerlaw = pyimport(\"powerlaw\");\n",
    "X = powerlaw.Fit(d)\n",
    "println(\"Range of degrees in graph: $(minimum(d)) , $(maximum(deg))\")\n",
    "println(\"Value of l':\", X.power_law.xmin)\n",
    "println(\"Corresponding value of gamma:\", X.power_law.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divergence vs $\\ell$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot divergence vs 'l'\n",
    "x = X.xmins\n",
    "y = X.Ds\n",
    "plot(x, y, \".\")\n",
    "\n",
    "## Plot min value with larger dot\n",
    "x = Int(X.power_law.xmin)\n",
    "y = X.Ds[x-1]\n",
    "plot([x], [y], \"p\")\n",
    "xlabel(L\"$\\ell$\", fontsize=14)\n",
    "ylabel(\"Divergence\", fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot divergence vs. exponent (alphas here, gamma' in the book)\n",
    "plot(X.alphas[begin:50], X.Ds[begin:50], \".\")\n",
    "\n",
    "## Plot min value with larger dot\n",
    "i = Int(X.power_law.xmin)\n",
    "x = X.alphas[i-1]\n",
    "y = X.Ds[i-1]\n",
    "plot([x], [y], \"o\")\n",
    "xlabel(raw\"$\\gamma$\", fontsize=14)\n",
    "ylabel(\"Divergence\", fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2.6 - inverse (cumulative) cdf vs degree and fitted power law\n",
    "\n",
    "In the first plot, we look at degrees starting from $\\ell'$.\n",
    "\n",
    "In the second plot, we look at the whole range of degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Figure 2.6 - starting from l'\n",
    "fig1 = X.power_law.plot_ccdf(color=\"black\", linestyle=\"-\");\n",
    "fig1 = X.plot_ccdf(ax=fig1, linewidth=2, color=\"gray\", original_data=false, linestyle=\":\")\n",
    "xlabel(\"degree\", fontsize=13)\n",
    "ylabel(\"inverse cdf\", fontsize=13);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now starting from 1 - need to translate power law line manually\n",
    "fig = X.plot_ccdf(linewidth=2, color=\"dimgray\", original_data=true, linestyle=\"--\")\n",
    "xlabel(\"degree\", fontsize=13)\n",
    "ylabel(\"inverse cdf\", fontsize=13)\n",
    "\n",
    "## get end points for power law fitted line\n",
    "x = [Int(X.power_law.xmin), Int(X.data[end])]     ## x-axis: from l' to max value in data\n",
    "delta_y = X.ccdf(original_data=true)[2][x[1]-1]   ## translation for first point\n",
    "y = [delta_y, X.power_law.ccdf()[end] * delta_y] ## y-axis values\n",
    "plt.plot(x, y, \"-\", linewidth=2, color=\"black\")\n",
    "print(\"power law slope:\", (log10(y[2]) - log10(y[1])) / (log10(x[2]) - log10(x[1])));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.7: simple $d$-regular graphs\n",
    "\n",
    "We generate several $d$-regular graphs and count how many are simple graphs.\n",
    "We consider $d=2$ to $d=10$, with $n=100$ nodes. \n",
    "We used $n=10,000$ nodes in the book.\n",
    "\n",
    "We plot the empirical proportion of simple graphs below (black dots), and we compare with the theoretical values (dashed line). We see good agreement even for small value $n=100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function check_random_regular_simple(n, k)\n",
    "    stubs = reduce(vcat, [fill(i, k) for i in 1:n])\n",
    "    shuffle!(stubs)\n",
    "    existing = Set{Tuple{Int,Int}}()\n",
    "    for i in 1:2:length(stubs)\n",
    "        a, b = minmax(stubs[i], stubs[i+1])\n",
    "        (a == b || (a, b) in existing) && return false\n",
    "        push!(existing, (a, b))\n",
    "    end\n",
    "    return true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# n = 10000\n",
    "REP = 100\n",
    "D = 2:10\n",
    "simple = [mean(check_random_regular_simple(n, d) for _ in 1:REP) for d in D]\n",
    "th = [exp(-(d * d - 1) / 4) for d in D]\n",
    "\n",
    "plot(D, simple, \"o\", color=\"black\")\n",
    "plot(D, th, \":\", color=\"black\")\n",
    "xlabel(\"degree\", fontsize=14)\n",
    "ylabel(\"P(graph is simple)\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.8 - Random geometric graphs (RGG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model, $n$ nodes are dropped randomly on the d-dimensional space $[0,1]^d$.\n",
    "Two nodes are connected by an edge if their distance is less than some **radius** parameter $r$.\n",
    "We consider the **unit square**, so we fix $d=2$ in our examples.\n",
    "\n",
    "For RGG on the unit square, the (expected) average degree of a node in a graph with $n$ nodes is $\\pi r^2 (n-1)$ where $r$ is the radius parameter, unless the node is near the square boundary. Near the boundary, this approximation is actually slightly larger than the true expected average degree due to boundary effects (nodes close to the boundary of the square will have a smaller number of connections).\n",
    "\n",
    "We can slightly modify this model by considering a unit **torus**. This will eliminate boundary effects so all nodes have (expected) average degree $\\pi r^2 (n-1).$\n",
    "\n",
    "In all experiments below, you can use either the unit square by setting ```boundary=:periodic```, or the torus model by setting ```boundary=:open```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at some RGGs\n",
    "\n",
    "We plot some geometric random graphs with $n=100$ nodes and varying radius threshold $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting a few random geometric graphs with 100 nodes and varying radius threshold\n",
    "n = 100\n",
    "boundary = :periodic ## Set to :open to see a torus-based RGG, else we use the constrained unit square\n",
    "\n",
    "## select a value for the radius:\n",
    "# radius = 0.1\n",
    "radius = 0.15\n",
    "# radius = 0.2\n",
    "\n",
    "g, _, pos = euclidean_graph(n, 2, seed=1234, cutoff=radius, bc=boundary)\n",
    "print(\"Geometric random graph with radius=\", radius)\n",
    "gplot(g, pos[1, :], pos[2, :], nodefillc=\"gray\", nodestrokelw=1, nodestrokec=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RGG - size of the giant component**\n",
    "\n",
    "Next we look at the size of the giant component for geometric random graphs on the unit square as we vary the radius parameter.\n",
    "\n",
    "For RGG on the unit square, the (expected) average degree of a node in a graph with $n$ nodes is $\\pi r^2 (n-1)$ where $r$ is the radius parameter, unless the node is near the square boundary. Near the boundary, this approximation is actually slightly larger than the true expected average degree due to boundary effects (nodes close to the boundary of the square will have a smaller number of connections).\n",
    "\n",
    "In the experiment below, we fix some degree range and compute the corresponding radius parameters $r$.\n",
    "For each value $r$, we generate 1,000 GRGs and compute the mean and standard deviation for the size of the \n",
    "giant component.\n",
    "\n",
    "We see a similar shape as with binomial (Erdos-Renyi) random graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = :open ## Set to :open to see a torus-based RGG, else we use the constrained unit square\n",
    "\n",
    "## number of nodes:\n",
    "n = 100\n",
    "#n = 10000\n",
    "\n",
    "repeats = 1000\n",
    "average_degree = 0.5:0.5:15\n",
    "radii = sqrt.(average_degree / (pi * (n - 1)))\n",
    "\n",
    "df = DataFrame([\"gc_avg\", \"gc_std\", \"deg_avg\"] .=> Ref(Float64[]))\n",
    "## generate random graphs and gather the sizes of the giant component\n",
    "for radius in radii\n",
    "    x = Int[]\n",
    "    y = Float64[]\n",
    "    for rep in 1:repeats\n",
    "        g, _ = euclidean_graph(n, 2, seed=rep, cutoff=radius, bc=boundary)\n",
    "        push!(x, maximum(length.(connected_components(g))))\n",
    "        push!(y, mean(degree(g)))\n",
    "    end\n",
    "    push!(df, [mean(x), std(x), mean(y)])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the above empirical results (confidence intervals and mean values)\n",
    "fill_between(average_degree, df.gc_avg - 1.654 * df.gc_std,\n",
    "    min.(n, df.gc_avg + 1.654 * df.gc_std), color=\"lightgray\")\n",
    "plot(average_degree, df.gc_avg, color=\"black\", linestyle=\":\")\n",
    "xlabel(\"Average degree (approximate)\", fontsize=14)\n",
    "ylabel(\"giant component size\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Degree formula vs empirical results**\n",
    "\n",
    "If the experiment was conducted on the unit square (with `boundary = :periodic` ), then the empirical degrees are slightly smaller than the ones computes with the formula -- this is clearly seen by comparing with a unit slope line. However if the experiment was conducted on torus (with `boundary = :open`), then the values are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(average_degree, df.deg_avg, color=\"black\")\n",
    "plot(df.deg_avg, df.deg_avg, \":\", color=\"dimgray\")\n",
    "ylabel(\"empirical average degree\", fontsize=14)\n",
    "xlabel(\"average degree formula\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connectivity of RGGs**\n",
    "\n",
    "This time we look at the probability that the random graph is connected.\n",
    "We vary some constant $c$ introduced in the book such that the radius $r$ for the RGGs is given by $n\\pi r^2 = \\ln n + c$. We compare theory (black line) and experimental results (in grey) with $n=100$ nodes. \n",
    "We used $n=10,000$ nodes in the book (this will be much slower).\n",
    "\n",
    "In the cell below, the grey area corresponds to a 90% confidence interval for proportions; for empirical proportion $x$ obtained from sample of size $n$, the formula is given by $x \\pm 1.645 \\sqrt{x(1-x)/n}$.\n",
    "\n",
    "In this case, if we generate RGGs on a square, boundary nodes will have a higher chance of being isolated, so the convergence to the theoretical result with respect to $n$ is slow, as we observe in the results below.\n",
    "Working on a torus, we see faster convergence, but even with $n = 10,000$, there are still some small differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary = :open\n",
    "n = 100\n",
    "# n = 10000\n",
    "\n",
    "repeats = 1000\n",
    "\n",
    "## set lower bound for the range of values for 'c'\n",
    "lo = max(-5, -Int(floor(log(n) * 10)) / 10)\n",
    "c_range = lo:0.1:10\n",
    "ic_avg = Float64[]\n",
    "\n",
    "for c in c_range\n",
    "    x = Int64[]\n",
    "    r = sqrt((c + log(n)) / (pi * (n)))\n",
    "    for rep in 1:repeats\n",
    "        g, _ = euclidean_graph(n, 2, seed=rep, cutoff=r, bc=boundary)\n",
    "        push!(x, Int(is_connected(g)))\n",
    "    end\n",
    "    push!(ic_avg, mean(x))\n",
    "end\n",
    "## theoretical values\n",
    "th = exp.(-exp.(-c_range));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(c_range, ic_avg - 1.654 * sqrt.(ic_avg .* (1 .- ic_avg) / n),\n",
    "    ic_avg + 1.645 * sqrt.(ic_avg .* (1 .- ic_avg) / n), color=\"lightgrey\")\n",
    "plot(c_range, th, \"-\", color=\"black\")\n",
    "xlabel(L\"constant $c$\", fontsize=14)\n",
    "ylabel(\"P(graph is connected)\", fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Experiments section\n",
    "\n",
    "We use the giant component of the **GitHub machine learning (ml) developers** subgraph that we introduced in Chapter 1. Recall this graph has 7,083 nodes and 19,491 edges. \n",
    "\n",
    "We compute several graphs statistics for this \"base graph\", as reported in the first column of **Table 2.8** from the book.\n",
    "\n",
    "We then generate **random** graphs with the same number of nodes and edges using 4 different models:\n",
    "* binomial or Erdos-Renyi: only average degree is used\n",
    "* Chung-Lu: expected degree distribution\n",
    "* Configuration: exact degree distribution\n",
    "* Configuration with Viger method: connected, simple graph is obtained\n",
    "\n",
    "See **section 2.8** of the book for a more complete discussion of the results, but as a general observation, more complex models (such as the configuration model with Viger method) tend to preserve more characteristics of the reference graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the GitHub edge list into a graph\n",
    "D = CSV.read(datadir * \"GitHubDevelopers/musae_git_edges.csv\", DataFrame) .+ 1\n",
    "max_node_id = max(maximum(D.id_1), maximum(D.id_2))\n",
    "gh = SimpleGraph(max_node_id)\n",
    "foreach(row -> add_edge!(gh, row...), eachrow(D))\n",
    "\n",
    "## add some node features, here there are\n",
    "## 2 class of nodes, 0: web developer (red), 1: ml developer (blue)\n",
    "X = CSV.read(datadir * \"GitHubDevelopers/musae_git_target.csv\", DataFrame)\n",
    "X.id .+= 1\n",
    "@assert extrema(diff(X.id)) == (1, 1) && extrema(X.id) == (1, length(vertices(gh)))\n",
    "gh_lbl = ifelse.(X.ml_target .== 0, \"web\", \"ml\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_ml = induced_subgraph(gh, findall(==(\"ml\"), gh_lbl))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = connected_components(gh_ml)\n",
    "sg = induced_subgraph(gh_ml, cc[argmax(length.(cc))])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function baseStats(G)\n",
    "    deg = degree(G)\n",
    "    cc = connected_components(G)\n",
    "    return Any[nv(G), ne(G),\n",
    "        minimum(deg), mean(deg), median(deg), quantile(deg, 0.99), maximum(deg),\n",
    "        igraph_diameter(G),\n",
    "        length(cc), maximum(length, cc), count(==(0), deg),\n",
    "        global_clustering_coefficient(G),\n",
    "        mean(local_clustering_coefficient(G)[degree(G).>1])]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function igraph_diameter(G)\n",
    "    ccs = connected_components(G)\n",
    "    ccg = [induced_subgraph(G, cc)[1] for cc in ccs]\n",
    "    maximum(maximum(maximum(gdistances(g, i)) for i in vertices(g)) for g in ccg)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function cm_simple(ds)\n",
    "    @assert iseven(sum(ds))\n",
    "    stubs = reduce(vcat, fill(i, ds[i]) for i in 1:length(ds))\n",
    "    shuffle!(stubs)\n",
    "    local_edges = Set{Tuple{Int,Int}}()\n",
    "    recycle = Tuple{Int,Int}[]\n",
    "    for i in 1:2:length(stubs)\n",
    "        e = minmax(stubs[i], stubs[i+1])\n",
    "        if (e[1] == e[2]) || (e in local_edges)\n",
    "            push!(recycle, e)\n",
    "        else\n",
    "            push!(local_edges, e)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # resolve self-loops and duplicates\n",
    "    last_recycle = length(recycle)\n",
    "    recycle_counter = last_recycle\n",
    "    while !isempty(recycle)\n",
    "        recycle_counter -= 1\n",
    "        if recycle_counter < 0\n",
    "            if length(recycle) < last_recycle\n",
    "                last_recycle = length(recycle)\n",
    "                recycle_counter = last_recycle\n",
    "            else\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        p1 = popfirst!(recycle)\n",
    "        from_recycle = 2 * length(recycle) / length(stubs)\n",
    "        success = false\n",
    "        for _ in 1:2:length(stubs)\n",
    "            p2 = if rand() < from_recycle\n",
    "                used_recycle = true\n",
    "                recycle_idx = rand(axes(recycle, 1))\n",
    "                recycle[recycle_idx]\n",
    "            else\n",
    "                used_recycle = false\n",
    "                rand(local_edges)\n",
    "            end\n",
    "            if rand() < 0.5\n",
    "                newp1 = minmax(p1[1], p2[1])\n",
    "                newp2 = minmax(p1[2], p2[2])\n",
    "            else\n",
    "                newp1 = minmax(p1[1], p2[2])\n",
    "                newp2 = minmax(p1[2], p2[1])\n",
    "            end\n",
    "            if newp1 == newp2\n",
    "                good_choice = false\n",
    "            elseif (newp1[1] == newp1[2]) || (newp1 in local_edges)\n",
    "                good_choice = false\n",
    "            elseif (newp2[1] == newp2[2]) || (newp2 in local_edges)\n",
    "                good_choice = false\n",
    "            else\n",
    "                good_choice = true\n",
    "            end\n",
    "            if good_choice\n",
    "                if used_recycle\n",
    "                    recycle[recycle_idx], recycle[end] = recycle[end], recycle[recycle_idx]\n",
    "                    pop!(recycle)\n",
    "                else\n",
    "                    pop!(local_edges, p2)\n",
    "                end\n",
    "                success = true\n",
    "                push!(local_edges, newp1)\n",
    "                push!(local_edges, newp2)\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        success || push!(recycle, p1)\n",
    "    end\n",
    "    g = SimpleGraph(length(ds))\n",
    "    for e in local_edges\n",
    "        add_edge!(g, e...)\n",
    "    end\n",
    "    return g\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = erdos_renyi(nv(sg), ne(sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = expected_degree_graph(degree(sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl2 = fastCL(degree(sg), ne(sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = cm_simple(degree(sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(\"statistic\" => [\"nodes\", \"edges\", \"d_min\", \"d_mean\", \"d_median\", \"d_quant_99\", \"d_max\",\n",
    "        \"diameter\", \"components\", \"largest\", \"isolates\", \"C_glob\", \"C_loc\"],\n",
    "    \"Base Graph\" => baseStats(sg),\n",
    "    \"Erdos-Renyi\" => baseStats(er),\n",
    "    \"Chung-Lu original\" => baseStats(cl),\n",
    "    \"Chung-Lu fixed\" => baseStats(cl2),\n",
    "    \"Configuration simple\" => baseStats(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortest path length distribution\n",
    "\n",
    "We compute and compare the shortest path length distribution for several node pairs and for the 5 graphs we have (GitHub ml reference graph, and 4 random graphs). Sampling is used to speed-up the process.\n",
    "\n",
    "We consider the giant component for disconnected graphs.\n",
    "\n",
    "We see a reasonably high similarity for all graphs, with the binomial random graph having slightly longer path lengths due to the absence of high degree (hub) nodes in that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute min path length distribution for several node pairs for the 5 graphs (real and 4 random ones)\n",
    "cc_er = connected_components(er)\n",
    "er_g = induced_subgraph(er, cc_er[argmax(length.(cc_er))])[1]\n",
    "cc_cl = connected_components(cl)\n",
    "cl_g = induced_subgraph(cl, cc_cl[argmax(length.(cc_cl))])[1]\n",
    "cc_cl2 = connected_components(cl2)\n",
    "cl2_g = induced_subgraph(cl2, cc_cl2[argmax(length.(cc_cl2))])[1]\n",
    "cc_cm = connected_components(cm)\n",
    "cm_g = induced_subgraph(cm, cc_cm[argmax(length.(cc_cm))])[1]\n",
    "\n",
    "SAMPLE_SIZE = 200\n",
    "\n",
    "graphs = [sg, er_g, cl_g, cl2_g, cm_g]\n",
    "Vs = [sample(1:nv(g), SAMPLE_SIZE, replace=false) for g in graphs]\n",
    "\n",
    "sps = [Int[] for _ in eachindex(graphs)]\n",
    "for i in 1:SAMPLE_SIZE\n",
    "    for j in 1:length(sps)\n",
    "        d = [e for e in gdistances(graphs[j], Vs[j][i]) if e > 0]\n",
    "        sps[j] = [sps[j]; d]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare shortest path length distributions\n",
    "bins = 0.5:1:11.5\n",
    "fig, axs = plt.subplots(2, 3)\n",
    "\n",
    "## plot the 5 histograms\n",
    "axs[1, 1].hist(sps[1], bins=bins, width=0.9, density=true, color=\"darkgrey\")\n",
    "axs[1, 1].set_title(\"Base (GitHub ml)\", fontsize=10)\n",
    "axs[1, 2].hist(sps[2], bins=bins, width=0.9, density=true, color=\"darkgrey\")\n",
    "axs[1, 2].set_title(\"Binomial\", fontsize=10)\n",
    "axs[1, 3].hist(sps[3], bins=bins, width=0.9, density=true, color=\"darkgrey\")\n",
    "axs[1, 3].set_title(\"Chung-Lu\", fontsize=10)\n",
    "axs[2, 1].hist(sps[4], bins=bins, width=0.9, density=true, color=\"darkgrey\")\n",
    "axs[2, 1].set_title(\"Config.\", fontsize=10)\n",
    "axs[2, 2].hist(sps[5], bins=bins, width=0.9, density=true, color=\"darkgrey\")\n",
    "axs[2, 2].set_title(\"Config.(V)\", fontsize=10)\n",
    "\n",
    "## set uniform y-range and ticks\n",
    "for i in 1:2\n",
    "    for j in 1:3\n",
    "        axs[i, j].set_ylim(0, 0.5)\n",
    "        axs[i, j].set_xticks([2, 4, 6, 8, 10])\n",
    "    end\n",
    "end\n",
    "\n",
    "## adjust 3-2 format\n",
    "axs[2, 3].set_visible(false)\n",
    "axs[2, 1].set_position([0.24, 0.08, 0.228, 0.343])\n",
    "axs[2, 2].set_position([0.55, 0.08, 0.228, 0.343])\n",
    "\n",
    "## labels only on the outer axis\n",
    "axs[1, 1].set_ylabel(\"proportion\")\n",
    "axs[2, 1].set_ylabel(\"proportion\")\n",
    "axs[2, 1].set_xlabel(\"path length\")\n",
    "axs[2, 2].set_xlabel(\"path length\")\n",
    "axs[1, 2].get_yaxis().set_ticklabels([])\n",
    "axs[1, 3].get_yaxis().set_ticklabels([])\n",
    "\n",
    "## add mean values\n",
    "axs[1, 1].text(6, 0.42, \"mean: \" * string(round(mean(sps[1]), digits=2)), fontsize=8)\n",
    "axs[1, 2].text(6, 0.42, \"mean: \" * string(round(mean(sps[2]), digits=2)), fontsize=8)\n",
    "axs[1, 3].text(6, 0.42, \"mean: \" * string(round(mean(sps[3]), digits=2)), fontsize=8)\n",
    "axs[2, 1].text(6, 0.42, \"mean: \" * string(round(mean(sps[4]), digits=2)), fontsize=8)\n",
    "axs[2, 2].text(6, 0.42, \"mean: \" * string(round(mean(sps[5]), digits=2)), fontsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extras\n",
    "### More power law tests - Grid and GitHub graphs\n",
    "\n",
    "We try to fit power law for the degree distributions as we did before, this time for 3 real graphs:\n",
    "* GitHub ml developers (giant component)\n",
    "* GitHub web developers (giant component)\n",
    "* Grid (Europe power grid graph, giant component)\n",
    "\n",
    "While the first two exhibit power law degree distribution, this is not the case for the Grid graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GitHub ml subgraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## estimates for xmin and gamma\n",
    "d = degree(sg)\n",
    "X = powerlaw.Fit(d)\n",
    "println(\"gamma:\", X.power_law.alpha)\n",
    "println(\"l':\", X.power_law.xmin)\n",
    "println(\"KS statistic:\", X.power_law.D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = X.power_law.plot_ccdf(color=\"black\", linestyle=\"-\");\n",
    "fig1 = X.plot_ccdf(ax=fig1, linewidth=2, color=\"gray\", original_data=false, linestyle=\":\")\n",
    "fig1.set_xlabel(\"degree\", fontsize=13)\n",
    "fig1.set_ylabel(\"inverse cdf\", fontsize=13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GitHub web subgraph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## github web developers subgraph\n",
    "gh_web = induced_subgraph(gh, findall(!=(\"ml\"), gh_lbl))[1]\n",
    "cc = connected_components(gh_web)\n",
    "sg = induced_subgraph(gh_web, cc[argmax(length.(cc))])[1]\n",
    "## estimates for xmin and gamma\n",
    "d = degree(sg)\n",
    "X = powerlaw.Fit(d)\n",
    "println(\"gamma:\", X.power_law.alpha)\n",
    "println(\"l':\", X.power_law.xmin)\n",
    "println(\"KS statistic:\", X.power_law.D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = X.power_law.plot_ccdf(color=\"black\", linestyle=\"-\");\n",
    "fig1 = X.plot_ccdf(ax=fig1, linewidth=2, color=\"gray\", original_data=false, linestyle=\":\")\n",
    "fig1.set_xlabel(\"degree\", fontsize=13)\n",
    "fig1.set_ylabel(\"inverse cdf\", fontsize=13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = split.(readlines(datadir * \"GridEurope/gridkit_europe-highvoltage.edges\"))\n",
    "vertex_ids = unique(reduce(vcat, edge_list))\n",
    "vertex_map = Dict(vertex_ids .=> 1:length(vertex_ids))\n",
    "gr = SimpleGraph(length(vertex_ids))\n",
    "foreach(((from, to),) -> add_edge!(gr, vertex_map[from], vertex_map[to]), edge_list)\n",
    "\n",
    "cc = connected_components(gr)\n",
    "sg = induced_subgraph(gr, cc[argmax(length.(cc))])[1]\n",
    "## estimates for xmin and gamma\n",
    "d = degree(sg)\n",
    "X = powerlaw.Fit(d)\n",
    "println(\"gamma:\", X.power_law.alpha)\n",
    "println(\"l':\", X.power_law.xmin)\n",
    "println(\"KS statistic:\", X.power_law.D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = X.power_law.plot_ccdf(color=\"black\", linestyle=\"-\");\n",
    "fig1 = X.plot_ccdf(ax=fig1, linewidth=2, color=\"gray\", original_data=false, linestyle=\":\")\n",
    "fig1.set_xlabel(\"degree\", fontsize=13)\n",
    "fig1.set_ylabel(\"inverse cdf\", fontsize=13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Independent sets**\n",
    "\n",
    "Illustrating a few functions to find independent sets (a set of vertices no two of which are adjacent).\n",
    "The concept was defined in Chapter 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate random graph with (at least one) independent set\n",
    "## n: nodes, s: independent set size, d: avg degree\n",
    "function indepSet(n, s, d)\n",
    "    N = n - s\n",
    "    di = (n * d รท 2) - s * d\n",
    "    ## random graph with N nodes\n",
    "    g = erdos_renyi(N, di)\n",
    "    ## extra nodes\n",
    "    add_vertices!(g, s)\n",
    "    ## assign remaining degree to extra nodes\n",
    "    z = rand(N+1:n, s * d)\n",
    "    cm = countmap(z)\n",
    "    deg = [cm[i] for i in N+1:n]\n",
    "    for i in 1:length(deg)\n",
    "        e = sample(1:N, deg[i], replace=false)\n",
    "        for j in e\n",
    "            add_edge!(g, j, i + N)\n",
    "        end\n",
    "    end\n",
    "    return induced_subgraph(g, randperm(nv(g)))[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function random_indset(g, maxiter)\n",
    "    best = Int[]\n",
    "    for _ in 1:maxiter\n",
    "        this = independent_set(g, MaximalIndependentSet())\n",
    "        length(this) > length(best) && (best = this)\n",
    "    end\n",
    "    return best\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = indepSet(50, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm based on vertex degree\n",
    "independent_set(g, DegreeIndependentSet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ris = random_indset(g, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_colors = fill(\"gray\", nv(g))\n",
    "for n in ris\n",
    "    g_colors[n] = \"red\"\n",
    "end\n",
    "gplot(g, nodefillc=g_colors, nodestrokec=\"black\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
