{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04d76892-12bc-4ed6-9708-ac73d20fb2b6",
   "metadata": {},
   "source": [
    "# New requirement - (update when new version is ready)\n",
    "\n",
    "Install the NEExT package and dependencies as follows:\n",
    "\n",
    "```\n",
    "pip install pydantic==2.11.7\n",
    "pip install imbalanced_learn==0.13.0\n",
    "pip install --no-deps neext==0.2.9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import umap\n",
    "from NEExT import NEExT\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc \n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "from collections import Counter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ded3885",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Set the directory below as required.\n",
    "\n",
    "In the next cell, we load one of the datasets ```nci1``` or ```nci109```.\n",
    "\n",
    "There are 4 csv files:\n",
    "* edges: the edgelist for every graph\n",
    "* graph_indicator: maps each node to its graph\n",
    "* graph_labels: binary labels (0/1)\n",
    "* node_labels: numerical label for each node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46dca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../Datasets/NCI/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c95d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nci1 or nci109\n",
    "dataset = 'nci1'\n",
    "\n",
    "## csv data files\n",
    "edges = datapath+dataset+'_edges.csv'\n",
    "node_graph_mapping = datapath+dataset+'_graph_indicator.csv'\n",
    "graph_labels = datapath+dataset+'_graph_labels.csv'\n",
    "node_labels = datapath+dataset+'_node_labels.csv'\n",
    "\n",
    "# Initialize NEExT and set logging level\n",
    "nxt = NEExT(log_level=\"ERROR\")\n",
    "\n",
    "# Load data with node reindexing and largest component filtering\n",
    "# Load as networkx for now\n",
    "print(\"\\nLoading data...\")\n",
    "graph_collection = nxt.read_from_csv(\n",
    "    edges_path=edges,\n",
    "    node_graph_mapping_path=node_graph_mapping,\n",
    "    graph_label_path=graph_labels,\n",
    "    node_features_path=node_labels,\n",
    "    reindex_nodes=True,\n",
    "    filter_largest_component=False,\n",
    "    graph_type=\"networkx\",\n",
    "    node_sample_rate=1.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0350a",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "We explore some simple descriptive statistics: number of graphs, number of nodes and edges, etc.\n",
    "\n",
    "We see that graphs with label = 1 have slightly more nodes and edges on average; we will come back to this when we explore supervised learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1ec45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of graphs\n",
    "n_graphs = graph_collection.describe()['num_graphs']\n",
    "print('number of graphs:', n_graphs)\n",
    "\n",
    "## store graph labels for supervised learning \n",
    "g_labels = graph_collection.get_labels()['label']\n",
    "print('graphs with label = 1:',np.sum(g_labels))\n",
    "\n",
    "## map to igraph objects and count the number of vertices and edges\n",
    "g = ig.Graph()\n",
    "M = 0\n",
    "for i in range(n_graphs):\n",
    "    g[i] = ig.Graph.from_networkx(graph_collection.graphs[i].G, vertex_attr_hashable='name').simplify()\n",
    "    g[i].vs['node_label'] = [int(l) for l in g[i].vs['node_label']] ## map node labels to integers\n",
    "    M = max(M, np.max(g[i].vs['node_label']))\n",
    "vc = [g[i].vcount() for i in range(n_graphs)]\n",
    "ec = [g[i].ecount() for i in range(n_graphs)]\n",
    "print('mean number of nodes:', np.mean(vc))\n",
    "print('mean number of edges:', np.mean(ec))\n",
    "print('max node label (min=0):',M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot number of nodes/edges for graphs with label 0 and 1 resp.\n",
    "\n",
    "a = [vc[i] for i in range(len(vc)) if g_labels[i]==0]\n",
    "b = [vc[i] for i in range(len(vc)) if g_labels[i]==1]\n",
    "c = [ec[i] for i in range(len(ec)) if g_labels[i]==0]\n",
    "d = [ec[i] for i in range(len(ec)) if g_labels[i]==1]\n",
    "\n",
    "plt.subplots(1,2,figsize=(9,4))\n",
    "plt.subplot(121)\n",
    "plt.boxplot([a,b],labels=['0','1'],widths=.6, \n",
    "            flierprops = dict(marker='.', markerfacecolor='black', markersize=3,linestyle='none'),\n",
    "            medianprops = dict(linestyle='-', linewidth=1.5, color='black'))\n",
    "plt.ylabel('Count per graph',fontsize=14);\n",
    "plt.xlabel('Label',fontsize=14)\n",
    "plt.grid()\n",
    "plt.title('Number of nodes',fontsize=14);\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.boxplot([c,d],labels=['0','1'],widths=.6, \n",
    "            flierprops = dict(marker='.', markerfacecolor='black', markersize=3,linestyle='none'),\n",
    "            medianprops = dict(linestyle='-', linewidth=1.5, color='black'))\n",
    "#plt.ylabel('Count per graph',fontsize=11)\n",
    "plt.xlabel('Label',fontsize=14);\n",
    "plt.grid()\n",
    "plt.title('Number of edges',fontsize=14)\n",
    "#plt.savefig(dataset+'_counts.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09fe6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example of a graph with label 0\n",
    "id = 799\n",
    "print('graph label:',g_labels[id])\n",
    "ig.plot(g[id], bbox=(0,0,300,300), vertex_size=10, vertex_color='grey', \n",
    "        #target=dataset+'_0.eps',\n",
    "        vertex_label=g[id].vs['node_label'], vertex_label_size=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1bcfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example of a graph with label 1 \n",
    "id = 2299\n",
    "print('label:',g_labels[id])\n",
    "ig.plot(g[id], bbox=(0,0,300,300), vertex_size=10, vertex_color='grey', \n",
    "        #target=dataset+'_1.eps',\n",
    "        vertex_label=g[id].vs['node_label'], vertex_label_size=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b457830",
   "metadata": {},
   "source": [
    "# Supervised learning\n",
    "\n",
    "We build supervised learning (classification) models to predict the graph labels. \n",
    "\n",
    "In what follows, we use **random forest** classifiers, train each model on 80% of the graph, and apply it to the other 20%. We use accuracy as well as area under ROC curves (aoc) as measures of performance.\n",
    "\n",
    "We will explore three ways to obtain features (vector representations) for each graph:\n",
    "* overall **graph features**, such as degree and coreness distribution, number of nodes and edges, etc.\n",
    "* **graph2vec** embedding, a neural method that takes advantage of the node labels, and\n",
    "* **NEExT**, a tool to build graph embeddings based on vectors of node features for each graph.\n",
    "\n",
    "We look at each set of features separately, and also using all features at once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e04237",
   "metadata": {},
   "outputs": [],
   "source": [
    "## results in book obtained on a MacOS 14.6.1 with M1 chip.\n",
    "## seeding for reproducibility\n",
    "## some results may still vary slightly on different architectures\n",
    "\n",
    "RS = 321\n",
    "np.random.seed(RS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f7769-a919-4bac-8d60-37a0cf0db2c0",
   "metadata": {},
   "source": [
    "## (1) Overall graph features\n",
    "\n",
    "* number of nodes and edges, and the graph density\n",
    "* degree distribution\n",
    "* coreness distribution\n",
    "* graph assortativity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597aec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build graph-based features for each compound (graph)\n",
    "L = []\n",
    "\n",
    "for i in range(n_graphs):\n",
    "    sg = g[i]\n",
    "    \n",
    "    ## node and edge counts, density\n",
    "    vc = sg.vcount()\n",
    "    ec = sg.ecount()\n",
    "    x = [vc,ec,vc/ec]\n",
    "    \n",
    "    ## assortativity\n",
    "    a = sg.assortativity_degree()\n",
    "    if np.isnan(a):\n",
    "        a=0\n",
    "    x.extend([a])\n",
    "    \n",
    "    ## degree distribution (1, 2 and >=3)\n",
    "    c = Counter(sg.degree())\n",
    "    x.extend([c[1]/vc,c[2]/vc,(vc-c[1]-c[2])/vc])\n",
    "    \n",
    "    ## coreness distribution\n",
    "    c = Counter(sg.coreness())\n",
    "    x.extend([c[1]/vc,c[2]/vc,(vc-c[1]-c[2])/vc])\n",
    "    \n",
    "    L.append(x)\n",
    "\n",
    "## store all features in a dataframe\n",
    "col = ['nodes','edges','density','assort','deg1','deg2','deg3+','core1','core2','core3+']\n",
    "OGF = pd.DataFrame(L,columns=col)\n",
    "OGF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ff722-804b-4592-b5aa-c853dfbf85c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## accuracy, ROC curve and auc\n",
    "## overall graph features only\n",
    "\n",
    "## train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(OGF, g_labels, test_size=0.2, random_state=RS)\n",
    "\n",
    "## random forest classifier -- accuracy\n",
    "rfc_mdl = rfc(n_estimators=100, criterion='entropy', random_state=RS)\n",
    "rfc_mdl.fit(X_train,y_train)\n",
    "y_pred = rfc_mdl.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "## ROC curve\n",
    "y_probs = rfc_mdl.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_probs)\n",
    "auc = metrics.roc_auc_score(y_test, y_probs)\n",
    "plt.plot(fpr,tpr,label=\"ROC, auc=\"+str('%.3f' % auc),color='black')\n",
    "plt.plot([0,1],[0,1],'--',label='Random',color='black')\n",
    "plt.legend(loc=4,fontsize=14)\n",
    "plt.title('Graph features', fontsize=16)\n",
    "plt.xlabel('False Positive Rate',fontsize=14)\n",
    "plt.ylabel('True Positive Rate',fontsize=14)\n",
    "#plt.savefig('nci_64d_roc.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600b130-4e2a-457d-a663-a4212c16f81b",
   "metadata": {},
   "source": [
    "## (2) graph2vec features\n",
    "\n",
    "Pre-computed graph embeddings using graph2vec. We tested three versions:\n",
    "* 1024-dimensioanl embeddings\n",
    "* 64-dimensional embeddings\n",
    "* 1024-dimensional embedding followed by reduction to 64 dimensions (using UMAP)\n",
    "\n",
    "The last method gave the best results and is the one we use below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977a0d60-4e1a-46b2-8065-b0def94a153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the embedings from csv file\n",
    "g2v = datapath+dataset+'_g2v.csv'\n",
    "G2VF = pd.read_csv(g2v, header=None)\n",
    "G2VF = np.array(G2VF.drop(columns=[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf264c-68ca-4e84-a0d7-c065f42be3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## accuracy, ROC curve and auc\n",
    "## graph2vec features only\n",
    "\n",
    "## train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(G2VF, g_labels, test_size=0.2, random_state=RS)\n",
    "\n",
    "## random forest classifier -- accuracy\n",
    "rfc_mdl = rfc(n_estimators=100, criterion='entropy', random_state=RS)\n",
    "rfc_mdl.fit(X_train,y_train)\n",
    "y_pred = rfc_mdl.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "## ROC curve\n",
    "y_probs = rfc_mdl.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_probs)\n",
    "auc = metrics.roc_auc_score(y_test, y_probs)\n",
    "plt.plot(fpr,tpr,label=\"ROC, AUC=\"+str('%.3f' % auc),color='black')\n",
    "plt.plot([0,1],[0,1],'--',label='Random',color='black')\n",
    "plt.legend(loc=4,fontsize=14)\n",
    "plt.xlabel('False Positive Rate',fontsize=14)\n",
    "plt.ylabel('True Positive Rate',fontsize=14)\n",
    "#plt.savefig('nci_64d_roc.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e64dd15",
   "metadata": {},
   "source": [
    "## (3) NEExT: embedding using node-level features\n",
    "\n",
    "This is a 2-step process; we use the functions provided by the NEExT package.\n",
    "\n",
    "* first, we compute several node features for each graph and normalize; those are the \"bag of vectors\" that represent each graph;\n",
    "* then, we embed the graphs via the earth mover (Wasserstein or similar) distance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce78465",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nxt.set_log_level(\"ERROR\") ## minimize log output\n",
    "\n",
    "# Compute node features\n",
    "features = nxt.compute_node_features(\n",
    "    graph_collection=graph_collection,\n",
    "    feature_list=[\"page_rank\",\"degree_centrality\",\"closeness_centrality\",\"betweenness_centrality\",\"eigenvector_centrality\",\n",
    "                  \"clustering_coefficient\",\"local_efficiency\",\"lsme\",\"load_centrality\",\"basic_expansion\"],\n",
    "    feature_vector_length=5,\n",
    "    show_progress=False\n",
    ")\n",
    "\n",
    "# normalize\n",
    "features.normalize()\n",
    "features.features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510fb090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute graph embeddings\n",
    "embeddings = nxt.compute_graph_embeddings(\n",
    "    graph_collection=graph_collection,\n",
    "    features=features,\n",
    "    embedding_algorithm=\"approx_wasserstein\",\n",
    "    embedding_dimension=len(features.feature_columns),\n",
    "    random_state=RS\n",
    ")\n",
    "\n",
    "## node feature based embeddings\n",
    "NEF = embeddings.embeddings_df\n",
    "NEF = np.array(NEF.drop(columns=['graph_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## accuracy, ROC curve and auc\n",
    "## NEExT's node-based feature embeddings only\n",
    "\n",
    "## train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(NEF, g_labels, test_size=0.2, random_state=RS)\n",
    "\n",
    "\n",
    "## random forest classifier -- accuracy\n",
    "rfc_mdl = rfc(n_estimators=100, criterion='entropy', random_state=RS)\n",
    "rfc_mdl.fit(X_train,y_train)\n",
    "y_pred = rfc_mdl.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "## ROC curve\n",
    "y_probs = rfc_mdl.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_probs)\n",
    "auc = metrics.roc_auc_score(y_test, y_probs)\n",
    "plt.plot(fpr,tpr,label=\"ROC, AUC=\"+str('%.3f' % auc),color='black')\n",
    "plt.plot([0,1],[0,1],'--',label='Random',color='black')\n",
    "plt.legend(loc=4,fontsize=14)\n",
    "plt.xlabel('False Positive Rate',fontsize=14)\n",
    "plt.ylabel('True Positive Rate',fontsize=14)\n",
    "#plt.savefig('nci_64d_roc.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5870617b-739f-4254-8c5f-688351341854",
   "metadata": {},
   "source": [
    "## (4) Using all features\n",
    "\n",
    "We merge all the features we computed above.\n",
    "\n",
    "A 2-dim projection show some small clusters with (mostly) graphs with the same label, but for most graphs, there is no clear separation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748379a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge features\n",
    "AF = np.concatenate((OGF, G2VF, NEF), axis=1)\n",
    "AF.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c79d4b-cafd-49e0-8c45-b5736e4bec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation -  reduce the embeddings to 2D \n",
    "umap_model = umap.UMAP(n_neighbors=15, \n",
    "                      min_dist=0.1, \n",
    "                      n_components=2, \n",
    "                      random_state=RS,\n",
    "                      n_jobs=1)\n",
    "embedding_2d = umap_model.fit_transform(AF)\n",
    "\n",
    "# Create a DataFrame with the 2D embeddings and labels\n",
    "viz_df = pd.DataFrame({\n",
    "    'UMAP1': embedding_2d[:, 0],\n",
    "    'UMAP2': embedding_2d[:, 1],\n",
    "    #'graph_id': embeddings.embeddings_df['graph_id']\n",
    "})\n",
    "\n",
    "# Add class labels from graph collection\n",
    "viz_df['label'] = g_labels\n",
    "\n",
    "## plot\n",
    "plt.scatter(viz_df.UMAP1, viz_df.UMAP2, c=viz_df.label, s=5, cmap='Set1')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b2c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## accuracy, ROC curve and auc\n",
    "## using all features\n",
    "\n",
    "## train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(AF, g_labels, test_size=0.2, random_state=RS)\n",
    "\n",
    "## random forest classifier -- accuracy\n",
    "rfc_mdl = rfc(n_estimators=100, criterion='entropy', random_state=RS)\n",
    "rfc_mdl.fit(X_train,y_train)\n",
    "y_pred = rfc_mdl.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "## ROC curve\n",
    "y_probs = rfc_mdl.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_probs)\n",
    "auc = metrics.roc_auc_score(y_test, y_probs)\n",
    "plt.plot(fpr,tpr,label=\"ROC, auc=\"+str('%.3f' % auc),color='black')\n",
    "plt.plot([0,1],[0,1],'--',label='Random',color='black')\n",
    "plt.legend(loc=4,fontsize=14)\n",
    "plt.grid(color='lightgrey')\n",
    "plt.xlabel('False Positive Rate',fontsize=14)\n",
    "plt.ylabel('True Positive Rate',fontsize=14)\n",
    "#plt.savefig(dataset+'_roc.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b9cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bootstrap confidence interval for the AUC above\n",
    "def bootstrap(y_test,y_probs,n_boot=1000):\n",
    "    y_pred = np.array(y_probs)\n",
    "    y_true = np.array(y_test)\n",
    "    scores = []\n",
    "    rng = np.random.RandomState(RS)\n",
    "    for i in range(n_boot):\n",
    "        indices = rng.randint(0, len(y_pred), len(y_pred))\n",
    "        sc = metrics.roc_auc_score(y_true[indices], y_pred[indices])\n",
    "        scores.append(sc)\n",
    "    sorted_scores = np.array(scores)\n",
    "    sorted_scores.sort()\n",
    "    conf_lo = sorted_scores[int(0.025 * len(sorted_scores))]\n",
    "    conf_up = sorted_scores[int(0.975 * len(sorted_scores))]\n",
    "    return (conf_lo, conf_up)\n",
    "bootstrap(y_test,y_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722b79e-4ded-4b30-8f8b-8af55bfa6e01",
   "metadata": {},
   "source": [
    "## Top features\n",
    "\n",
    "From the previous experiment using all features, we look at the top ones in terms of importance.\n",
    "\n",
    "With random forest classifiers, we already have such feature importance measures available.\n",
    "\n",
    "The NEExT package also provided methods for feature importance which can be used in unsupervised context.\n",
    "\n",
    "Recall that we have:\n",
    "\n",
    "* 10 overall graph features,\n",
    "* 64 features from the graph2vec embeddings, and\n",
    "* 50 features from the NEExT feature-based embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c6adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = np.argsort(rfc_mdl.feature_importances_)[::-1]\n",
    "f = list(OGF.columns) + ['g2v_'+str(i) for i in np.arange(0,64)] + ['neext_'+str(i) for i in np.arange(0,50)]\n",
    "n_top = 10\n",
    "print('top',n_top,'features:')\n",
    "print([f[i] for i in top_features[:n_top]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8588b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top = 10\n",
    "AF_norm = (AF - AF.mean(axis=0)) / (AF.std(axis=0))\n",
    "\n",
    "data = {\n",
    "    'feature' : np.concatenate([np.repeat(str(t+1),n_graphs) for t in top_features[:n_top]]),\n",
    "    'value' : np.concatenate([np.array(AF_norm[:,t]) for t in top_features[:n_top]]),\n",
    "    'label' : list(g_labels)*n_top\n",
    "}\n",
    "_df = pd.DataFrame(data)\n",
    "sns.boxplot(x='feature', y='value', data=_df, hue='label', palette='grey', showfliers=False, width=.5, gap=.1);\n",
    "plt.xlabel('top features', fontsize=14)\n",
    "plt.ylabel('normalized value', fontsize=14)\n",
    "plt.grid(axis='y')\n",
    "plt.xticks(np.arange(n_top), [f[i] for i in top_features[:n_top]], rotation=45)\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "#plt.savefig(dataset+'_features.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b181f2f",
   "metadata": {},
   "source": [
    "# Unsupervised learning\n",
    "\n",
    "We perform simple **k-means** clustering (fixing k to 10) and explore the content of the different clusters.\n",
    "\n",
    "Wityh unsupervised learning, we do not use the graph labels to identify the clusters.\n",
    "However, we use the labels a-posteriori for diagnostic.\n",
    "\n",
    "We plot the proportion of graphs with label == 1 vs the size of the cluster, and we observe several small clusters with a large proportion of graphs with label == 1.\n",
    "\n",
    "We then explore the clusters by looking at two of the top overall graph features: the number of edges, and the proportion of nodes of degree 3 or more. \n",
    "We see that a few small clusters can easily be identified only with those simple features, and those clusters are (for the most part) mainly made up of graphs with label 1.\n",
    "\n",
    "However, a large proportion of the graphs end up in two larger clusters where graphs with both label values are found in large number, and where those two overall graph features are close to the average values over all graphs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build k-means clustering \n",
    "NCL = 10 ## number of clusters\n",
    "km = KMeans(n_clusters=NCL, n_init=100, random_state=RS).fit(AF_norm).labels_\n",
    "K = pd.DataFrame(np.array([g_labels, km, np.repeat(1,len(g_labels))]).transpose(),\n",
    "                 columns=['label=1','cluster','total'])\n",
    "C = K.groupby(by='cluster').sum()\n",
    "C['ratio'] = C['label=1']/C['total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1748749",
   "metadata": {},
   "outputs": [],
   "source": [
    "OGF['cluster'] = km\n",
    "_df = OGF.groupby(by='cluster').mean()\n",
    "_df['size'] = C['total']\n",
    "_df['label=1'] = C['ratio']\n",
    "_df.sort_values(by='label=1', ascending=False)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3c9d5fb-8401-4efa-bb82-eb447b1e3187",
   "metadata": {},
   "source": [
    "## LaTeX - subset of columns\n",
    "print(_df[['size','label=1','edges','deg3+','core2']].sort_values(by='label=1', ascending=False).to_latex(index=False, float_format=lambda x: '%.3f' % x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b4f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## overall averages\n",
    "OGF.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a72a542-5524-4c74-b7ba-186af8d290b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot the clusters w.r.t. two overall graph features\n",
    "## dashed lines are the average values for those features over all graphs\n",
    "## greyscale color indicates the proportion of label 1 graphs (black = 100%)\n",
    "## sizes are proportional to the number of graphs in each cluster\n",
    "\n",
    "OGF['cluster'] = km\n",
    "_df = OGF.groupby(by='cluster').mean()\n",
    "_df['sizes'] = C['total']\n",
    "_df['ratio'] = 1-C['ratio']\n",
    "\n",
    "plt.scatter(_df.edges, _df['deg3+'], s=_df.sizes, c=_df.ratio, cmap='grey', vmin=0, vmax=1)\n",
    "plt.grid(linestyle=':')\n",
    "plt.vlines(OGF.edges.mean(), .18,.44,linestyles='--',color='grey')\n",
    "plt.hlines(OGF['deg3+'].mean(), 10, 100,linestyles='--',color='grey')\n",
    "plt.xlabel('number of edges', fontsize=14)\n",
    "plt.ylabel('proportion of degree-3+ nodes', fontsize=14)\n",
    "#plt.savefig(dataset+'_kmeans_2.eps')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9bfab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot example with large 2-core \n",
    "id = 2077\n",
    "print('cluster:',km[id])\n",
    "print('label:',g_labels[id])\n",
    "print(OGF[id:(id+1)]['core2'])\n",
    "ig.plot(g[id], bbox=(0,0,300,300), vertex_size=8, vertex_color='grey', \n",
    "        #target=dataset+'_2core_1.eps',\n",
    "        vertex_label=g[id].vs['node_label'], vertex_label_size=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## variance of the 2-core proportion\n",
    "np.var(OGF[OGF.cluster==2]['core2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11054a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot example with small 2-core \n",
    "id = 0\n",
    "print('cluster:',km[id])\n",
    "print('label:',g_labels[id])\n",
    "ig.plot(g[id], bbox=(0,0,300,300), vertex_size=8, vertex_color='grey', \n",
    "        #target=dataset+'_2core_2.eps',\n",
    "        vertex_label=g[id].vs['node_label'], vertex_label_size=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca028b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## variance of the 2-core proportion\n",
    "np.var(OGF[OGF.cluster==9]['core2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "complexnetworks",
   "language": "python",
   "name": "complexnetworks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
