{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 - Random Graph Models\n",
    "\n",
    "In the first part of this notebook, we provide the code required to generate the Figures in Chapter 2 of the textbook.\n",
    "\n",
    "In the second part, we consider the GitHub ml developers graph that we introduced in Chapter 1, and compare various statistics for this graph with the values we get for the random graphs models introduced in Chapter 2.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "We use one new package in this notebook called ```plfit``` which can be installed via ```pip install plfit```.\n",
    "In case of error when pip installing, you can copy the code from the GitHub repository: https://github.com/keflavich/plfit\n",
    "\n",
    "As with the previous notebook, make sure to set the data directory properly in the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir='../Datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "import plfit\n",
    "from scipy.stats import poisson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Generating Figures for Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.1: size of the giant component\n",
    "\n",
    "We generate several binomial random graphs with $n$ nodes, where we vary the average node degree (thus, the number of edges). We consider $n=100$ below, and you can try for different $n$. Un-comment the second line to run with $n=10000$ nodes as in the book (this will be much slower).\n",
    "\n",
    "We plot the theoretical giant component size (black line) and the 90% confidence interval from empirical data in grey, both as a function of the average degree; we see good agreement and we observe the various phases as described in the book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# n=10000\n",
    "gc_avg = []\n",
    "gc_std = []\n",
    "REP = 1000 ## repeats\n",
    "ad = np.arange(.1,10.1,.1)\n",
    "for d in ad:\n",
    "    x = []\n",
    "    p = d/(n-1)\n",
    "    for rep in range(REP):\n",
    "        g = ig.Graph.Erdos_Renyi(n=n, p=p)\n",
    "        x.append(g.clusters().giant().vcount())\n",
    "    gc_avg.append(np.mean(x))\n",
    "    gc_std.append(np.std(x))\n",
    "\n",
    "## theoretical\n",
    "th = [np.log(n) for i in np.arange(.1,1.1,.1)]\n",
    "from scipy.optimize import fsolve\n",
    "def fn(x,d):\n",
    "    return x+np.exp(-x*d)-1\n",
    "for i in np.arange(1.1,10.1,.1):\n",
    "    th.append(n*fsolve(fn,1,args=(i))[0])\n",
    "\n",
    "plt.fill_between(ad,[x[0]-1.654*x[1] for x in zip(gc_avg,gc_std)],\n",
    "                 [x[0]+1.645*x[1] for x in zip(gc_avg,gc_std)],color='lightgray')\n",
    "plt.plot(ad,th,color='black')\n",
    "plt.title('Theoretical predictions (black) vs empirical results (grey)')\n",
    "plt.xlabel('average degree',fontsize=14)\n",
    "plt.ylabel('giant component size',fontsize=14);\n",
    "\n",
    "## un-comment to save plot in a file\n",
    "#plt.savefig('giant_100.eps');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.2: probability that the graph is connected\n",
    "\n",
    "This is a similar experiment as above, but this time we look at the probability that the random graph is connected.\n",
    "We vary some constant $c$ introduced in the book such that edge probability for the binomial graphs is given by $(\\log(n)+c)/n$. Once again we compare theory (black line) and experimental results (in grey), with $n=100$ nodes and you can try for different $n$. Un-comment the second line to run with $n=10000$ nodes as in the book (this will be much slower).\n",
    "\n",
    "In the cell below, the grey area corresponds to a 90% confidence interval for proportions; for empirical proportion $x$ obtained from sample of size $n$, the formula is given by $x \\pm 1.645 \\sqrt{x(1-x)/n}$.\n",
    "\n",
    "Here also we see good agreement between theory and experimental results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "#n = 10000\n",
    "REP = 1000 ## repeats\n",
    "lo = -int(np.floor(np.log(n)*10))/10\n",
    "if lo<-10:\n",
    "    lo = -10\n",
    "C = np.arange(lo,10.1,.1)\n",
    "ic_avg=[]\n",
    "for c in C:\n",
    "    x = []\n",
    "    p = (c+np.log(n))/n\n",
    "    for rep in range(REP):        \n",
    "        g = ig.Graph.Erdos_Renyi(n=n, p=p)\n",
    "        x.append(int(g.is_connected()))\n",
    "    ic_avg.append(np.mean(x))\n",
    "\n",
    "## theoretical\n",
    "th = [np.exp(-np.exp(-c)) for c in C]\n",
    "\n",
    "## plot\n",
    "plt.fill_between(C,[x-1.654*np.sqrt(x*(1-x)/n) for x in ic_avg],\n",
    "                 [x+1.645*np.sqrt(x*(1-x)/n) for x in ic_avg],color='lightgray')\n",
    "plt.plot(C,th,color='black')\n",
    "plt.title('Theoretical predictions (black) vs empirical results (grey)')\n",
    "plt.xlabel(r'constant $c$',fontsize=14)\n",
    "plt.ylabel('P(graph is connected)',fontsize=14);\n",
    "\n",
    "## un-comment to save plot in a file\n",
    "#plt.savefig('connected_100.eps');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.4: Distribution of shortest path lengths\n",
    "\n",
    "We consider a series of binomial random graphs with expected average degree 5, where we vary the number of nodes from $n=50$ to $n=3200$.\n",
    "\n",
    "We see that as we double the number of nodes, the average shortest path lengths increases slowly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = []\n",
    "N = [50,100,200,400,800,1600,3200]\n",
    "for n in N:\n",
    "    p = 5/(n-1)\n",
    "    ## keep giant component\n",
    "    g = ig.Graph.Erdos_Renyi(n=n, p=p).clusters().giant()\n",
    "    z = g.shortest_paths()\n",
    "    sp.append([x for y in z for x in y])\n",
    "## plot    \n",
    "plt.boxplot(sp, labels=N, sym='.',whis=5)\n",
    "plt.ylabel('shortest path length')\n",
    "plt.xlabel('number of nodes');\n",
    "## un-comment to save plot in a file\n",
    "# plt.savefig('path_len.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.5 Poisson vs degree distributions\n",
    "\n",
    "We plot the degree distribution for binomial random graphs with expected average degree 10, and $n=100$ nodes (the black dots), and we compare with the corresponding Poisson distributed (dashed line).\n",
    "\n",
    "Try increasing $n$; the dots should get closer to the Poisson distribution, with more stable results if you try multiple runs.\n",
    "\n",
    "Un-comment line 2 to run with $n=10000$ as in the book.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "#n = 10000\n",
    "p = 10/(n-1)\n",
    "g = ig.Graph.Erdos_Renyi(n=n, p=p)\n",
    "x = [x[0] for x in sorted(Counter(g.degree()).items())]\n",
    "pmf = [poisson.pmf(k,10) for k in x]\n",
    "frq = [x[1]/n for x in sorted(Counter(g.degree()).items())]\n",
    "plt.plot(x,frq,'o',color='black')\n",
    "plt.plot(x,pmf,':',color='black')\n",
    "plt.xlabel('degree',fontsize=14)\n",
    "plt.ylabel('frequency/pmf',fontsize=14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.6 --  Power law graphs\n",
    "\n",
    "We generate a random graph with $n=10,000$ nodes following power law degree distribution with exponent $\\gamma=2.5$.\n",
    "We do so using the Chung-Lu models described in section 2.5 of the book, and we discard 0-degree nodes.\n",
    "\n",
    "We then fit and plot the degree distribution of the obtained graph using the ```plfit``` package https://pypi.org/project/plfit/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fast Chung-Lu: generate m edges w.r.t. distribution d\n",
    "def fastCL(d, m):\n",
    "    n = len(d)\n",
    "    s = np.sum(d)\n",
    "    p = [i/s for i in d]\n",
    "    target = m\n",
    "    tples = []\n",
    "    ## generate edges (tuples), drop collisions, until m edges are obtained.\n",
    "    while len(tples) < target:\n",
    "        s = target - len(tples)\n",
    "        e0 = np.random.choice(n, size=s, replace=True, p=p)\n",
    "        e1 = np.random.choice(n, size=s, replace=True, p=p)\n",
    "        tples.extend([(min(e0[i],e1[i]),max(e0[i],e1[i])) for i in range(len(e0)) if e0[i]!=e1[i]]) ## ignore loops\n",
    "        tples = list(set(tples)) ## drop collisions\n",
    "    return tples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## power law graph\n",
    "gamma = 2.5\n",
    "n = 10000\n",
    "\n",
    "## min and max degrees\n",
    "delta = 1\n",
    "Delta = np.sqrt(n)\n",
    "\n",
    "## generate degrees\n",
    "W = []\n",
    "for i in np.arange(1,n+1):\n",
    "    W.append(delta * (n/(i-1+n/(Delta/delta)**(gamma-1)))**(1/(gamma-1)))\n",
    "\n",
    "# deg = [int(np.round(w)) for w in W] ## to enforce integer weights, not an obligation\n",
    "deg = W\n",
    "\n",
    "## generate graph with Chung-Lu model\n",
    "m = int(np.mean(deg)*n/2)\n",
    "tpl = fastCL(deg,m)\n",
    "g1 = ig.Graph.TupleList(tpl)\n",
    "\n",
    "## number of isolated nodes (no edges)\n",
    "iso = n-g1.vcount()\n",
    "print('isolates:',iso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run plfit and compute K-S statistic (details in the book)\n",
    "d = g1.degree()\n",
    "X = plfit.plfit(d)\n",
    "\n",
    "## those are gamma' and l' minimizing divergence from the tail of the power law distribution\n",
    "print(X.plfit())\n",
    "\n",
    "## plot K-S statistics vs. cutoff value l\n",
    "ax = plt.figure(1)\n",
    "ax = X.xminvsks()\n",
    "ax.set_xlabel(r'$\\ell$',fontsize=14)\n",
    "ax.set_ylabel('Kolmogorov-Smirnov statistic',fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-S test - this can take a few minutes\n",
    "# Monte-Carlo test to determine whether distribution is consistent with a power law\n",
    "KS_tst = X.test_pl(niter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot K-S statistics vs. exponent (alpha here, gamma' in the book)\n",
    "ax = plt.figure(1)\n",
    "ax = X.alphavsks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inverse cdf along with fitted line (as with Figure 2.6 in the book)\n",
    "X.plotcdf(pointcolor='grey', pointmarker='.',zoom=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2.7: simple d-regular graphs\n",
    "\n",
    "We generate several $d$-regular graphs and count how many are simple graphs.\n",
    "We consider $d=2$ to $d=10$, with $n=100$ nodes. You can try for different $n$. Un-comment the second line to run with $n=10000$ nodes as in the book (this will be much slower).\n",
    "\n",
    "We plot the empirical proportion of simple graphs below (black dots), and we compare with the theoretical values (dashed line). We see good agreement even for small value $n=100$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "# n = 10000\n",
    "REP = 100\n",
    "D = np.arange(2,11) \n",
    "simple = []\n",
    "for d in D:\n",
    "    x = 0\n",
    "    for rep in range(REP):\n",
    "        g = ig.Graph.Degree_Sequence([d for i in range(n)])\n",
    "        x += int(g.is_simple())\n",
    "    simple.append(x/REP)\n",
    "th = [np.exp(-(d*d-1)/4) for d in D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(D,simple,'o',color='black')\n",
    "plt.plot(D,th,':',color='black')\n",
    "plt.xlabel('degree',fontsize=14)\n",
    "plt.ylabel('P(graph is simple)',fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 -- Experiments section\n",
    "\n",
    "We use the giant component of the GitHub machine learning (ml) developers subgraph that we introduced in Chapter 1. Recall this graph has 7,083 nodes and 19,491 edges. \n",
    "\n",
    "We compute several graphs statistics for this \"base graph\", as reported in the first column of Table 2.8 from the book.\n",
    "\n",
    "We then generate random graphs with the same number of nodes and edges using 4 different models:\n",
    "* binomial (only average degree)\n",
    "* Chung-Lu (expected degree distribution)\n",
    "* Configuration (exact degree distribution)\n",
    "* Configuration with Viger method (connected, simple graph is obtained)\n",
    "\n",
    "See section 2.8 of the book for a discussion of the results bit as a general observation, more complex models (such as the configuration model with Viger method) tend to preserve more characteristics of the reference graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the GitHub edge list into a graph (gh)\n",
    "D = pd.read_csv(datadir+'GitHubDevelopers/musae_git_edges.csv')\n",
    "tuples = [tuple(x) for x in D.values]\n",
    "gh = ig.Graph.TupleList(tuples, directed = False)\n",
    "\n",
    "## Add some node features;\n",
    "## There are 2 class of nodes\n",
    "## 0: web developer (red), 1: ml developer (blue)\n",
    "X = pd.read_csv(datadir+'GitHubDevelopers/musae_git_target.csv')\n",
    "idx = [int(i) for i in gh.vs['name']]\n",
    "sorterIndex = dict(zip(idx,range(len(idx))))\n",
    "X['Rank'] = X['id'].map(sorterIndex)\n",
    "X.sort_values(['Rank'], ascending=[True],inplace=True)\n",
    "X.dropna(inplace=True)\n",
    "gh.vs['target'] = list(X['ml_target'])\n",
    "cls = ['grey','black']\n",
    "gh.vs['color'] = [cls[i] for i in list(X['ml_target'])]\n",
    "gh.es['color'] = 'grey'\n",
    "\n",
    "## for github, 9739 are ml developers, build the subgraph\n",
    "gh_ml = gh.subgraph([v for v in gh.vs() if v['color']=='black'])\n",
    "\n",
    "## keep the giant component\n",
    "sg = gh_ml.clusters().giant()\n",
    "print(sg.vcount(),'nodes and',sg.ecount(),'edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## return statistics from Table 2.8 for graph G\n",
    "def baseStats(G):\n",
    "    deg = G.degree()\n",
    "    return [G.vcount(),G.ecount(),np.min(deg),np.mean(deg),np.median(deg),np.max(deg),G.diameter(),\n",
    "     np.max(G.clusters().membership)+1,G.clusters().giant().vcount(),sum([x==0 for x in G.degree()]),\n",
    "     G.transitivity_undirected(),G.transitivity_avglocal_undirected()]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## statistice for Base and random graphs\n",
    "S = []\n",
    "S.append(['Base Graph'] + baseStats(sg))\n",
    "## Random (Erdos-Renyi) graph with same number of nodes and edges\n",
    "er = ig.Graph.Erdos_Renyi(n=sg.vcount(), m=sg.ecount())\n",
    "S.append(['Erdos-Renyi'] + baseStats(er))\n",
    "## Random (Chung-Lu) graph with same degree distribution\n",
    "tpl = fastCL(sg.degree(),sg.ecount()) \n",
    "cl = ig.Graph.Erdos_Renyi(n=sg.vcount(),m=0)\n",
    "cl.add_edges(tpl)\n",
    "S.append(['Chung-Lu'] + baseStats(cl))\n",
    "## Random (configuration model) graph with same degree distribution\n",
    "cm = ig.Graph.Degree_Sequence(sg.degree(),method='simple')\n",
    "S.append(['Configuration'] + baseStats(cm))\n",
    "## Random graph with same degree distribution using the\n",
    "## configuration model with VL method, which yield a simple graph\n",
    "cmvl = ig.Graph.Degree_Sequence(sg.degree(),method='vl')\n",
    "S.append(['Configuration (VL)'] + baseStats(cmvl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store in dataframe and show results\n",
    "D = pd.DataFrame(S,columns=['graph','nodes','edges',r'$d_{min}$',r'$d_{mean}$',\n",
    "                             r'$d_{median}$',r'$d_{max}$','diameter','components','largest','isolates',\n",
    "                             r'$C_{glob}$',r'$C_{loc}$'])\n",
    "D = D.transpose()\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shortest path length distribution\n",
    "\n",
    "We compute and compare the minimum path length distribution for several node pairs and for the 5 graphs we have (reference and 4 random ones). Sampling can be used to speed-up the process.\n",
    "\n",
    "We consider the giant component for disconnected graphs.\n",
    "\n",
    "We see a reasonably high similarity for all graphs, with the binomial random graph having slightly longer path lengths due to the absence of high degree (hub) nodes in that model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sampling -- doing all vertices is slower\n",
    "size = 1000\n",
    "\n",
    "## using the giant component for disconnected graphs\n",
    "er_g = er.clusters().giant()\n",
    "cl_g = cl.clusters().giant()\n",
    "cm_g = cm.clusters().giant()\n",
    "\n",
    "## to consider all vertices, replace the code below with:\n",
    "# sp_sg = [i for v in sg.shortest_paths(source=None) for i in v]\n",
    "# sp_er = [i for v in er_g.shortest_paths(source=None) for i in v]\n",
    "# sp_cl = [i for v in cl_g.shortest_paths(source=None) for i in v]\n",
    "# sp_cm = [i for v in cm_g.shortest_paths(source=None) for i in v]\n",
    "# sp_cmvl = [i for v in cmvl.shortest_paths(source=None) for i in v]\n",
    "\n",
    "# to use sampling:\n",
    "## NB: we sample separately since we use the giant components and graphs may\n",
    "##     have a different number of nodes (except the first and last one)\n",
    "sp_sg = []\n",
    "for v in np.random.choice(sg.vcount(),size=size,replace=False):\n",
    "    sp_sg.extend(sg.shortest_paths(source=v)[0])\n",
    "sp_er = []\n",
    "for v in np.random.choice(er_g.vcount(),size=size,replace=False):\n",
    "    sp_er.extend(er_g.shortest_paths(source=v)[0])\n",
    "sp_cl = []\n",
    "for v in np.random.choice(cl_g.vcount(),size=size,replace=False):\n",
    "    sp_cl.extend(cl_g.shortest_paths(source=v)[0])\n",
    "sp_cm = []\n",
    "for v in np.random.choice(cm_g.vcount(),size=size,replace=False):\n",
    "    sp_cm.extend(cm_g.shortest_paths(source=v)[0])\n",
    "sp_cmvl = []\n",
    "for v in np.random.choice(cmvl.vcount(),size=size,replace=False):\n",
    "    sp_cmvl.extend(cmvl.shortest_paths(source=v)[0])\n",
    "\n",
    "## generate boxplots   \n",
    "plt.boxplot([sp_sg,sp_er,sp_cl,sp_cm,sp_cmvl],labels=['Base','Bin','CL','CM','CM(V)'],\n",
    "            sym='.',whis=10, medianprops = dict(linestyle='-', linewidth=2.5,color='black'))\n",
    "plt.ylabel('shortest path length',fontsize=14);\n",
    "\n",
    "## save plot to file\n",
    "#plt.savefig('pathlen_box.eps');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More power law tests - GitHub subgraphs and Grid graph\n",
    "\n",
    "We try to fit power law for degree distribution as we did before, this time for 3 real graphs:\n",
    "* GitHub ml developers (giant component)\n",
    "* GitHub web developers (giant component)\n",
    "* Grid (Europe power grid graph, giant component)\n",
    "\n",
    "While the first two exhibit power law degree distribution, this is clearly not the case for the Grid graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub ml subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for github, 9739 are ml developers, build the subgraph\n",
    "gh_ml = gh.subgraph([v for v in gh.vs() if v['color']=='black'])\n",
    "## keep the giant component\n",
    "sg = gh_ml.clusters().giant()\n",
    "\n",
    "## estimates for xmin and gamma\n",
    "d = sg.degree()\n",
    "X = plfit.plfit(d)\n",
    "print(X.plfit())\n",
    "ax = plt.figure(1)\n",
    "ax = X.xminvsks()\n",
    "ax.set_xlabel(r'$\\ell$',fontsize=14)\n",
    "ax.set_ylabel('Kolmogorov-Smirnov statistic',fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-S test -- very good fit here\n",
    "KS_tst = X.test_pl(niter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GitHub web subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## github web developers subgraph\n",
    "gh_web = gh.subgraph([v for v in gh.vs() if v['color']!='black'])\n",
    "## keep the giant component\n",
    "sg = gh_web.clusters().giant()\n",
    "\n",
    "## estimates for xmin and gamma\n",
    "d = sg.degree()\n",
    "X = plfit.plfit(d)\n",
    "print(X.plfit())\n",
    "ax = plt.figure(1)\n",
    "ax = X.xminvsks()\n",
    "ax.set_xlabel(r'$\\ell$',fontsize=14)\n",
    "ax.set_ylabel('Kolmogorov-Smirnov statistic',fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KS test -- not as good as previous graph, but still consistent with power law\n",
    "## (if p<.1, the data may be inconsistent with a powerlaw.)\n",
    "KS_tst = X.test_pl(niter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = ig.Graph.Read_Ncol(datadir+'GridEurope/gridkit_europe-highvoltage.edges', directed=False)\n",
    "gr = gr.simplify()\n",
    "## keep the giant component\n",
    "sg = gr.clusters().giant()\n",
    "\n",
    "## estimates for xmin and gamma\n",
    "d = sg.degree()\n",
    "X = plfit.plfit(d)\n",
    "print(X.plfit())\n",
    "ax = plt.figure(1)\n",
    "ax = X.xminvsks()\n",
    "ax.set_xlabel(r'$\\ell$',fontsize=14)\n",
    "ax.set_ylabel('Kolmogorov-Smirnov statistic',fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we get xmin=15 ... how many nodes does this cover? --> just a few!\n",
    "sum([x>=15 for x in sg.degree()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's fix xmin=4 to cover more nodes!\n",
    "d = sg.degree()\n",
    "X = plfit.plfit(d)\n",
    "print(X.plfit(xmin=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-S test -- highly likely not power law\n",
    "KS_tst = X.test_pl(niter=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent sets\n",
    "\n",
    "Illustrating a few functions to find independent sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate random graph with (at least one) independent set \n",
    "## n: nodes, s: independent set size, d: avg degree\n",
    "def indepSet(n,s,d):\n",
    "    N = n-s\n",
    "    di = n*d//2-s*d\n",
    "    ## random graph with N nodes\n",
    "    g = ig.Graph.Erdos_Renyi(n=N,m=di)\n",
    "    ## extra nodes\n",
    "    g.add_vertices(s)\n",
    "    ## assign remaining degree to extra nodes\n",
    "    z = np.random.choice(np.arange(N,n),size=s*d)\n",
    "    deg = [x[1] for x in sorted(Counter(z).items())]\n",
    "    for i in range(len(deg)):\n",
    "        e = np.random.choice(N,deg[i],replace=False)\n",
    "        for j in e:\n",
    "            g.add_edge(j,i+N)\n",
    "    p = list(np.random.permutation(n))\n",
    "    G = g.permute_vertices(p)\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = indepSet(50, 10, 20)\n",
    "\n",
    "## every set of size min or mode\n",
    "#ivs = g.independent_vertex_sets(min=9)\n",
    "\n",
    "## largest set(s) only\n",
    "ivs = g.largest_independent_vertex_sets()\n",
    "\n",
    "## maximal sets (that can't be extended)\n",
    "#ivs = g.maximal_independent_vertex_sets()\n",
    "\n",
    "print(g.independence_number())\n",
    "\n",
    "ivs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs",
   "language": "python",
   "name": "graphs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
